{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Markdown, display\n",
    "import copy\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['age', 'workclass', 'fnlwgt', 'education', 'education.num', 'marital', 'occupation', 'relationship', 'race', 'gender', 'capgain', 'caploss', 'hours', 'country', 'income']\n",
    "df_train = pd.read_csv('adult.data', names=cols, sep=\",\")\n",
    "df_test = pd.read_csv('adult.test', names=cols, sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-processing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#{1: {'State-gov': 0, 'Self-emp-not-inc': 1, 'Private': 2, 'Federal-gov': 3, 'Local-gov': 4, '?': 5,\n",
    "#'Self-emp-inc': 6, 'Without-pay': 7, 'Never-worked': 8}, \n",
    "#3: {'Bachelors': 0, 'HS-grad': 1, '11th': 2, 'Masters': 3, '9th': 4, \n",
    "#'Some-college': 5, 'Assoc-acdm': 6, 'Assoc-voc': 7, '7th-8th': 8, 'Doctorate': 9, 'Prof-school': 10, '5th-6th': 11, '10th': 12, '1st-4th': 13, 'Preschool': 14, '12th': 15}, \n",
    "#5: {'Never-married': 0, 'Married-civ-spouse': 1, 'Divorced': 2, 'Married-spouse-absent': 3, 'Separated': 4, 'Married-AF-spouse': 5, 'Widowed': 6}, \n",
    "#6: {'Adm-clerical': 0, 'Exec-managerial': 1, 'Handlers-cleaners': 2, 'Prof-specialty': 3, 'Other-service': 4, 'Sales': 5, 'Craft-repair': 6, 'Transport-moving': 7, 'Farming-fishing': 8, 'Machine-op-inspct': 9, 'Tech-support': 10, '?': 11, 'Protective-serv': 12, 'Armed-Forces': 13, 'Priv-house-serv': 14},\n",
    "#7: {'Not-in-family': 0, 'Husband': 1, 'Wife': 2, 'Own-child': 3, 'Unmarried': 4, 'Other-relative': 5}, \n",
    "#8: {'White': 0, 'Black': 1, 'Asian-Pac-Islander': 2, 'Amer-Indian-Eskimo': 3, 'Other': 4}, \n",
    "#9: {'Male': 1, 'Female': 0},\n",
    "#13: {'United-States': 0, 'Cuba': 1, 'Jamaica': 2, 'India': 3, '?': 4, 'Mexico': 5, 'South': 6, 'Puerto-Rico': 7, 'Honduras': 8, 'England': 9, 'Canada': 10, 'Germany': 11, 'Iran': 12, 'Philippines': 13, 'Italy': 14, 'Poland': 15, 'Columbia': 16, 'Cambodia': 17, 'Thailand': 18, 'Ecuador': 19, 'Laos': 20, 'Taiwan': 21, 'Haiti': 22, 'Portugal': 23, 'Dominican-Republic': 24, 'El-Salvador': 25, 'France': 26, 'Guatemala': 27, 'China': 28, 'Japan': 29, 'Yugoslavia': 30, 'Peru': 31, 'Outlying-US(Guam-USVI-etc)': 32, 'Scotland': 33, 'Trinadad&Tobago': 34, 'Greece': 35, 'Nicaragua': 36, 'Vietnam': 37, 'Hong': 38, 'Ireland': 39, 'Hungary': 40, 'Holand-Netherlands': 41}, 14: {'<=50K': 0, '>50K': 1}, 0: {'|1x3 Cross validator': 0, '': 1}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    " def preprocess(df):\n",
    "    df.isin(['?']).sum(axis=0)\n",
    "\n",
    "    # replace missing values (?) to nan and then drop the columns\n",
    "    df['country'] = df['country'].replace('?',np.nan)\n",
    "    df['workclass'] = df['workclass'].replace('?',np.nan)\n",
    "    df['occupation'] = df['occupation'].replace('?',np.nan)\n",
    "\n",
    "    # dropping the NaN rows now\n",
    "    df.dropna(how='any',inplace=True)\n",
    "            \n",
    "    df['income'] = df['income'].map({'<=50K': 0, '>50K': 1}).astype(int)\n",
    "    df['gender'] = df['gender'].map({'Male': 1, 'Female': 0}).astype(int)\n",
    "    df['workclass'] = df['workclass'].map({'State-gov': 0, 'Self-emp-not-inc': 1, 'Private': 2, 'Federal-gov': 3, 'Local-gov': 4, '?': 5,\n",
    "                                           'Self-emp-inc': 6, 'Without-pay': 7, 'Never-worked': 8}).astype(int)\n",
    "    df['education'] = df['education'].map({'Bachelors': 0, 'HS-grad': 1, '11th': 2, 'Masters': 3, '9th': 4, \n",
    "                                           'Some-college': 5, 'Assoc-acdm': 6, 'Assoc-voc': 7, '7th-8th': 8, 'Doctorate': 9, \n",
    "                                           'Prof-school': 10, '5th-6th': 11, '10th': 12, '1st-4th': 13, 'Preschool': 14, '12th': 15}).astype(int)\n",
    "    df['marital'] = df['marital'].map({'Never-married': 0, 'Married-civ-spouse': 1, 'Divorced': 2, 'Married-spouse-absent': 3, \n",
    "                                                     'Separated': 4, 'Married-AF-spouse': 5, 'Widowed': 6}).astype(int)\n",
    "    df['occupation'] = df['occupation'].map({'Adm-clerical': 0, 'Exec-managerial': 1, 'Handlers-cleaners': 2, \n",
    "                                             'Prof-specialty': 3, 'Other-service': 4, 'Sales': 5, 'Craft-repair': 6, 'Transport-moving': 7, 'Farming-fishing': 8, \n",
    "                                             'Machine-op-inspct': 9, 'Tech-support': 10, '?': 11, 'Protective-serv': 12, 'Armed-Forces': 13, 'Priv-house-serv': 14}).astype(int)\n",
    "    df['relationship'] = df['relationship'].map({'Not-in-family': 0, 'Husband': 1, 'Wife': 2, \n",
    "                                                 'Own-child': 3, 'Unmarried': 4, 'Other-relative': 5}).astype(int)\n",
    "    df['race'] = df['race'].map({'White': 0, 'Black': 1, 'Asian-Pac-Islander': 2, 'Amer-Indian-Eskimo': 3, 'Other': 4}).astype(int)\n",
    "    df['country'] = df['country'].map({'United-States': 0, 'Cuba': 1, 'Jamaica': 2, 'India': 3, '?': 4, 'Mexico': 5, 'South': 6, 'Puerto-Rico': 7, \n",
    "                                       'Honduras': 8, 'England': 9, 'Canada': 10, 'Germany': 11, 'Iran': 12, 'Philippines': 13, 'Italy': 14, \n",
    "                                       'Poland': 15, 'Columbia': 16, 'Cambodia': 17, 'Thailand': 18, 'Ecuador': 19, 'Laos': 20, 'Taiwan': 21, \n",
    "                                       'Haiti': 22, 'Portugal': 23, 'Dominican-Republic': 24, 'El-Salvador': 25, 'France': 26, 'Guatemala': 27, \n",
    "                                       'China': 28, 'Japan': 29, 'Yugoslavia': 30, 'Peru': 31, 'Outlying-US(Guam-USVI-etc)': 32, 'Scotland': 33,\n",
    "                                       'Trinadad&Tobago': 34, 'Greece': 35, 'Nicaragua': 36, 'Vietnam': 37, 'Hong': 38, 'Ireland': 39, 'Hungary': 40, \n",
    "                                       'Holand-Netherlands': 41}).astype(int)\n",
    "    \n",
    "    \n",
    "    labels = df['age']\n",
    "    proc = []\n",
    "    for v in labels:\n",
    "            if v <= 30:\n",
    "                proc.append(1)\n",
    "            elif v <= 40:\n",
    "                proc.append(2)\n",
    "            elif v <= 50:\n",
    "                proc.append(3)\n",
    "            else:\n",
    "                proc.append(4)\n",
    "    df['age']=proc \n",
    "    \n",
    "    labels = df['hours']\n",
    "    proc=[]\n",
    "    for v in labels:\n",
    "        if v<=25:\n",
    "            proc.append(1)\n",
    "        elif v<=41:\n",
    "            proc.append(2)\n",
    "        elif v<=55:\n",
    "            proc.append(3)\n",
    "        else:\n",
    "            proc.append(4)\n",
    "    df['hours']=proc\n",
    "    \n",
    "    df = df.drop(['fnlwgt', 'education.num', 'capgain', 'caploss', 'country'], axis = 1, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess(df_train)\n",
    "preprocess(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = df_train[1:100]\n",
    "# df_test = df_test[1:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Privileged, unprivileged**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# privileged, unprivileged groups\n",
    "privileged_groups = [{'gender': 1}] # Male\n",
    "unprivileged_groups = [{'gender': 0}] # Female"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function to compute fairness metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(test_df, y_pred, unprivileged_groups, privileged_groups):\n",
    "    # BLD constructor is taking arguments of Structured dataset\n",
    "    test_bld = BinaryLabelDataset(df=test_df, label_names=['income'], protected_attribute_names=['gender'])\n",
    "    \n",
    "    pred_data = test_bld.copy()\n",
    "    pred_data.labels = y_pred\n",
    "\n",
    "    metric_selection = ClassificationMetric(\n",
    "                    test_bld, pred_data,\n",
    "                    unprivileged_groups=unprivileged_groups,\n",
    "                    privileged_groups=privileged_groups)\n",
    "    \n",
    "    tnr_diff = metric_selection.true_negative_rate(1) - metric_selection.true_negative_rate(0)\n",
    "    \n",
    "    return [metric_selection.true_positive_rate_difference(), \\\n",
    "        metric_selection.statistical_parity_difference(),\\\n",
    "        tnr_diff,\\\n",
    "        metric_selection.accuracy()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: Original\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-0.11157278063988774,\n",
       " -0.16672961606457132,\n",
       " -0.07813651283616496,\n",
       " 0.8253652058432935]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = df_train.drop(columns='income')\n",
    "y_train = df_train['income']\n",
    "\n",
    "X_test = df_test.drop(columns='income')\n",
    "y_test = df_test['income']\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=10, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "metrics = get_metrics(df_test, y_pred, unprivileged_groups, privileged_groups)\n",
    "print(\"Results: Original\")\n",
    "# 'TruePositiveRateDiff', 'StatisticalParityDiff', 'TrueNegativeRateDiff', 'Accuracy'\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fairness metric to retrieve, threshold on metric for iterations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricIndex = 1 #1=statistical parity\n",
    "threshold = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function to return the <attribute, val> pair removing which will result in the minimum parity difference**\n",
    "Note that our search is for the pair that has the least absolute parity difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAttribute(X_train, y_train, X_test, y_test, f, attrList, attrVals):\n",
    "    attrK = None\n",
    "    attrKval = None\n",
    "    f_curr = f\n",
    "    indices = []\n",
    "    \n",
    "    cols = list(set(X_train.columns) - set(attrList))\n",
    "    clf = RandomForestClassifier(max_depth=10, random_state=0)\n",
    "\n",
    "    X_train_pred = copy.deepcopy(X_train)\n",
    "    y_train_pred = copy.deepcopy(y_train)\n",
    "    # tuples satisfying predicate\n",
    "    for i in range(len(attrList)):\n",
    "        print(i)\n",
    "        X_train_pred = X_train_pred[X_train_pred[attrList[i]] == attrVals[i]]\n",
    "        \n",
    "    for col in cols:\n",
    "        print(col)\n",
    "        for val in X_train[col].unique():\n",
    "            predIndices = X_train_pred[X_train_pred[col] == val].index        \n",
    "            X_train_rest = X_train.drop(index=predIndices)\n",
    "            y_train_rest = y_train.drop(index=predIndices)\n",
    "        \n",
    "#             print(\"#Rows left: \", len(X_train_rest))\n",
    "            clf.fit(X_train_rest, y_train_rest)\n",
    "            y_pred = clf.predict(X_test)\n",
    "\n",
    "            f_i = get_metrics(pd.concat([X_test, y_test], axis=1), y_pred, privileged_groups, unprivileged_groups)[metricIndex]\n",
    "            if ((abs(f_i) < abs(f_curr)) and (abs(f_i) > threshold)) : #closer to 0 implies fairer\n",
    "                attrK = col\n",
    "                attrKval = val\n",
    "                f_curr = f_i\n",
    "                print(\"Attribute passed: \", attrK)\n",
    "                print(\"Attribute value passed: \", attrKval)\n",
    "                print(\"Rows after removing predicate: \", len(X_train_rest))\n",
    "                print(\"f_curr: \", f_curr)\n",
    "    \n",
    "    return [attrK, attrKval, f_curr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function to get a set of predicates such that removing tuples that satisfy these predicates will decrease parity difference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredicates(X_train, y_train, X_test, y_test, f_0):    \n",
    "    attrList = []\n",
    "    attrVals = []\n",
    "    found = True\n",
    "    f_curr = f_0\n",
    "    \n",
    "    print(\"Size of X_train: \", len(X_train))\n",
    "    \n",
    "    depth=0\n",
    "    k = len(list(set(X_train.columns) - set(attrList)))\n",
    "    while (k > 0 and found):\n",
    "        print(\"Depth: \", depth)\n",
    "        depth += 1\n",
    "        found = False\n",
    "#         Testing on training data (could do on validation data)\n",
    "        results = getAttribute(X_train, y_train, X_train, y_train, f_curr, attrList, attrVals)\n",
    "        attrK = results[0]\n",
    "        attrKval = results[1]\n",
    "        f = results[2]\n",
    "        \n",
    "        if (attrK is not None):\n",
    "            attrList.insert(len(attrList), attrK)\n",
    "            attrVals.insert(len(attrVals), attrKval)\n",
    "            f_curr = f\n",
    "            \n",
    "            print(\"Selected k: \", attrK)\n",
    "            print(\"Selected k-val: \", attrKval)\n",
    "            print(\"f: \", f)\n",
    "            found = True\n",
    "            \n",
    "    return [attrList, attrVals]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get predicates on training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X_train:  30162\n",
      "Depth:  0\n",
      "marital\n",
      "Attribute passed:  marital\n",
      "Attribute value passed:  0\n",
      "Rows after removing predicate:  20436\n",
      "f_curr:  0.1347629751547424\n",
      "Attribute passed:  marital\n",
      "Attribute value passed:  1\n",
      "Rows after removing predicate:  16097\n",
      "f_curr:  0.03250703410903325\n",
      "age\n",
      "education\n",
      "relationship\n",
      "hours\n",
      "gender\n",
      "occupation\n",
      "race\n",
      "workclass\n",
      "Selected k:  marital\n",
      "Selected k-val:  1\n",
      "f:  0.03250703410903325\n",
      "Depth:  1\n",
      "0\n",
      "age\n",
      "education\n",
      "relationship\n",
      "Attribute passed:  relationship\n",
      "Attribute value passed:  1\n",
      "Rows after removing predicate:  17708\n",
      "f_curr:  0.03212775503021813\n",
      "hours\n",
      "gender\n",
      "occupation\n",
      "race\n",
      "workclass\n",
      "Selected k:  relationship\n",
      "Selected k-val:  1\n",
      "f:  0.03212775503021813\n",
      "Depth:  2\n",
      "0\n",
      "1\n",
      "age\n",
      "education\n",
      "hours\n",
      "gender\n",
      "Attribute passed:  gender\n",
      "Attribute value passed:  1\n",
      "Rows after removing predicate:  17709\n",
      "f_curr:  0.023115618220082998\n",
      "occupation\n",
      "race\n",
      "workclass\n",
      "Selected k:  gender\n",
      "Selected k-val:  1\n",
      "f:  0.023115618220082998\n",
      "Depth:  3\n",
      "0\n",
      "1\n",
      "2\n",
      "age\n",
      "education\n",
      "hours\n",
      "occupation\n",
      "race\n",
      "workclass\n",
      "['marital', 'relationship', 'gender']\n",
      "[1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "attrList, attrVals = getPredicates(X_train, y_train, X_test, y_test, metrics[metricIndex])\n",
    "print(attrList)\n",
    "print(attrVals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['marital', 'relationship', 'gender']\n"
     ]
    }
   ],
   "source": [
    "print(attrList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attrList = ['marital', 'relationship', 'gender']\n",
    "# attrVals = [1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16097\n",
      "17708\n",
      "17709\n"
     ]
    }
   ],
   "source": [
    "# print(len(X_train) - len(X_train[(X_train['marital']==1)]))\n",
    "# print(len(X_train) - len(X_train[(X_train['marital']==1) & (X_train['relationship']==1)]))\n",
    "# print(len(X_train) - len(X_train[(X_train['marital']==1) & (X_train['relationship']==1) & (X_train['gender']==1)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Testing on test data**\n",
    "\n",
    "Compare initial fairness to final fairness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial #rows:  30162\n",
      "0.16672961606457132\n",
      "marital\n",
      "1\n",
      "#Rows left:  16097\n",
      "0.03377930419174387\n",
      "relationship\n",
      "1\n",
      "#Rows left:  17708\n",
      "0.038582701978855063\n",
      "gender\n",
      "1\n",
      "#Rows left:  17709\n",
      "0.027478600698372227\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial #rows: \", len(X_train))\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(get_metrics(pd.concat([X_test, y_test], axis=1), y_pred, privileged_groups, unprivileged_groups)[metricIndex])\n",
    "\n",
    "X_train_temp = copy.deepcopy(X_train)\n",
    "y_train_temp = copy.deepcopy(y_train)\n",
    "removeTupleIndices = list(range(len(X_train)))\n",
    "for i in range(len(attrList)):\n",
    "    col = attrList[i]\n",
    "    val = attrVals[i]\n",
    "#     print(col)\n",
    "#     print(val)\n",
    "    predIndices = X_train_temp[X_train_temp[col] == val].index\n",
    "    X_train_temp = X_train_temp[X_train_temp[col] == val]\n",
    "    X_train_rest = X_train.drop(index=predIndices)\n",
    "    y_train_rest = y_train.drop(index=predIndices)\n",
    "        \n",
    "    print(\"#Rows left: \", len(X_train_rest))\n",
    "    clf.fit(X_train_rest, y_train_rest)\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    print(get_metrics(pd.concat([X_test, y_test], axis=1), y_pred, privileged_groups, unprivileged_groups)[metricIndex])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top-k heuristic**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<Attribute, metric> for each attribute**\n",
    "\n",
    "Remove tuples satisfying attribute=1 and record new fairness metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = X_train.columns\n",
    "topKattrList = []\n",
    "for col in K:\n",
    "    for val in X_train[col].unique():\n",
    "        removeTupleIndices = X_train[X_train[col] == val].index\n",
    "\n",
    "        X_train_temp = X_train.drop(removeTupleIndices, inplace = False)\n",
    "        y_train_temp = y_train.drop(removeTupleIndices, inplace = False)\n",
    "\n",
    "        clf.fit(X_train_temp, y_train_temp)\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        f_i = get_metrics(pd.concat([X_test, y_test], axis=1), y_pred, privileged_groups, unprivileged_groups)[metricIndex]\n",
    "        topKattrList.insert(len(attrList), [col, val, abs(f_i)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['age', 2, 0.1584974636330573], ['age', 3, 0.14935293441648956], ['age', 4, 0.16405531140835458], ['hours', 4, 0.16650031831085685], ['hours', 3, 0.14954305637517262], ['hours', 1, 0.18019894844784315], ['hours', 2, 0.08574871433485667], ['gender', 0, 0.17404620228378637], ['gender', 1, 0.03138871814531957], ['race', 4, 0.16833415873971969], ['race', 3, 0.16732736287263167], ['race', 2, 0.16478631208553618], ['race', 1, 0.16841983197094307], ['race', 0, 0.1874438227022669], ['relationship', 5, 0.16196248547531822], ['relationship', 4, 0.16548904922190916], ['relationship', 3, 0.1709113363096373], ['relationship', 2, 0.23439754758319545], ['relationship', 1, 0.04613277834357236], ['relationship', 0, 0.1306857382915273], ['occupation', 14, 0.1682162903466809], ['occupation', 13, 0.1706459117731007], ['occupation', 12, 0.16759726063102798], ['occupation', 6, 0.16987234528073392], ['occupation', 10, 0.1617356951329601], ['occupation', 9, 0.16419500430983894], ['occupation', 8, 0.1716849028020041], ['occupation', 7, 0.1684713442298477], ['occupation', 5, 0.15344647401897582], ['occupation', 4, 0.19499791092515437], ['occupation', 3, 0.11573067441281591], ['occupation', 2, 0.18730108078857324], ['occupation', 1, 0.12202203027665112], ['occupation', 0, 0.16865502715616765], ['marital', 6, 0.16479919015026234], ['marital', 5, 0.16839854906335047], ['marital', 4, 0.16796570968537383], ['marital', 3, 0.16564107858726668], ['marital', 2, 0.1720315273479044], ['marital', 1, 0.03377930419174387], ['marital', 0, 0.14325184092637333], ['education', 13, 0.15963588856670768], ['education', 15, 0.16715154318832517], ['education', 14, 0.1717492931256349], ['education', 12, 0.168169251309636], ['education', 11, 0.168657534567524], ['education', 10, 0.1579862726650178], ['education', 7, 0.16873283714537757], ['education', 9, 0.156777900984171], ['education', 8, 0.16903045684372955], ['education', 6, 0.1670445870495092], ['education', 5, 0.16829355873503785], ['education', 4, 0.17009520400208528], ['education', 3, 0.13978451226566463], ['education', 2, 0.16393995042667214], ['education', 1, 0.2519174525679513], ['education', 0, 0.11906603299901783], ['workclass', 7, 0.16474767789135775], ['workclass', 6, 0.16599468376638302], ['workclass', 4, 0.1682593977627191], ['workclass', 3, 0.16078434314578344], ['workclass', 2, 0.12552175469208376], ['workclass', 1, 0.17849978609775202], ['workclass', 0, 0.16800630969005567], ['age', 1, 0.17561550078491003]]\n"
     ]
    }
   ],
   "source": [
    "print(topKattrList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sort <attribute, metric> pairs in increasing order of metric** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(topKattrList, columns = ['col', 'val', 'fval'])\n",
    "df_sorted = df.sort_values(by=['fval'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "      <th>val</th>\n",
       "      <th>fval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gender</td>\n",
       "      <td>1</td>\n",
       "      <td>0.031389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>marital</td>\n",
       "      <td>1</td>\n",
       "      <td>0.033779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>relationship</td>\n",
       "      <td>1</td>\n",
       "      <td>0.046133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>hours</td>\n",
       "      <td>2</td>\n",
       "      <td>0.085749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>occupation</td>\n",
       "      <td>3</td>\n",
       "      <td>0.115731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>occupation</td>\n",
       "      <td>2</td>\n",
       "      <td>0.187301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>race</td>\n",
       "      <td>0</td>\n",
       "      <td>0.187444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>occupation</td>\n",
       "      <td>4</td>\n",
       "      <td>0.194998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>relationship</td>\n",
       "      <td>2</td>\n",
       "      <td>0.234398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>education</td>\n",
       "      <td>1</td>\n",
       "      <td>0.251917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             col  val      fval\n",
       "8         gender    1  0.031389\n",
       "39       marital    1  0.033779\n",
       "18  relationship    1  0.046133\n",
       "6          hours    2  0.085749\n",
       "30    occupation    3  0.115731\n",
       "..           ...  ...       ...\n",
       "31    occupation    2  0.187301\n",
       "13          race    0  0.187444\n",
       "29    occupation    4  0.194998\n",
       "17  relationship    2  0.234398\n",
       "55     education    1  0.251917\n",
       "\n",
       "[65 rows x 3 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Top-k heuristic**\n",
    "\n",
    "Remove tuples satisfying predicates in increasing order of parity difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Rows left:  9782\n",
      "gender\n",
      "1\n",
      "-0.03138871814531957\n",
      "#Rows left:  17577\n",
      "marital\n",
      "1\n",
      "0.09872474863752784\n",
      "#Rows left:  17709\n",
      "relationship\n",
      "1\n",
      "0.027478600698372227\n",
      "#Rows left:  23466\n",
      "hours\n",
      "2\n",
      "0.07422607595077377\n",
      "#Rows left:  29367\n",
      "occupation\n",
      "3\n",
      "0.1429208024494641\n"
     ]
    }
   ],
   "source": [
    "def topkAttributes(X_train, y_train, df_sorted, k_num):\n",
    "    X_train_temp = copy.deepcopy(X_train)\n",
    "    y_train_temp = copy.deepcopy(y_train)\n",
    "    for k in range(k_num):\n",
    "        col = df_sorted.iloc[k]['col']\n",
    "        val = df_sorted.iloc[k]['val']\n",
    "        predIndices = X_train_temp[X_train_temp[col] == val].index        \n",
    "        X_train_temp = X_train_temp[X_train_temp[col] == val]\n",
    "        X_train_rest = X_train.drop(index=predIndices)\n",
    "        y_train_rest = y_train.drop(index=predIndices)\n",
    "        \n",
    "        print(\"#Rows left: \", len(X_train_rest))\n",
    "        clf.fit(X_train_rest, y_train_rest)\n",
    "        y_pred = clf.predict(X_test)\n",
    "\n",
    "        print(col)\n",
    "        print(val)\n",
    "        print(get_metrics(pd.concat([X_test, y_test], axis=1), y_pred, privileged_groups, unprivileged_groups)[metricIndex])\n",
    "        \n",
    "topkAttributes(X_train, y_train, df_sorted, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
