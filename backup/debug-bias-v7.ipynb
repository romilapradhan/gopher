{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'tensorflow': AdversarialDebiasing will be unavailable. To install, run:\n",
      "pip install 'aif360[AdversarialDebiasing]'\n",
      "WARNING:root:No module named 'numba.decorators': LFR will be unavailable. To install, run:\n",
      "pip install 'aif360[LFR]'\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "from aif360.algorithms.preprocessing.optim_preproc import OptimPreproc\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_adult\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.distortion_functions import get_distortion_adult\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.opt_tools import OptTools\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Markdown, display\n",
    "import copy\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('adult-small.csv')\n",
    "df = pd.read_csv('adult.csv')\n",
    "\n",
    "# check columns that have missing values\\n\n",
    "df.isin(['?']).sum(axis=0)\n",
    "\n",
    "# replace missing values (?) to nan and then drop the columns\n",
    "df['native.country'] = df['native.country'].replace('?',np.nan)\n",
    "df['workclass'] = df['workclass'].replace('?',np.nan)\n",
    "df['occupation'] = df['occupation'].replace('?',np.nan)\n",
    "\n",
    "# dropping the NaN rows now\n",
    "df.dropna(how='any',inplace=True)\n",
    "\n",
    "df['income'] = df['income'].map({'<=50K': 0, '>50K': 1}).astype(int)\n",
    "df['sex'] = df['sex'].map({'Male': 1, 'Female': 0}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data pre-processing (using one-hot encoding)\n",
    "\n",
    "# For each category we made a separate column\n",
    "df = pd.concat([df, pd.get_dummies(df['race'], prefix='race')],axis=1)\n",
    "df = pd.concat([df, pd.get_dummies(df['marital.status'], prefix='marital')],axis=1)\n",
    "df = pd.concat([df, pd.get_dummies(df['workclass'], prefix='workclass')],axis=1)\n",
    "df = pd.concat([df, pd.get_dummies(df['relationship'], prefix='relationship')],axis=1)\n",
    "df = pd.concat([df, pd.get_dummies(df['education'], prefix='education')],axis=1)\n",
    "df = pd.concat([df, pd.get_dummies(df['occupation'], prefix='occupation')],axis=1)\n",
    "\n",
    "# age binning\n",
    "df['ageUnder18'] = np.where(df['age'] < 18, 1, 0)\n",
    "df['age18to24'] = np.where((df['age'] >= 18) & (df['age'] <= 24), 1, 0)\n",
    "df['age25to44'] = np.where((df['age'] >= 25) & (df['age'] <= 44), 1, 0)\n",
    "df['age45to64'] = np.where((df['age'] >= 45) & (df['age'] <= 64), 1, 0)\n",
    "df['ageAbove65'] = np.where(df['age'] >= 65, 1, 0)\n",
    "\n",
    "# privileged, unprivileged groups\n",
    "privileged_groups = [{'sex': 1}] # Male\n",
    "unprivileged_groups = [{'sex': 0}] # Female\n",
    "\n",
    "df = df.drop(columns=['workclass', 'fnlwgt', 'education', 'education.num', 'occupation', \\\n",
    "                      'relationship', 'marital.status', 'race', 'native.country', 'capital.gain', \\\n",
    "                      'capital.loss', 'hours.per.week', 'age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(test_df, y_pred, unprivileged_groups, privileged_groups):\n",
    "    # BLD constructor is taking arguments of Structured dataset\n",
    "    test_bld = BinaryLabelDataset(df=test_df, label_names=['income'], protected_attribute_names=['sex'])\n",
    "    \n",
    "    # Made a copy of the the bld dataset\n",
    "    pred_data = test_bld.copy()\n",
    "    pred_data.labels = y_pred\n",
    "\n",
    "    metric_selection = ClassificationMetric(\n",
    "                    test_bld, pred_data,\n",
    "                    unprivileged_groups=unprivileged_groups,\n",
    "                    privileged_groups=privileged_groups)\n",
    "    \n",
    "    tnr_diff = metric_selection.true_negative_rate(1) - metric_selection.true_negative_rate(0)\n",
    "    \n",
    "    return [metric_selection.true_positive_rate_difference(), \\\n",
    "        metric_selection.statistical_parity_difference(),\\\n",
    "        tnr_diff,\\\n",
    "        metric_selection.accuracy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: Original\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TruePositiveRateDiff    -0.135077\n",
       "StatisticalParityDiff   -0.181838\n",
       "TrueNegativeRateDiff    -0.088531\n",
       "Accuracy                 0.825942\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# k-fold cross-validation to compute fairness over entire data\n",
    "\n",
    "X = df.drop(columns='income')\n",
    "y = df['income']\n",
    "\n",
    "num_k = 5 # number of folds for cross-validation\n",
    "\n",
    "# Metrics for each set of (train and test) sample\n",
    "metrics = [None] * num_k\n",
    "\n",
    "# Regression on original data\n",
    "k_fold = KFold(n_splits=num_k, random_state=None, shuffle=False)\n",
    "for k, (train, test) in enumerate(k_fold.split(X, y)):\n",
    "    # Here train and test are the list of indices on which split is done\n",
    "    # take out test set from X\n",
    "    test_df = X.iloc[test].copy()\n",
    "    test_df['income'] = y.iloc[test]\n",
    "    \n",
    "    reg = LogisticRegression(max_iter=300, solver = 'lbfgs')\n",
    "    reg.fit(X.iloc[train], y.iloc[train])\n",
    "    y_pred = reg.predict(X.iloc[test])\n",
    "    metrics[k] = get_metrics(test_df, y_pred, unprivileged_groups, privileged_groups)\n",
    "\n",
    "print(\"Results: Original\")\n",
    "mf_orig = pd.DataFrame(metrics, columns = ['TruePositiveRateDiff', 'StatisticalParityDiff', \\\n",
    "                                      'TrueNegativeRateDiff', 'Accuracy'])\n",
    "mf_orig.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metricIndex = 1\n",
    "threshold = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPredicates(X_train, y_train, X_test, y_test, f_0):    \n",
    "    attrList = []\n",
    "    found = True\n",
    "    f_curr = f_0\n",
    "    \n",
    "    K = X_train.columns\n",
    "    while (len(K) > 0 and found):\n",
    "        found = False\n",
    "        results = getAttribute(X_train, y_train, K, X_test, y_test, f_curr)\n",
    "        attrK = results[0]\n",
    "        f = results[1]\n",
    "        indices = results[2]\n",
    "        print(\"Selected k: \", attrK)\n",
    "        print(\"f: \", f)\n",
    "\n",
    "        if (attrK is not None):\n",
    "            K = K.drop(attrK)\n",
    "            attrList.insert(len(attrList), attrK)\n",
    "            f_curr = f\n",
    "            X_train = X_train.drop(indices)\n",
    "            y_train = y_train.drop(indices)\n",
    "            found = True\n",
    "            \n",
    "    return attrList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# binary attributes\n",
    "def getAttribute(X_train, y_train, K, X_test, y_test, f):\n",
    "    attrK = None\n",
    "    f_curr = f\n",
    "    indices = []\n",
    "#     removeTupleIndices = []\n",
    "    \n",
    "    reg = LogisticRegression(max_iter=300, solver = 'lbfgs')\n",
    "    for col in K:\n",
    "        removeTupleIndices = X_train[X_train[col] == 1].index\n",
    "\n",
    "        X_train_temp = X_train.drop(removeTupleIndices, inplace = False)\n",
    "        y_train_temp = y_train.drop(removeTupleIndices, inplace = False)\n",
    "\n",
    "        reg.fit(X_train_temp, y_train_temp)\n",
    "        y_pred = reg.predict(X_test)\n",
    "\n",
    "        f_i = get_metrics(pd.concat([X_test, y_test], axis=1), y_pred, privileged_groups, unprivileged_groups)[metricIndex]\n",
    "        if ((abs(f_i) < abs(f_curr)) and (abs(f_i) > threshold)) : #closer to 0 implies fairer\n",
    "            attrK = col\n",
    "            f_curr = f_i\n",
    "            indices = copy.deepcopy(removeTupleIndices)\n",
    "            print(\"attrK: \", attrK)\n",
    "            print(\"f_curr: \", f_curr)\n",
    "    \n",
    "    return [attrK, f_curr, indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.10686055672268907, -0.16753487179888252, -0.07622049167709677, 0.8312613956572187]\n"
     ]
    }
   ],
   "source": [
    "train, test = train_test_split(df, test_size = 0.2)\n",
    "\n",
    "X_train = train.drop(columns='income')\n",
    "y_train = train['income']\n",
    "\n",
    "X_test = test.drop(columns='income')\n",
    "y_test = test['income']\n",
    "\n",
    "reg = LogisticRegression(max_iter=300, solver = 'lbfgs')\n",
    "reg.fit(X_train, y_train)\n",
    "y_pred = reg.predict(X_test)\n",
    "f_orig = get_metrics(pd.concat([X_test, y_test], axis=1), y_pred, unprivileged_groups, privileged_groups)\n",
    "\n",
    "print(f_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attrK:  sex\n",
      "f_curr:  0.045699596819462854\n",
      "Selected k:  sex\n",
      "f:  0.045699596819462854\n",
      "attrK:  race_Black\n",
      "f_curr:  0.04347480014420749\n",
      "attrK:  race_White\n",
      "f_curr:  0.029787828796742875\n",
      "attrK:  marital_Married-civ-spouse\n",
      "f_curr:  -0.010756652882522613\n",
      "attrK:  workclass_Private\n",
      "f_curr:  -0.007870358573597164\n",
      "Selected k:  workclass_Private\n",
      "f:  -0.007870358573597164\n",
      "attrK:  race_White\n",
      "f_curr:  -0.005670664497331168\n",
      "attrK:  marital_Married-civ-spouse\n",
      "f_curr:  0.002508746174376529\n",
      "attrK:  workclass_State-gov\n",
      "f_curr:  -0.0021318287583951823\n",
      "Selected k:  workclass_State-gov\n",
      "f:  -0.0021318287583951823\n",
      "attrK:  race_Other\n",
      "f_curr:  -0.0016439048745210683\n",
      "attrK:  marital_Married-civ-spouse\n",
      "f_curr:  0.0005279114410582145\n",
      "attrK:  education_10th\n",
      "f_curr:  -0.00020927242072056595\n",
      "Selected k:  education_10th\n",
      "f:  -0.00020927242072056595\n",
      "attrK:  marital_Married-civ-spouse\n",
      "f_curr:  -0.0002039743847529591\n",
      "Selected k:  marital_Married-civ-spouse\n",
      "f:  -0.0002039743847529591\n",
      "attrK:  workclass_Federal-gov\n",
      "f_curr:  0.00015654434847150404\n",
      "Selected k:  workclass_Federal-gov\n",
      "f:  0.00015654434847150404\n",
      "Selected k:  None\n",
      "f:  0.00015654434847150404\n"
     ]
    }
   ],
   "source": [
    "attrList = getPredicates(X_train, y_train, X_test, y_test, f_orig[metricIndex])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sex',\n",
       " 'workclass_Private',\n",
       " 'workclass_State-gov',\n",
       " 'education_10th',\n",
       " 'marital_Married-civ-spouse',\n",
       " 'workclass_Federal-gov']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attrList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
