{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import copy\n",
    "import random\n",
    "import math\n",
    "from scipy import stats\n",
    "from scipy.stats import rankdata\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import classification_report\n",
    "from operator import itemgetter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Markdown, display\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['status', 'duration', 'credit_hist', 'purpose', 'credit_amt', 'savings', 'employment', 'install_rate', 'personal_status', 'debtors', 'residence', 'property', 'age', 'install_plans', 'housing', 'num_credits', 'job', 'num_liable', 'telephone', 'foreign_worker', 'credit']\n",
    "df = pd.read_table('german.data', names=cols, sep=\" \", index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-processing** (categorical to numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    " def preprocess(df):\n",
    "    df['status'] = df['status'].map({'A11': 0, 'A12': 1, 'A13': 2, 'A14': 3}).astype(int)\n",
    "    \n",
    "    df.loc[(df['duration'] <= 12), 'duration'] = 0\n",
    "    df.loc[(df['duration'] > 12) & (df['duration'] <= 24), 'duration'] = 1\n",
    "    df.loc[(df['duration'] > 24) & (df['duration'] <= 36), 'duration'] = 2\n",
    "    df.loc[(df['duration'] > 36), 'duration'] = 3    \n",
    "    \n",
    "    df['credit_hist'] = df['credit_hist'].map({'A34': 0, 'A33': 1, 'A32': 2, 'A31': 3, 'A30': 4}).astype(int)    \n",
    "    df = pd.concat([df, pd.get_dummies(df['purpose'], prefix='purpose')],axis=1)\n",
    "\n",
    "    df.loc[(df['credit_amt'] <= 2000), 'credit_amt'] = 0\n",
    "    df.loc[(df['credit_amt'] > 2000) & (df['credit_amt'] <= 5000), 'credit_amt'] = 1\n",
    "    df.loc[(df['credit_amt'] > 5000), 'credit_amt'] = 2    \n",
    "    \n",
    "    df['savings'] = df['savings'].map({'A61': 0, 'A62': 1, 'A63': 2, 'A64': 3, 'A65': 4}).astype(int)\n",
    "    df['employment'] = df['employment'].map({'A71': 0, 'A72': 1, 'A73': 2, 'A74': 3, 'A75': 4}).astype(int)    \n",
    "    df['gender'] = df['personal_status'].map({'A91': 1, 'A92': 0, 'A93': 1, 'A94': 1, 'A95': 0}).astype(int)\n",
    "    df['debtors'] = df['debtors'].map({'A101': 0, 'A102': 1, 'A103': 2}).astype(int)\n",
    "    df['property'] = df['property'].map({'A121': 3, 'A122': 2, 'A123': 1, 'A124': 0}).astype(int)        \n",
    "    df['age'] = df['age'].apply(lambda x : 1 if x >= 45 else 0) # 1 if old, 0 if young\n",
    "    df['install_plans'] = df['install_plans'].map({'A141': 1, 'A142': 1, 'A143': 0}).astype(int)\n",
    "    df = pd.concat([df, pd.get_dummies(df['housing'], prefix='housing')],axis=1)\n",
    "    df['job'] = df['job'].map({'A171': 0, 'A172': 1, 'A173': 2, 'A174': 3}).astype(int)    \n",
    "    df['telephone'] = df['telephone'].map({'A191': 0, 'A192': 1}).astype(int)\n",
    "    df['foreign_worker'] = df['foreign_worker'].map({'A201': 1, 'A202': 0}).astype(int)\n",
    "    \n",
    "    df['credit'] = df['credit'].replace(2, 0) #1 = Good, 2= Bad credit risk\n",
    "\n",
    "#     process age\n",
    "#     df.loc[(df['age'] >= 15) & (df['age'] <= 24) , 'age'] = 0\n",
    "#     df.loc[(df['age'] >= 25) & (df['age'] <= 34) , 'age'] = 1\n",
    "#     df.loc[(df['age'] >= 35) & (df['age'] <= 44) , 'age'] = 2\n",
    "#     df.loc[(df['age'] >= 45) & (df['age'] <= 54) , 'age'] = 3\n",
    "#     df.loc[(df['age'] >= 55) & (df['age'] <= 64) , 'age'] = 4\n",
    "#     df.loc[(df['age'] >= 65) , 'age'] = 5\n",
    "\n",
    "    return df\n",
    "\n",
    "df = preprocess(df)\n",
    "df_orig = copy.deepcopy(df)\n",
    "\n",
    "y = df['credit']\n",
    "df = df.drop(columns=['purpose', 'personal_status', 'housing', 'credit'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2, random_state=1)\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Protected, privileged**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# protected: 'gender'=0\n",
    "# privileged: 'gender'=1\n",
    "\n",
    "# protected: 'age'=0\n",
    "# privileged: 'age'=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parametric Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size=500\n",
    "# X_train = X_train[0:size]\n",
    "# y_train = y_train[0:size]\n",
    "\n",
    "X_train_orig = copy.deepcopy(X_train)\n",
    "X_test_orig = copy.deepcopy(X_test)\n",
    "\n",
    "# Scale data: regularization penalty default: ‘l2’, ‘lbfgs’ solvers support only l2 penalties. \n",
    "# Regularization makes the predictor dependent on the scale of the features.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression(random_state=0, max_iter=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute fairness metric**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeFairness(y_pred, X_test, y_test, metric): \n",
    "    fairnessMetric = 0\n",
    "    protected_idx = X_test[X_test['age']==0].index\n",
    "    numProtected = len(protected_idx)\n",
    "    privileged_idx = X_test[X_test['age']==1].index\n",
    "    numPrivileged = len(privileged_idx)\n",
    "        \n",
    "    p_protected = 0\n",
    "    for i in range(len(protected_idx)):\n",
    "        p_protected += y_pred[protected_idx[i]][1]\n",
    "    p_protected /= len(protected_idx)\n",
    "    \n",
    "    p_privileged = 0\n",
    "    for i in range(len(privileged_idx)):\n",
    "        p_privileged += y_pred[privileged_idx[i]][1]\n",
    "    p_privileged /= len(privileged_idx)\n",
    "    \n",
    "    # statistical parity difference\n",
    "    statistical_parity = p_protected - p_privileged\n",
    "    \n",
    "    # equality of opportunity, or \n",
    "    # true positive rate parity\n",
    "    # P(Y=1 | Y=1, G=0)- P(Y=1 | Y=1, G=1)\n",
    "    true_positive_protected = 0\n",
    "    actual_positive_protected = 0\n",
    "    for i in range(len(protected_idx)):\n",
    "        if (y_test[protected_idx[i]] == 1):\n",
    "            actual_positive_protected += 1\n",
    "#             if (y_pred[protected_idx[i]][1] > y_pred[protected_idx[i]][0]):\n",
    "            true_positive_protected += y_pred[protected_idx[i]][1]\n",
    "    tpr_protected = true_positive_protected/actual_positive_protected\n",
    "    \n",
    "    true_positive_privileged = 0\n",
    "    actual_positive_privileged = 0\n",
    "    for i in range(len(privileged_idx)):\n",
    "        if (y_test[privileged_idx[i]] == 1):\n",
    "            actual_positive_privileged += 1\n",
    "#             if (y_pred[privileged_idx[i]][1] > y_pred[privileged_idx[i]][0]):\n",
    "            true_positive_privileged += y_pred[privileged_idx[i]][1]\n",
    "    tpr_privileged = true_positive_privileged/actual_positive_privileged\n",
    "    \n",
    "    tpr_parity = tpr_protected - tpr_privileged\n",
    "    \n",
    "    # equalized odds or TPR parity + FPR parity\n",
    "    # false positive rate parity\n",
    "    \n",
    "    # predictive parity\n",
    "    p_o1_y1_s1 = 0\n",
    "    p_o1_s1 = 0\n",
    "    for i in range(len(protected_idx)):\n",
    "#         if (y_pred[protected_idx[i]][1] > y_pred[protected_idx[i]][0]):\n",
    "        p_o1_s1 += y_pred[protected_idx[i]][1]\n",
    "        if (y_test[protected_idx[i]] == 1):\n",
    "            p_o1_y1_s1 += y_pred[protected_idx[i]][1]\n",
    "    ppv_protected = p_o1_y1_s1/p_o1_s1\n",
    "    \n",
    "    p_o1_y1_s0 = 0\n",
    "    p_o1_s0 = 0\n",
    "    for i in range(len(privileged_idx)):\n",
    "#         if (y_pred[privileged_idx[i]][1] > y_pred[privileged_idx[i]][0]):\n",
    "        p_o1_s0 += y_pred[privileged_idx[i]][1]\n",
    "        if (y_test[privileged_idx[i]] == 1):\n",
    "            p_o1_y1_s0 += y_pred[privileged_idx[i]][1]\n",
    "    ppv_privileged = p_o1_y1_s0/p_o1_s0\n",
    "    \n",
    "    predictive_parity = ppv_protected - ppv_privileged\n",
    "    \n",
    "    if (metric == 0):\n",
    "        fairnessMetric = statistical_parity\n",
    "    elif (metric == 1):\n",
    "        fairnessMetric = tpr_parity\n",
    "    elif (metric == 2):\n",
    "        fairnessMetric = predictive_parity\n",
    "        \n",
    "    return fairnessMetric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Influence of points computed using ground truth**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ground_truth_influence(X_train, y_train, X_test, X_test_orig, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict_proba(X_test)\n",
    "    spd_0 = computeFairness(y_pred, X_test_orig, y_test, 0)\n",
    "\n",
    "    delta_spd = []\n",
    "    for i in range(len(X_train)):\n",
    "        X_removed = np.delete(X_train, i, 0)\n",
    "        y_removed = y_train.drop(index=i, inplace=False)\n",
    "        clf.fit(X_removed, y_removed)\n",
    "        y_pred = clf.predict_proba(X_test)\n",
    "        delta_spd_i = computeFairness(y_pred, X_test_orig, y_test, 0) - spd_0\n",
    "        delta_spd.append(delta_spd_i)\n",
    "    \n",
    "    return delta_spd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss function** (Log loss for logistic regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_loss(y_true, y_pred):\n",
    "    loss = 0\n",
    "    for i in range(len(y_true)):\n",
    "        if (y_pred[i][1] != 0 and y_pred[i][0] != 0):\n",
    "            loss += - y_true[i] * math.log(y_pred[i][1]) - (1 - y_true[i]) * math.log(y_pred[i][0])\n",
    "    loss /= len(y_true)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute Accuracy** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def computeAccuracy(y_true, y_pred):\n",
    "    accuracy = 0\n",
    "    for i in range(len(y_true)):\n",
    "        idx = y_true[i]\n",
    "        if (y_pred[i][idx] > y_pred[i][1 - idx]):\n",
    "            accuracy += 1\n",
    "#         accuracy += y_pred[i][idx]\n",
    "    accuracy /= len(y_true)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First-order derivative of loss function at z with respect to model parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_L_del_theta_i(num_params, y_true, x, y_pred):\n",
    "#     del_L_del_theta = np.ones((num_params, 1)) * ((1 - y_true) * y_pred[1] - y_true * y_pred[0])\n",
    "    del_L_del_theta = np.ones((num_params, 1)) * (- y_true + y_pred[1])\n",
    "    for j in range(1, num_params):\n",
    "            del_L_del_theta[j] *=  x[j-1]\n",
    "    return del_L_del_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hessian: Second-order partial derivative of loss function with respect to model parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hessian_one_point(num_params, x, y_pred):\n",
    "    H = np.ones((num_params, num_params)) * (y_pred[0] * y_pred[1])\n",
    "    for i in range(1, num_params):\n",
    "        for j in range(i + 1):\n",
    "            if j == 0:\n",
    "                H[i][j] *= x[i-1]\n",
    "            else:\n",
    "                H[i][j] *= x[i-1] * x[j-1] \n",
    "    i_lower = np.tril_indices(num_params, -1)\n",
    "    H.T[i_lower] = H[i_lower]     \n",
    "    return H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First-order derivative of $P(y \\mid \\textbf{x})$ with respect to model parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_f_del_theta_i(num_params, x, y_pred):\n",
    "    del_f_del_theta = np.ones((num_params, 1)) * (y_pred[0] * y_pred[1])\n",
    "    for j in range(1, num_params):\n",
    "            del_f_del_theta[j] *=  x[j-1]\n",
    "    return del_f_del_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Computing $v=\\nabla($Statistical parity difference$)$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return v = del(SPD)/del(theta)\n",
    "def del_spd_del_theta(num_params, X_test_orig, X_test, y_pred):\n",
    "    del_f_protected = np.zeros((num_params, 1))\n",
    "    del_f_privileged = np.zeros((num_params, 1))\n",
    "    numPrivileged = X_test_orig['age'].sum()\n",
    "    numProtected = len(X_test_orig) - numPrivileged\n",
    "    for i in range(len(X_test)):\n",
    "        del_f_i = del_f_del_theta_i(num_params, X_test[i], y_pred[i])\n",
    "        if X_test_orig.iloc[i]['age'] == 1: #privileged\n",
    "            del_f_privileged = np.add(del_f_privileged, del_f_i)\n",
    "        elif X_test_orig.iloc[i]['age'] == 0:\n",
    "            del_f_protected = np.add(del_f_protected, del_f_i)\n",
    "    del_f_privileged /= numPrivileged\n",
    "    del_f_protected /= numProtected\n",
    "    v = np.subtract(del_f_protected, del_f_privileged)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Computing $v=\\nabla($TPR parity difference$)$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return v = del(TPR_parity)/del(theta)\n",
    "def del_tpr_parity_del_theta(num_params, X_test_orig, X_test, y_pred, y_test):\n",
    "    del_f_protected = np.zeros((num_params, 1))\n",
    "    del_f_privileged = np.zeros((num_params, 1))\n",
    "    \n",
    "    protected_idx = X_test_orig[X_test_orig['age']==0].index\n",
    "    privileged_idx = X_test_orig[X_test_orig['age']==1].index\n",
    "\n",
    "    actual_positive_privileged = 0\n",
    "    for i in range(len(privileged_idx)):\n",
    "        if (y_test[privileged_idx[i]] == 1):\n",
    "            actual_positive_privileged += 1\n",
    "#             if (y_pred[privileged_idx[i]][1] > y_pred[privileged_idx[i]][0]):\n",
    "            del_f_i = del_f_del_theta_i(num_params, X_test[privileged_idx[i]], y_pred[privileged_idx[i]])\n",
    "            del_f_privileged = np.add(del_f_privileged, del_f_i)\n",
    "    del_f_privileged /= actual_positive_privileged\n",
    "    \n",
    "    actual_positive_protected = 0\n",
    "    for i in range(len(protected_idx)):\n",
    "        if (y_test[protected_idx[i]] == 1):\n",
    "            actual_positive_protected += 1\n",
    "#             if (y_pred[protected_idx[i]][1] > y_pred[protected_idx[i]][0]):\n",
    "            del_f_i = del_f_del_theta_i(num_params, X_test[protected_idx[i]], y_pred[protected_idx[i]])\n",
    "            del_f_protected = np.add(del_f_protected, del_f_i)\n",
    "    del_f_protected /= actual_positive_protected\n",
    "\n",
    "    v = np.subtract(del_f_protected, del_f_privileged)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Computing $v=\\nabla($Predictive parity difference$)$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return v = del(Predictive_parity)/del(theta)\n",
    "def del_predictive_parity_del_theta(num_params, X_test_orig, X_test, y_pred, y_test):\n",
    "    del_f_protected = np.zeros((num_params, 1))\n",
    "    del_f_privileged = np.zeros((num_params, 1))\n",
    "    \n",
    "    protected_idx = X_test_orig[X_test_orig['age']==0].index\n",
    "    privileged_idx = X_test_orig[X_test_orig['age']==1].index\n",
    "\n",
    "    u_dash_protected = np.zeros((num_params, 1))\n",
    "    v_protected = 0\n",
    "    v_dash_protected = np.zeros((num_params, 1))\n",
    "    u_protected = 0\n",
    "    for i in range(len(protected_idx)):\n",
    "        del_f_i = del_f_del_theta_i(num_params, X_test[protected_idx[i]], y_pred[protected_idx[i]])\n",
    "#         if (y_pred[protected_idx[i]][1] > y_pred[protected_idx[i]][0]):\n",
    "        v_protected += y_pred[protected_idx[i]][1]\n",
    "        v_dash_protected = np.add(v_dash_protected, del_f_i)\n",
    "        if (y_test[protected_idx[i]] == 1):\n",
    "            u_dash_protected = np.add(u_dash_protected, del_f_i)\n",
    "            u_protected += y_pred[protected_idx[i]][1]\n",
    "    del_f_protected = (u_dash_protected * v_protected - u_protected * v_dash_protected)/(v_protected * v_protected)\n",
    "    \n",
    "    u_dash_privileged = np.zeros((num_params, 1))\n",
    "    v_privileged = 0\n",
    "    v_dash_privileged = np.zeros((num_params, 1))\n",
    "    u_privileged = 0\n",
    "    for i in range(len(privileged_idx)):\n",
    "        del_f_i = del_f_del_theta_i(num_params, X_test[privileged_idx[i]], y_pred[privileged_idx[i]])\n",
    "#         if (y_pred[privileged_idx[i]][1] > y_pred[privileged_idx[i]][0]):\n",
    "        v_privileged += y_pred[privileged_idx[i]][1]\n",
    "        v_dash_privileged = np.add(v_dash_privileged, del_f_i)\n",
    "        if (y_test[privileged_idx[i]] == 1):\n",
    "            u_dash_privileged = np.add(u_dash_privileged, del_f_i)\n",
    "            u_privileged += y_pred[privileged_idx[i]][1]\n",
    "    del_f_privileged = (u_dash_privileged * v_privileged - u_privileged * v_dash_privileged)/(v_privileged * v_privileged)\n",
    "    \n",
    "    v = np.subtract(del_f_protected, del_f_privileged)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stochastic estimation of Hessian vector product (involving del fairness): $H_{\\theta}^{-1}v = H_{\\theta}^{-1}\\nabla_{\\theta}f(z, \\theta) = v + [I - \\nabla_{\\theta}^2L(z_{s_j}, \\theta^*)]H_{\\theta}^{-1}v$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniformly sample t points from training data \n",
    "def hessian_vector_product(num_params, n, size, v, hessian_all_points):\n",
    "    if (size > n):\n",
    "        size = n\n",
    "    sample = random.sample(range(n), size)\n",
    "    hinv_v = copy.deepcopy(v)\n",
    "    for idx in range(size):\n",
    "        i = sample[idx]\n",
    "        hessian_i = hessian_all_points[i]\n",
    "        hinv_v = np.matmul(np.subtract(np.identity(num_params), hessian_i), hinv_v)\n",
    "        hinv_v = np.add(hinv_v, v)\n",
    "    return hinv_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First-order influence computation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_order_influence(del_L_del_theta, hinv_v, n):\n",
    "    infs = []\n",
    "    for i in range(n):\n",
    "        inf = -np.dot(del_L_del_theta[i].transpose(), hinv_v)\n",
    "        inf *= -1/n\n",
    "        infs.append(inf[0][0].tolist())\n",
    "    return infs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Second-order influence computation for a group of points in subset U**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_order_influence(X_train, U, size, del_L_del_theta, hessian_all_points):\n",
    "    u = len(U)\n",
    "    s = len(X_train)\n",
    "    p = u/s\n",
    "    c1 = (1 - 2*p)/(s * (1-p)**2)\n",
    "    c2 = 1/((s * (1-p))**2)\n",
    "    num_params = len(del_L_del_theta[0])\n",
    "    del_L_del_theta_hinv = np.zeros((num_params, 1))\n",
    "    del_L_del_theta_sum = np.zeros((num_params, 1))\n",
    "    hessian_U = np.zeros((num_params, num_params))\n",
    "    for i in range(u):\n",
    "        idx = U[i]\n",
    "        hessian_U = np.add(hessian_U, s * hessian_all_points[idx])\n",
    "        del_L_del_theta_sum = np.add(del_L_del_theta_sum, del_L_del_theta[idx])\n",
    "    \n",
    "    hinv_del_L_del_theta= np.matmul(hinv_exact, del_L_del_theta_sum)\n",
    "    hinv_hessian_U = np.matmul(hinv_exact, hessian_U)\n",
    "    term1 = c1 * hinv_del_L_del_theta\n",
    "    term2 = c2 * np.matmul(hinv_hessian_U, hinv_del_L_del_theta)\n",
    "    sum_term = np.add(term1, term2)\n",
    "    return sum_term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Metrics: Initial state**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial statistical parity:  -0.11218759952324076\n",
      "Initial TPR parity:  -0.08639444415122699\n",
      "Initial predictive parity:  -0.09396577739948753\n",
      "Initial loss:  0.5063649711386483\n",
      "Initial accuracy:  0.755\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "num_params = len(clf.coef_.transpose()) + 1 #weights and intercept; params: clf.coef_, clf.intercept_\n",
    "y_pred_test = clf.predict_proba(X_test)\n",
    "y_pred_train = clf.predict_proba(X_train)\n",
    "\n",
    "spd_0 = computeFairness(y_pred_test, X_test_orig, y_test, 0)\n",
    "print(\"Initial statistical parity: \", spd_0)\n",
    "\n",
    "tpr_parity_0 = computeFairness(y_pred_test, X_test_orig, y_test, 1)\n",
    "print(\"Initial TPR parity: \", tpr_parity_0)\n",
    "\n",
    "predictive_parity_0 = computeFairness(y_pred_test, X_test_orig, y_test, 2)\n",
    "print(\"Initial predictive parity: \", predictive_parity_0)\n",
    "\n",
    "loss_0 = logistic_loss(y_test, y_pred_test)\n",
    "print(\"Initial loss: \", loss_0)\n",
    "\n",
    "accuracy_0 = computeAccuracy(y_test, y_pred_test)\n",
    "print(\"Initial accuracy: \", accuracy_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-compute: (1) Hessian (2) del_L_del_theta for each training data point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_L_del_theta = []\n",
    "for i in range(int(len(X_train))):\n",
    "    del_L_del_theta.insert(i, del_L_del_theta_i(num_params, y_train[i], X_train[i], y_pred_train[i]))\n",
    "\n",
    "hessian_all_points = []\n",
    "for i in range(len(X_train)):\n",
    "    hessian_all_points.insert(i, hessian_one_point(num_params, X_train[i], y_pred_train[i])\n",
    "                              /len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Select delta fairness function depending on selected metric*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = 0\n",
    "if metric == 0:\n",
    "    v1 = del_spd_del_theta(num_params, X_test_orig, X_test, y_pred_test)\n",
    "elif metric == 1:\n",
    "    v1 = del_tpr_parity_del_theta(num_params, X_test_orig, X_test, y_pred_test, y_test)\n",
    "elif metric == 2:\n",
    "    v1 = del_predictive_parity_del_theta(num_params, X_test_orig, X_test, y_pred_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*H^{-1} computation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "hexact = 1\n",
    "if hexact == 1: \n",
    "    H_exact = np.zeros((num_params, num_params))\n",
    "    for i in range(len(X_train)):\n",
    "        H_exact = np.add(H_exact, hessian_all_points[i])\n",
    "    hinv_exact = np.linalg.pinv(H_exact) \n",
    "    hinv_v = np.matmul(hinv_exact, v1)\n",
    "else: #using Hessian vector product\n",
    "    size_hvp = int(len(X_train) * .01)\n",
    "    hinv_v = hessian_vector_product(num_params, len(X_train), size_hvp, v1, hessian_all_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First-order influence of each training data point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "infs_1 = first_order_influence(del_L_del_theta, hinv_v, len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking ground truth, first-order and second-order influences for a set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if metric == 0:\n",
    "#     print(\"Statistical parity \")\n",
    "# elif metric == 1:\n",
    "#     print(\"True positive rate parity \")\n",
    "# elif metric == 2:\n",
    "#     print(\"Predictive parity\")\n",
    "    \n",
    "# active = 1\n",
    "# if active:\n",
    "#     predicates = [ 'age']\n",
    "#     idx=X_train_orig.index \n",
    "#     for pred in predicates:\n",
    "#        idx0 = X_train_orig[(X_train_orig[pred] == 1)].index \n",
    "#        idx=idx.intersection(idx0)\n",
    "      \n",
    "#     print(\"#Rows removed: \", len(idx))\n",
    "#     print(\"#Rows left: \", len(X_train) - len(idx))\n",
    "#     X = np.delete(X_train, idx, 0)\n",
    "#     y = y_train.drop(index=idx, inplace=False)\n",
    "#     clf.fit(X, y)\n",
    "#     y_pred_test = clf.predict_proba(X_test)\n",
    "#     print(\"Ground truth influence of subset (on statistical parity): \", computeFairness(y_pred_test, X_test_orig, y_test, 0) - spd_0)\n",
    "#     print(\"Ground truth influence of subset (on tpr parity): \", computeFairness(y_pred_test, X_test_orig, y_test, 1) - tpr_parity_0)\n",
    "#     print(\"Ground truth influence of subset (on predictive parity): \", computeFairness(y_pred_test, X_test_orig, y_test, 2) - predictive_parity_0)\n",
    "\n",
    "#     del_f_1 = 0\n",
    "#     for i in range(len(idx)):\n",
    "#         del_f_1 += infs_1[idx[i]]\n",
    "#     print(\"First-order influence: \", del_f_1)\n",
    "\n",
    "#     size_hvp = 1\n",
    "#     params_f_2 = second_order_influence(X_train, idx, size_hvp, del_L_del_theta, hessian_all_points)\n",
    "#     del_f_2 = np.dot(v1.transpose(), params_f_2)[0][0]\n",
    "#     print(\"Second-order influence: \", del_f_2)\n",
    "    \n",
    "#     spd_1 = computeFairness(y_pred_test, X_test_orig, y_test, 0)\n",
    "#     print(\"Ground truth statistical parity after removing subset: \", spd_1)\n",
    "    \n",
    "#     tpr_parity_1 = computeFairness(y_pred_test, X_test_orig, y_test, 1)\n",
    "#     print(\"Ground truth tpr parity after removing subset: \", tpr_parity_1)\n",
    "\n",
    "#     predictive_parity_1 = computeFairness(y_pred_test, X_test_orig, y_test, 1)\n",
    "#     print(\"Ground truth predictive parity after removing subset: \", predictive_parity_1)\n",
    "\n",
    "#     loss_1 = logistic_loss(y_test, y_pred_test)\n",
    "#     print(\"Loss after removing subset: \", loss_1)\n",
    "\n",
    "#     accuracy_1 = computeAccuracy(y_test, y_pred_test)\n",
    "#     print(\"Accuracy after removing subset: \", accuracy_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(spd_0, tpr_parity_0, preditive_parity_0, loss_0, accuracy_0)\n",
    "# print(spd_1, tpr_parity_1, predictive_parity_1, loss_1, accuracy_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fairness: Ground-truth subset influence vs. computed subset influences: Random subset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Ground-truth subset, Add 1st-order inf individual, Second-order subset influence\")\n",
    "# sampleSize = int(.2 * len(X_train))\n",
    "# for i in range(100):\n",
    "#     idx = random.sample(range(1, len(X_train)), sampleSize) \n",
    "    \n",
    "#     # Ground truth subset influence\n",
    "#     X = np.delete(X_train, idx, 0)\n",
    "#     y = y_train.drop(index=idx, inplace=False)\n",
    "#     clf.fit(X, y)\n",
    "#     y_pred_test = clf.predict_proba(X_test)\n",
    "#     inf_gt = computeFairness(y_pred_test, X_test_orig, y_test, 0) - spd_0\n",
    "    \n",
    "#     # First-order subset influence\n",
    "#     del_f_1 = 0\n",
    "#     for i in range(len(idx)):\n",
    "#         del_f_1 += infs_1[idx[i]]\n",
    "    \n",
    "#     # Second-order subset influence\n",
    "#     size_hvp = 1\n",
    "#     params_f_2 = second_order_influence(X_train, idx, size_hvp, del_L_del_theta, hessian_all_points)\n",
    "#     del_f_2 = np.dot(v1.transpose(), params_f_2)[0][0]\n",
    "    \n",
    "# #     print(inf_gt, del_f_1, del_f_2, sep=\", \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fairness: Ground-truth subset influence vs. computed subset influences: Coherent subset** \n",
    "\n",
    "(by coherent, we mean group of data points that share some properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute, Value, Ground-truth subset, Add 1st-order inf individual, Second-order subset influence, %rowsRemoved, Accuracy\n"
     ]
    }
   ],
   "source": [
    "attributes = []\n",
    "attributeValues = []\n",
    "second_order_influences = []\n",
    "gt_influences = []\n",
    "fractionRows = []\n",
    "\n",
    "print(\"Attribute, Value, Ground-truth subset, Add 1st-order inf individual, \\\n",
    "Second-order subset influence, %rowsRemoved, Accuracy\")\n",
    "clf.fit(X_train, y_train)\n",
    "continuous_cols = ['duration', 'credit_amt', 'install_rate', 'num_credits', 'residence']\n",
    "for col in X_train_orig.columns:\n",
    "    if \"purpose\" in col or \"housing\" in col: #dummy variables purpose=0 doesn't make sense\n",
    "        vals = [1]\n",
    "    else:\n",
    "        vals = X_train_orig[col].unique()\n",
    "    for val in vals:\n",
    "#         print(col, val, sep=\": \")\n",
    "        idx = X_train_orig[X_train_orig[col] == val].index \n",
    "    \n",
    "        X = np.delete(X_train, idx, 0)\n",
    "        y = y_train.drop(index=idx, inplace=False)\n",
    "        inf_gt = 0\n",
    "        if len(y.unique()) == 1:\n",
    "            print(col, val)\n",
    "        if len(y.unique()) > 1:\n",
    "            # Ground truth subset influence\n",
    "            clf.fit(X, y)\n",
    "            y_pred = clf.predict_proba(X_test)\n",
    "            if metric == 0:\n",
    "                inf_gt = computeFairness(y_pred, X_test_orig, y_test, 0) - spd_0\n",
    "            elif metric == 1:\n",
    "                inf_gt = computeFairness(y_pred, X_test_orig, y_test, 1) - tpr_parity_0\n",
    "            elif metric == 2:\n",
    "                inf_gt = computeFairness(y_pred, X_test_orig, y_test, 2) - predictive_parity_0\n",
    "            accuracy = computeAccuracy(y_test, y_pred)\n",
    "\n",
    "        # First-order subset influence\n",
    "        del_f_1 = 0            \n",
    "        for i in range(len(idx)):\n",
    "            del_f_1 += infs_1[idx[i]]\n",
    "\n",
    "        # Second-order subset influence\n",
    "        size_hvp = 1\n",
    "        params_f_2 = second_order_influence(X_train, idx, size_hvp, del_L_del_theta, hessian_all_points)\n",
    "        del_f_2 = np.dot(v1.transpose(), params_f_2)[0][0]\n",
    "        \n",
    "        attributes.append(col)\n",
    "        attributeValues.append(val)\n",
    "        second_order_influences.append(del_f_2)\n",
    "        gt_influences.append(inf_gt)\n",
    "        fractionRows.append(len(idx)/len(X_train)*100)\n",
    "\n",
    "#         print(col, val, inf_gt, del_f_1, del_f_2, len(idx)/len(X_train), accuracy, sep=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "expl = [attributes, attributeValues, second_order_influences, gt_influences, fractionRows]\n",
    "expl = (np.array(expl).T).tolist()\n",
    "\n",
    "explanations = pd.DataFrame(expl, columns=[\"attributes\", \"attributeValues\", \"second_order_influences\", \"gt_influences\", \"fractionRows\"])\n",
    "\n",
    "explanations['attributes'] = explanations['attributes'].astype(str)\n",
    "explanations['attributeValues'] = explanations['attributeValues'].astype(int)\n",
    "explanations['second_order_influences'] = explanations['second_order_influences'].astype(float)\n",
    "explanations['gt_influences'] = explanations['gt_influences'].astype(float)\n",
    "explanations['fractionRows'] = explanations['fractionRows'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explanations.sort_values(by=\"second_order_influences\", ascending=False).head(30)\n",
    "# explanations.sort_values(by=\"fractionRows\", ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import scipy.stats as ss\n",
    "# explanations[\"gt_rank\"] = len(explanations) - ss.rankdata(explanations[\"gt_influences\"])\n",
    "# explanations[\"so_rank\"] = len(explanations) - ss.rankdata(explanations[\"second_order_influences\"])\n",
    "# stats.kendalltau(explanations[\"gt_rank\"], explanations[\"so_rank\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha_f_lower: 0.0011218759952324076\n",
      "alpha_f_upper: 0.11218759952324076\n",
      "del_f_threshold: -0.011218759952324076\n",
      "support_small: 0.3\n",
      "del_f_threshold_small: 0.011218759952324076\n"
     ]
    }
   ],
   "source": [
    "alpha_f_lower = (-0.01) * (spd_0)\n",
    "alpha_f_upper = -spd_0\n",
    "del_f_threshold = (0.1) * spd_0\n",
    "support = 0.01 # Do not consider extremely small patterns\n",
    "support_small = 0.3 # For small patterns, 2nd-order estimation is quite accurate\n",
    "del_f_threshold_small = (-0.1) * (spd_0)\n",
    "print(\"alpha_f_lower:\", alpha_f_lower)\n",
    "print(\"alpha_f_upper:\", alpha_f_upper)\n",
    "print(\"del_f_threshold:\", del_f_threshold)\n",
    "print(\"support_small:\", support_small)\n",
    "print(\"del_f_threshold_small:\", del_f_threshold_small)\n",
    "\n",
    "candidates = explanations[(explanations[\"second_order_influences\"] > alpha_f_lower) \n",
    "                           & (explanations[\"second_order_influences\"] < alpha_f_upper)]\n",
    "candidates = copy.deepcopy(explanations)\n",
    "candidates.loc[:, 'score'] = candidates.loc[:, 'second_order_influences']*100/candidates.loc[:, 'fractionRows']\n",
    "# display(candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lattice generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated:  74  1-candidates\n"
     ]
    }
   ],
   "source": [
    "# candidates_1 = []\n",
    "# for i in range(len(candidates)):\n",
    "#     candidate = []\n",
    "#     candidate_i = candidates.iloc[i]\n",
    "# #     if ((candidate_i[\"second_order_influences\"] > del_f_threshold) & \n",
    "# #         (candidate_i[\"fractionRows\"] > support)):\n",
    "#     if ((candidate_i[\"fractionRows\"] > support_small) \n",
    "# #         or\n",
    "# #        ((candidate_i[\"fractionRows\"] > support) & (candidate_i[\"second_order_influences\"] > del_f_threshold))\n",
    "#        ):\n",
    "#         attr_i = candidate_i[\"attributes\"]\n",
    "#         val_i = str(candidate_i[\"attributeValues\"])\n",
    "#         predicates = []\n",
    "#         predicates.insert(0, attr_i + '=' + str(val_i))\n",
    "#         candidate.insert(0, predicates)\n",
    "#         candidate.insert(1, candidate_i[\"fractionRows\"])\n",
    "#         candidate.insert(2, candidate_i[\"score\"])\n",
    "#         candidate.insert(3, candidate_i[\"second_order_influences\"])\n",
    "#         candidates_1.insert(i, candidate)\n",
    "# print(\"Generated: \", len(candidates_1), \" 1-candidates\")\n",
    "# candidates_1.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated:  74  1-candidates\n",
      "Generated:  293  2-candidates\n",
      "Generated:  2\n",
      "Generated: 2824   3 -candidates\n",
      "Generated:  3\n",
      "Generated: 20699   4 -candidates\n",
      "CPU times: user 8min 47s, sys: 3.73 s, total: 8min 51s\n",
      "Wall time: 9min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "candidates_all = []\n",
    "\n",
    "# Generating 1-candidates\n",
    "candidates_1 = []\n",
    "for i in range(len(candidates)):\n",
    "    candidate = []\n",
    "    candidate_i = candidates.iloc[i]\n",
    "#     if ((candidate_i[\"second_order_influences\"] > del_f_threshold) & \n",
    "#         (candidate_i[\"fractionRows\"] > support)):\n",
    "    if ((candidate_i[\"fractionRows\"] > support_small) or\n",
    "       ((candidate_i[\"fractionRows\"] > support) & (candidate_i[\"second_order_influences\"] > del_f_threshold))\n",
    "       ):\n",
    "        attr_i = candidate_i[\"attributes\"]\n",
    "        val_i = str(candidate_i[\"attributeValues\"])\n",
    "        predicates = []\n",
    "        predicates.insert(0, attr_i + '=' + str(val_i))\n",
    "        candidate.insert(0, predicates)\n",
    "        candidate.insert(1, candidate_i[\"fractionRows\"])\n",
    "        candidate.insert(2, candidate_i[\"score\"])\n",
    "        candidate.insert(3, candidate_i[\"second_order_influences\"])\n",
    "        candidates_1.insert(i, candidate)\n",
    "print(\"Generated: \", len(candidates_1), \" 1-candidates\")\n",
    "candidates_1.sort()\n",
    "# display(candidates_1)\n",
    "\n",
    "for i in range(len(candidates_1)):\n",
    "    if (float(candidates_1[i][2]) > support): # if score > top-k, keep in candidates, not otherwise\n",
    "        candidates_all.insert(len(candidates_all), candidates_1[i])\n",
    "    \n",
    "# Generating 2-candidates\n",
    "candidates_2 = []\n",
    "for i in range(len(candidates_1)):\n",
    "    attr_i = candidates_1[i][0][0].split(\"=\")[0]\n",
    "    val_i = int(candidates_1[i][0][0].split(\"=\")[1])\n",
    "    for j in range(i):\n",
    "        # merge two candidates\n",
    "        attr_j = candidates_1[j][0][0].split(\"=\")[0]\n",
    "        val_j = int(candidates_1[j][0][0].split(\"=\")[1])\n",
    "        \n",
    "        if (attr_i != attr_j):\n",
    "            idx = X_train_orig[(X_train_orig[attr_i] == val_i) &\n",
    "                              (X_train_orig[attr_j] == val_j)].index \n",
    "            \n",
    "            idx_i = X_train_orig[(X_train_orig[attr_i] == val_i)].index \n",
    "            idx_j = X_train_orig[(X_train_orig[attr_j] == val_j)].index \n",
    "            fractionRows = len(idx)/len(X_train) * 100\n",
    "            isCompact = True\n",
    "            if (len(idx) == min(len(idx_i), len(idx_j))): # pattern is not compact if intersection equals one of its parents\n",
    "                isCompact = False\n",
    "            if (fractionRows/100 > support):\n",
    "                X = np.delete(X_train, idx, 0)\n",
    "                y = y_train.drop(index=idx, inplace=False)\n",
    "\n",
    "                size_hvp = 1\n",
    "                params_f_2 = second_order_influence(X_train, idx, size_hvp, del_L_del_theta, hessian_all_points)\n",
    "                del_f_2 = np.dot(v1.transpose(), params_f_2)[0][0]\n",
    "                \n",
    "                score = del_f_2 * 100/fractionRows\n",
    "                if (((score > candidates_1[i][2]) & (score > candidates_1[j][2]) \n",
    "#                      & (del_f_2 > del_f_threshold_small)\n",
    "                    )\n",
    "                   or (fractionRows/100 > support_small)):\n",
    "                        candidate = []\n",
    "                        predicates = []\n",
    "                        predicates.insert(0, attr_i + '=' + str(val_i))\n",
    "                        predicates.insert(1, attr_j + '=' + str(val_j))\n",
    "                        candidate.insert(0, sorted(predicates, key=itemgetter(0)))                        \n",
    "                        candidate.insert(1, len(idx)*100/len(X_train))\n",
    "                        candidate.insert(2, score)\n",
    "                        candidate.insert(3, del_f_2)\n",
    "            #             print(candidate)\n",
    "                        candidates_2.insert(len(candidates_2), candidate)  \n",
    "                        if (isCompact):\n",
    "                            candidates_all.insert(len(candidates_all), candidate)\n",
    "print(\"Generated: \", len(candidates_2), \" 2-candidates\")\n",
    "candidates_2.sort()\n",
    "\n",
    "# Recursively generating the rest\n",
    "candidates_L_1 = copy.deepcopy(candidates_2)\n",
    "iter=2\n",
    "while((len(candidates_L_1) > 0) & (iter < 4)):\n",
    "    print(\"Generated: \", iter)    \n",
    "    candidates_L = []\n",
    "    for i in range(len(candidates_L_1)):\n",
    "        candidate_i = candidates_L_1[i][0]\n",
    "        for j in range(i):\n",
    "            candidate_j = candidates_L_1[j][0]\n",
    "            # if L-1 lists intersect\n",
    "            intersect_candidates = set(candidate_i).intersection(candidate_j)\n",
    "            if (len(intersect_candidates) == iter - 1):\n",
    "                setminus_i = list(set(candidate_i) - intersect_candidates)[0].split(\"=\")\n",
    "                setminus_j = list(set(candidate_j) - intersect_candidates)[0].split(\"=\")\n",
    "                attr_i = setminus_i[0]\n",
    "                val_i = int(setminus_i[1])\n",
    "                attr_j = setminus_j[0]\n",
    "                val_j = int(setminus_j[1])\n",
    "                if (attr_i != attr_j):\n",
    "                    # merge to get L list\n",
    "                    merged_candidate = list(set(candidate_i + candidate_j))\n",
    "\n",
    "                    idx_i_j = pd.Index(list(range(len(X_train_orig))))\n",
    "                    for k in range(len(intersect_candidates)):\n",
    "                        attr = list(intersect_candidates)[k].split(\"=\")[0]\n",
    "                        val = int(list(intersect_candidates)[k].split(\"=\")[1])\n",
    "                        idx_i_j = idx_i_j.intersection(X_train_orig[(X_train_orig[attr] == val)].index)\n",
    "                    \n",
    "                    idx_i = idx_i_j.intersection(X_train_orig[(X_train_orig[attr_i] == val_i)].index)\n",
    "                    idx_j = idx_i_j.intersection(X_train_orig[(X_train_orig[attr_j] == val_j)].index)                    \n",
    "                    idx = idx_i.intersection(X_train_orig[(X_train_orig[attr_j] == val_j)].index) # merged\n",
    "\n",
    "                    fractionRows = len(idx)/len(X_train) * 100\n",
    "                    isCompact = True\n",
    "                    if (len(idx) == min(len(idx_i), len(idx_j))): # pattern is not compact if intersection equals one of its parents\n",
    "                        isCompact = False\n",
    "                    if (fractionRows/100 > support):\n",
    "                        X = np.delete(X_train, idx, 0)\n",
    "                        y = y_train.drop(index=idx, inplace=False)\n",
    "\n",
    "                        size_hvp = 1\n",
    "                        params_f_2 = second_order_influence(X_train, idx, size_hvp, del_L_del_theta, hessian_all_points)\n",
    "                        del_f_2 = np.dot(v1.transpose(), params_f_2)[0][0]\n",
    "    \n",
    "                        score = del_f_2 * 100/fractionRows\n",
    "                        if (((score > candidates_L_1[i][2]) & (score > candidates_L_1[j][2]) \n",
    "#                              & (del_f_2 > del_f_threshold_small)\n",
    "                            ) or \n",
    "                           (fractionRows > support_small)):\n",
    "                            candidate = []\n",
    "                            candidate.insert(0, sorted(merged_candidate, key=itemgetter(0)))                        \n",
    "                            candidate.insert(1, fractionRows)\n",
    "                            candidate.insert(2, del_f_2*len(X_train)/len(idx))\n",
    "                            candidate.insert(3, del_f_2)\n",
    "                            if (candidate not in candidates_L):\n",
    "                                candidates_L.insert(len(candidates_L), candidate)\n",
    "                                if (isCompact):\n",
    "                                    candidates_all.insert(len(candidates_all), candidate)\n",
    "    print(\"Generated:\", len(candidates_L), \" \", str(iter+1), \"-candidates\")\n",
    "    candidates_L_1 = copy.deepcopy(candidates_L)\n",
    "    candidates_L_1.sort()\n",
    "    iter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23298\n"
     ]
    }
   ],
   "source": [
    "candidates_support_3_compact = copy.deepcopy(candidates_all)\n",
    "print(len(candidates_support_3_compact))\n",
    "candidates_df_3_compact = pd.DataFrame(candidates_support_3_compact, columns=[\"predicates\",\"support\",\"score\",\"2nd-inf\"])\n",
    "candidates_df_3_compact = candidates_df_3_compact[candidates_df_3_compact[\"support\"] < 20].sort_values(by=['2nd-inf'], ascending=False)\n",
    "# display(candidates_df_3_compact)\n",
    "# display(candidates_df_3_compact[candidates_df_3_compact[\"support\"] < 20].sort_values(by=['2nd-inf'], ascending=False).head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# candidates_df_3_compact[\"2nd-inf\"]/0.112182"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Containment-based filtering (with LSH Ensemble)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subset(X_train_orig, explanation):\n",
    "    subset = X_train_orig.copy()\n",
    "    for predicate in explanation:\n",
    "#         print(predicate)\n",
    "        attr = predicate.split(\"=\")[0].strip(' ')\n",
    "        val = int(predicate.split(\"=\")[1].strip(' '))\n",
    "        subset = subset[subset[attr]==val]\n",
    "    return subset.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasketch import MinHashLSHEnsemble, MinHash, MinHashLSH\n",
    "import json\n",
    "\n",
    "class Topk:\n",
    "    '''\n",
    "        top explanations: explanation -> (minhash, set_index, score)\n",
    "    '''\n",
    "    def __init__(self, method='lsh', init_df=X_test_orig, init_explanations=[], threshold=0.75, k=5, num_perm=128):\n",
    "        self.method = method\n",
    "        self.num_perm = num_perm\n",
    "        if method == 'lshensemble':\n",
    "#             self.index = MinHashLSHEnsemble(threshold=threshold, num_perm=num_perm)\n",
    "#             hashed_explanations = []\n",
    "#             for explanation, score in init_explanations:\n",
    "#                 s = get_subset(init_df, explanation)\n",
    "#                 m = MinHash(num_perm=num_perm)\n",
    "#                 explanation_json = json.dumps(explanation)\n",
    "#                 for d in s:\n",
    "#                     m.update(str(d).encode('utf8'))\n",
    "#                 hashed_explanations.append((explanation_json, m, len(s)))\n",
    "#             self.index.index(hashed_explanations)\n",
    "            raise NotImplementedError\n",
    "        elif method == 'lsh':\n",
    "#             self.index = MinHashLSH(threshold=threshold, num_perm=num_perm, params=[64, self.num_perm//64])\n",
    "#             for explanation, score in init_explanations:\n",
    "#                 s = get_subset(init_df, explanation)\n",
    "#                 m = MinHash(num_perm=num_perm)\n",
    "#                 explanation_json = json.dumps(explanation)\n",
    "#                 for d in s:\n",
    "#                     m.update(str(d).encode('utf8'))\n",
    "#                 self.index.insert(explanation_json, m)\n",
    "            raise NotImplementedError\n",
    "\n",
    "        self.top_explanations = dict()\n",
    "        self.k = k\n",
    "        self.threshold = threshold\n",
    "        self.min_score = -100\n",
    "        self.min_score_explanation =None\n",
    "    \n",
    "    def _update_min(self, new_explanation, new_score):\n",
    "        if len(self.top_explanations) > 0:\n",
    "            for explanation, t in self.top_explanations.items():\n",
    "                if t[2] < new_score:\n",
    "                    new_score = t[2]\n",
    "                    new_explanation = explanation\n",
    "        self.min_score = new_score\n",
    "        self.min_score_explanation = new_explanation\n",
    "        \n",
    "    def _containment(self, x, q):\n",
    "        return len(x & q)/len(q)\n",
    "            \n",
    "    def update(self, df, explanation, score):\n",
    "        if (len(self.top_explanations) < self.k) or (score > self.min_score):\n",
    "            s = get_subset(df, explanation)\n",
    "            m = MinHash(num_perm=self.num_perm)\n",
    "            explanation = json.dumps(explanation)\n",
    "            for d in s:\n",
    "                m.update(str(d).encode('utf8'))\n",
    "\n",
    "            if self.method == 'lshensemble':\n",
    "#                 q_result = set(self.index.query(m, len(s))).intersection(set(self.top_explanations.keys()))\n",
    "                raise NotImplementedError\n",
    "            elif self.method == 'lsh':\n",
    "#                 q_result = set(self.index.query(m)).intersection(set(self.top_explanations.keys()))\n",
    "                raise NotImplementedError\n",
    "            elif self.method == 'containment':\n",
    "                q_result = set()\n",
    "                for k, v in self.top_explanations.items():\n",
    "                    if self._containment(v[1], s) > self.threshold:\n",
    "#                         print(self._containment(v[1], s))\n",
    "                        q_result.add(k)\n",
    "            \n",
    "#             print(q_result)\n",
    "#             print([round(len(self.top_explanations[q][1] & s)/len(s), 3) for q in q_result])\n",
    "#             print([round(len(self.top_explanations[q][1] & s)/len(self.top_explanations[q][1] | s), 3) for q in self.top_explanations.keys()])\n",
    "\n",
    "            if len(q_result)==0:\n",
    "                if len(self.top_explanations) <= self.k-1:\n",
    "                    self._update_min(explanation, score)\n",
    "                    self.top_explanations[explanation] = (m, s, score)\n",
    "                    return 0\n",
    "#                 else:\n",
    "#                     del self.top_explanations[self.min_score_explanation]\n",
    "#                     self._update_min(explanation, score)\n",
    "#                     self.top_explanations[explanation] = (m, s, score)\n",
    "#                     return 0\n",
    "#             else:\n",
    "#                 q_scores = [self.top_explanations[explanation][2] for explanation in q_result]\n",
    "#                 if max(q_scores) < score:\n",
    "#                     for explanation in q_result:\n",
    "#                         del self.top_explanations[explanation]\n",
    "#                     self._update_min(explanation, score)\n",
    "#                     self.top_explanations[explanation] = (m, s, score)\n",
    "# #                     print('Inserted')\n",
    "#                     return 0\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsh_df = candidates_df_3_compact.sort_values(by=['score'], ascending=False).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n",
      "<ipython-input-233-3bf5669d9a0b>:50: FutureWarning: Index.__and__ operating as a set operation is deprecated, in the future this will be a logical operation matching Series.__and__.  Use index.intersection(other) instead\n",
      "  return len(x & q)/len(q)\n"
     ]
    }
   ],
   "source": [
    "topk = Topk(method='containment', threshold=0.2, k=10)\n",
    "for row_idx in range(len(lsh_df)):\n",
    "    row = lsh_df.iloc[row_idx]\n",
    "    explanation, score = row[0], row[2]\n",
    "    topk.update(X_train_orig, explanation, score)\n",
    "    if len(topk.top_explanations) == topk.k:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanations = list(topk.top_explanations.keys())\n",
    "idxs = [v[1] for v in topk.top_explanations.values()]\n",
    "supports = list()\n",
    "scores = list()\n",
    "infs = list()\n",
    "for e in explanations:\n",
    "    condition = candidates_df_3_compact.predicates.apply(lambda x: x==json.loads(e))\n",
    "    supports.append(float(candidates_df_3_compact[condition]['support']))\n",
    "    scores.append(float(candidates_df_3_compact[condition]['score']))\n",
    "    infs.append(float(candidates_df_3_compact[condition]['2nd-inf']))\n",
    "\n",
    "expl = [explanations, supports, scores, infs]\n",
    "expl = (np.array(expl).T).tolist()\n",
    "\n",
    "explanations = pd.DataFrame(expl, columns=[\"explanations\", \"support\", \"score\", \"2nd-inf\"])\n",
    "explanations['score'] = explanations['score'].astype(float)\n",
    "explanations['support'] = explanations['support'].astype(float)\n",
    "explanations['2nd-inf'] = explanations['2nd-inf'].astype(float)/(-spd_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>explanations</th>\n",
       "      <th>support</th>\n",
       "      <th>score</th>\n",
       "      <th>2nd-inf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[\"age=1\", \"gender=0\", \"num_liable=1\", \"status=0\"]</td>\n",
       "      <td>1.125</td>\n",
       "      <td>1.970344</td>\n",
       "      <td>0.197583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[\"age=1\", \"gender=0\", \"job=2\", \"savings=0\"]</td>\n",
       "      <td>1.250</td>\n",
       "      <td>1.677376</td>\n",
       "      <td>0.186894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[\"age=1\", \"credit_amt=1\", \"purpose_A42=1\"]</td>\n",
       "      <td>1.250</td>\n",
       "      <td>1.601038</td>\n",
       "      <td>0.178389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[\"age=1\", \"install_plans=1\", \"num_credits=1\", \"telephone=1\"]</td>\n",
       "      <td>1.125</td>\n",
       "      <td>1.433697</td>\n",
       "      <td>0.143769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[\"age=1\", \"employment=0\", \"num_liable=1\", \"savings=0\"]</td>\n",
       "      <td>1.375</td>\n",
       "      <td>1.376272</td>\n",
       "      <td>0.168679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[\"credit_hist=2\", \"foreign_worker=1\", \"install_rate=4\", \"purpose_A46=1\"]</td>\n",
       "      <td>1.250</td>\n",
       "      <td>1.290394</td>\n",
       "      <td>0.143776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[\"install_rate=2\", \"job=3\", \"status=1\", \"telephone=1\"]</td>\n",
       "      <td>1.250</td>\n",
       "      <td>1.128621</td>\n",
       "      <td>0.125752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[\"age=1\", \"credit_hist=2\", \"install_rate=4\", \"telephone=1\"]</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.117628</td>\n",
       "      <td>0.199243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[\"age=1\", \"debtors=0\", \"gender=0\", \"housing_A152=1\"]</td>\n",
       "      <td>3.125</td>\n",
       "      <td>1.101111</td>\n",
       "      <td>0.306716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[\"credit_amt=2\", \"duration=3\", \"foreign_worker=1\", \"residence=2\"]</td>\n",
       "      <td>1.750</td>\n",
       "      <td>1.050419</td>\n",
       "      <td>0.163853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               explanations  \\\n",
       "0                         [\"age=1\", \"gender=0\", \"num_liable=1\", \"status=0\"]   \n",
       "1                               [\"age=1\", \"gender=0\", \"job=2\", \"savings=0\"]   \n",
       "2                                [\"age=1\", \"credit_amt=1\", \"purpose_A42=1\"]   \n",
       "3              [\"age=1\", \"install_plans=1\", \"num_credits=1\", \"telephone=1\"]   \n",
       "4                    [\"age=1\", \"employment=0\", \"num_liable=1\", \"savings=0\"]   \n",
       "5  [\"credit_hist=2\", \"foreign_worker=1\", \"install_rate=4\", \"purpose_A46=1\"]   \n",
       "6                    [\"install_rate=2\", \"job=3\", \"status=1\", \"telephone=1\"]   \n",
       "7               [\"age=1\", \"credit_hist=2\", \"install_rate=4\", \"telephone=1\"]   \n",
       "8                      [\"age=1\", \"debtors=0\", \"gender=0\", \"housing_A152=1\"]   \n",
       "9         [\"credit_amt=2\", \"duration=3\", \"foreign_worker=1\", \"residence=2\"]   \n",
       "\n",
       "   support     score   2nd-inf  \n",
       "0    1.125  1.970344  0.197583  \n",
       "1    1.250  1.677376  0.186894  \n",
       "2    1.250  1.601038  0.178389  \n",
       "3    1.125  1.433697  0.143769  \n",
       "4    1.375  1.376272  0.168679  \n",
       "5    1.250  1.290394  0.143776  \n",
       "6    1.250  1.128621  0.125752  \n",
       "7    2.000  1.117628  0.199243  \n",
       "8    3.125  1.101111  0.306716  \n",
       "9    1.750  1.050419  0.163853  "
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('max_colwidth', 100)\n",
    "explanations.sort_values(by=['score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%rows 1.125\n",
      "inf-1 0.010893867659963202\n",
      "inf-2 0.011963062905397866\n",
      "inf-gt -0.1068046596953276\n"
     ]
    }
   ],
   "source": [
    "idx = X_train_orig[\n",
    "                   (X_train_orig['age']==1)\n",
    "                   & (X_train_orig['employment']==2)                \n",
    "                   & (X_train_orig['num_liable']==1)\n",
    "                   & (X_train_orig['residence']==2)\n",
    "                  ].index \n",
    "\n",
    "# print(len(idx))\n",
    "print(\"%rows\", len(idx)*100/len(X_train))\n",
    "\n",
    "del_f_1 = 0            \n",
    "for i in range(len(idx)):\n",
    "    del_f_1 += infs_1[idx[i]]\n",
    "print(\"inf-1\", del_f_1)\n",
    "            \n",
    "size_hvp = 1\n",
    "params_f_2 = second_order_influence(X_train, idx, size_hvp, del_L_del_theta, hessian_all_points)\n",
    "del_f_2 = np.dot(v1.transpose(), params_f_2)[0][0]\n",
    "print(\"inf-2\", del_f_2)\n",
    "\n",
    "df_updated = df_orig.drop(index=idx, inplace=False)\n",
    "# display(df_orig[['credit','age']].groupby(by=[\"age\"]).mean())\n",
    "# display(df_updated[['credit','age']].groupby(by=[\"age\"]).mean())\n",
    "\n",
    "X = np.delete(X_train, idx, 0)\n",
    "y = y_train.drop(index=idx, inplace=False)\n",
    "clf.fit(X, y)\n",
    "y_pred = clf.predict_proba(X_test)\n",
    "print(\"inf-gt\", computeFairness(y_pred, X_test_orig, y_test, 0)/spd_0 - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
