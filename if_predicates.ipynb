{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import copy\n",
    "import random\n",
    "import math\n",
    "from scipy import stats\n",
    "from scipy.stats import rankdata\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Markdown, display\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['age', 'workclass', 'fnlwgt', 'education', 'education.num', 'marital', 'occupation', 'relationship', 'race', 'gender', 'capgain', 'caploss', 'hours', 'country', 'income']\n",
    "df_train = pd.read_csv('adult.data', names=cols, sep=\",\")\n",
    "df_test = pd.read_csv('adult.test', names=cols, sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One-hot encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " def one_hot_encode(df):\n",
    "    df.isin(['?']).sum(axis=0)\n",
    "\n",
    "    # replace missing values (?) to nan and then drop the columns\n",
    "    df['country'] = df['country'].replace('?',np.nan)\n",
    "    df['workclass'] = df['workclass'].replace('?',np.nan)\n",
    "    df['occupation'] = df['occupation'].replace('?',np.nan)\n",
    "\n",
    "    # dropping the NaN rows now\n",
    "    df.dropna(how='any',inplace=True)\n",
    "    df['income'] = df['income'].map({'<=50K': 0, '>50K': 1}).astype(int)\n",
    "    df = pd.concat([df, pd.get_dummies(df['gender'], prefix='gender')],axis=1)\n",
    "    df = pd.concat([df, pd.get_dummies(df['race'], prefix='race')],axis=1)\n",
    "    df = pd.concat([df, pd.get_dummies(df['marital'], prefix='marital')],axis=1)\n",
    "    df = pd.concat([df, pd.get_dummies(df['workclass'], prefix='workclass')],axis=1)\n",
    "    df = pd.concat([df, pd.get_dummies(df['relationship'], prefix='relationship')],axis=1)\n",
    "    df = pd.concat([df, pd.get_dummies(df['occupation'], prefix='occupation')],axis=1)\n",
    "    \n",
    "    # process age\n",
    "    df.loc[(df['age'] >= 15) & (df['age'] <= 24) , 'age'] = 0\n",
    "    df.loc[(df['age'] >= 25) & (df['age'] <= 34) , 'age'] = 1\n",
    "    df.loc[(df['age'] >= 35) & (df['age'] <= 44) , 'age'] = 2\n",
    "    df.loc[(df['age'] >= 45) & (df['age'] <= 54) , 'age'] = 3\n",
    "    df.loc[(df['age'] >= 55) & (df['age'] <= 64) , 'age'] = 4\n",
    "    df.loc[(df['age'] >= 65) , 'age'] = 5\n",
    "\n",
    "    # process hours\n",
    "    df.loc[(df['hours'] < 40), 'hours'] = 0\n",
    "    df.loc[(df['hours'] == 40), 'hours'] = 1\n",
    "    df.loc[(df['hours'] > 40), 'hours'] = 2\n",
    "\n",
    "    df = df.drop(columns=['workclass', 'gender', 'fnlwgt', 'education', 'occupation', \\\n",
    "                      'relationship', 'marital', 'race', 'country', 'capgain', \\\n",
    "                      'caploss'])\n",
    "    return df\n",
    "\n",
    "# one-hot encoding (for regression mdoels)\n",
    "df_train = one_hot_encode(df_train)\n",
    "df_test = one_hot_encode(df_test)\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Protected, privileged**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# protected: 'gender_Female'=1\n",
    "# privileged: 'gender_Male'=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parametric Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns='income')\n",
    "y_train = df_train['income']\n",
    "\n",
    "X_test = df_test.drop(columns='income')\n",
    "y_test = df_test['income']\n",
    "\n",
    "# size=500\n",
    "# X_train = X_train[0:size]\n",
    "# y_train = y_train[0:size]\n",
    "\n",
    "X_train_orig = copy.deepcopy(X_train)\n",
    "X_test_orig = copy.deepcopy(X_test)\n",
    "\n",
    "# Scale data: regularization penalty default: ‘l2’, ‘lbfgs’ solvers support only l2 penalties. \n",
    "# Regularization makes the predictor dependent on the scale of the features.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression(random_state=0, max_iter=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute fairness metric**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeFairness(y_pred, X_test, y_test, metric): \n",
    "    fairnessMetric = 0\n",
    "    protected_idx = X_test[X_test['gender_Female']==1].index\n",
    "    numProtected = len(protected_idx)\n",
    "    privileged_idx = X_test[X_test['gender_Male']==1].index\n",
    "    numPrivileged = len(privileged_idx)\n",
    "    \n",
    "    p_protected = 0\n",
    "    for i in range(len(protected_idx)):\n",
    "        p_protected += y_pred[protected_idx[i]][1]\n",
    "    p_protected /= len(protected_idx)\n",
    "    \n",
    "    p_privileged = 0\n",
    "    for i in range(len(privileged_idx)):\n",
    "        p_privileged += y_pred[privileged_idx[i]][1]\n",
    "    p_privileged /= len(privileged_idx)\n",
    "    \n",
    "    # statistical parity difference\n",
    "    statistical_parity = p_protected - p_privileged\n",
    "    \n",
    "    # equalized odds \n",
    "    # true positive rate parity\n",
    "    # P(Y=1 | Y=1, G=0)- P(Y=1 | Y=1, G=1)\n",
    "    true_positive_protected = 0\n",
    "    actual_positive_protected = 0\n",
    "    for i in range(len(protected_idx)):\n",
    "        if (y_test[protected_idx[i]] == 1):\n",
    "            actual_positive_protected += 1\n",
    "            if (y_pred[protected_idx[i]][1] > y_pred[protected_idx[i]][0]):\n",
    "                true_positive_protected += 1\n",
    "    tpr_protected = true_positive_protected/actual_positive_protected\n",
    "    \n",
    "    true_positive_privileged = 0\n",
    "    actual_positive_privileged = 0\n",
    "    for i in range(len(privileged_idx)):\n",
    "        if (y_test[privileged_idx[i]] == 1):\n",
    "            actual_positive_privileged += 1\n",
    "            if (y_pred[privileged_idx[i]][1] > y_pred[privileged_idx[i]][0]):\n",
    "                true_positive_privileged += 1\n",
    "    tpr_privileged = true_positive_privileged/actual_positive_privileged\n",
    "    \n",
    "    tpr_parity = tpr_protected - tpr_privileged\n",
    "    \n",
    "    if (metric == 0):\n",
    "        fairnessMetric = statistical_parity\n",
    "    elif (metric == 1):\n",
    "        fairnessMetric = tpr_parity\n",
    "    \n",
    "    # false positive rate parity\n",
    "    \n",
    "    # predictive parity\n",
    "    \n",
    "    return fairnessMetric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Influence of points computed using ground truth**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ground_truth_influence(X_train, y_train, X_test, X_test_orig, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict_proba(X_test)\n",
    "    spd_0 = computeFairness(y_pred, X_test_orig, y_test, 0)\n",
    "\n",
    "    delta_spd = []\n",
    "    for i in range(len(X_train)):\n",
    "        X_removed = np.delete(X_train, i, 0)\n",
    "        y_removed = y_train.drop(index=i, inplace=False)\n",
    "        clf.fit(X_removed, y_removed)\n",
    "        y_pred = clf.predict_proba(X_test)\n",
    "        delta_spd_i = computeFairness(y_pred, X_test_orig, y_test, 0) - spd_0\n",
    "        delta_spd.append(delta_spd_i)\n",
    "    \n",
    "    return delta_spd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss function** (Log loss for logistic regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_loss(y_true, y_pred):\n",
    "    loss = 0\n",
    "    for i in range(len(y_true)):\n",
    "        if (y_pred[i][1] != 0 and y_pred[i][0] != 0):\n",
    "            loss += - y_true[i] * math.log(y_pred[i][1]) - (1 - y_true[i]) * math.log(y_pred[i][0])\n",
    "    loss /= len(y_true)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute Accuracy** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def computeAccuracy(y_true, y_pred):\n",
    "    accuracy = 0\n",
    "    for i in range(len(y_true)):\n",
    "        idx = y_true[i]\n",
    "        if (y_pred[i][idx] > y_pred[i][1 - idx]):\n",
    "            accuracy += 1\n",
    "#         accuracy += y_pred[i][idx]\n",
    "    accuracy /= len(y_true)\n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First-order derivative of loss function at z with respect to model parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_L_del_theta_i(num_params, y_true, x, y_pred):\n",
    "#     del_L_del_theta = np.ones((num_params, 1)) * ((1 - y_true) * y_pred[1] - y_true * y_pred[0])\n",
    "    del_L_del_theta = np.ones((num_params, 1)) * (- y_true + y_pred[1])\n",
    "    for j in range(1, num_params):\n",
    "            del_L_del_theta[j] *=  x[j-1]\n",
    "    return del_L_del_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hessian: Second-order partial derivative of loss function with respect to model parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hessian_one_point(num_params, x, y_pred):\n",
    "    H = np.ones((num_params, num_params)) * (y_pred[0] * y_pred[1])\n",
    "    for i in range(1, num_params):\n",
    "        for j in range(i + 1):\n",
    "            if j == 0:\n",
    "                H[i][j] *= x[i-1]\n",
    "            else:\n",
    "                H[i][j] *= x[i-1] * x[j-1] \n",
    "    i_lower = np.tril_indices(num_params, -1)\n",
    "    H.T[i_lower] = H[i_lower]     \n",
    "    return H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First-order derivative of $P(y \\mid \\textbf{x})$ with respect to model parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_f_del_theta_i(num_params, x, y_pred):\n",
    "    del_f_del_theta = np.ones((num_params, 1)) * (y_pred[0] * y_pred[1])\n",
    "    for j in range(1, num_params):\n",
    "            del_f_del_theta[j] *=  x[j-1]\n",
    "    return del_f_del_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Computing $v=\\nabla($Statistical parity difference$)$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return v = del(SPD)/del(theta)\n",
    "def del_spd_del_theta(num_params, X_test_orig, X_test, y_pred):\n",
    "    del_f_protected = np.zeros((num_params, 1))\n",
    "    del_f_privileged = np.zeros((num_params, 1))\n",
    "    numProtected = X_test_orig['gender_Female'].sum()\n",
    "    numPrivileged = X_test_orig['gender_Male'].sum()\n",
    "    for i in range(len(X_test)):\n",
    "        del_f_i = del_f_del_theta_i(num_params, X_test[i], y_pred[i])\n",
    "        if X_test_orig.iloc[i]['gender_Male'] == 1: #privileged\n",
    "            del_f_privileged = np.add(del_f_privileged, del_f_i)\n",
    "        elif X_test_orig.iloc[i]['gender_Female'] == 1:\n",
    "            del_f_protected = np.add(del_f_protected, del_f_i)\n",
    "    del_f_privileged /= numPrivileged\n",
    "    del_f_protected /= numProtected\n",
    "    v = np.subtract(del_f_protected, del_f_privileged)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Computing $v=\\nabla($TPR parity difference$)$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return v = del(TPR_parity)/del(theta)\n",
    "def del_tpr_parity_del_theta(num_params, X_test_orig, X_test, y_pred, y_test):\n",
    "    del_f_protected = np.zeros((num_params, 1))\n",
    "    del_f_privileged = np.zeros((num_params, 1))\n",
    "    \n",
    "    protected_idx = X_test_orig[X_test_orig['gender_Female']==1].index\n",
    "    privileged_idx = X_test_orig[X_test_orig['gender_Male']==1].index\n",
    "\n",
    "    actual_positive_privileged = 0\n",
    "    for i in range(len(privileged_idx)):\n",
    "        if (y_test[privileged_idx[i]] == 1):\n",
    "            actual_positive_privileged += 1\n",
    "            if (y_pred[privileged_idx[i]][1] > y_pred[privileged_idx[i]][0]):\n",
    "                del_f_i = del_f_del_theta_i(num_params, X_test[privileged_idx[i]], y_pred[privileged_idx[i]])\n",
    "                del_f_privileged = np.add(del_f_privileged, del_f_i)\n",
    "    del_f_privileged /= actual_positive_privileged\n",
    "    \n",
    "    actual_positive_protected = 0\n",
    "    for i in range(len(protected_idx)):\n",
    "        if (y_test[protected_idx[i]] == 1):\n",
    "            actual_positive_protected += 1\n",
    "            if (y_pred[protected_idx[i]][1] > y_pred[protected_idx[i]][0]):\n",
    "                del_f_i = del_f_del_theta_i(num_params, X_test[protected_idx[i]], y_pred[protected_idx[i]])\n",
    "                del_f_protected = np.add(del_f_protected, del_f_i)\n",
    "    del_f_protected /= actual_positive_protected\n",
    "\n",
    "    v = np.subtract(del_f_protected, del_f_privileged)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stochastic estimation of Hessian vector product (involving del fairness): $H_{\\theta}^{-1}v = H_{\\theta}^{-1}\\nabla_{\\theta}f(z, \\theta) = v + [I - \\nabla_{\\theta}^2L(z_{s_j}, \\theta^*)]H_{\\theta}^{-1}v$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniformly sample t points from training data \n",
    "def hessian_vector_product(num_params, n, size, v, hessian_all_points):\n",
    "    if (size > n):\n",
    "        size = n\n",
    "    sample = random.sample(range(n), size)\n",
    "    hinv_v = copy.deepcopy(v)\n",
    "    for idx in range(size):\n",
    "        i = sample[idx]\n",
    "        hessian_i = hessian_all_points[i]\n",
    "        hinv_v = np.matmul(np.subtract(np.identity(num_params), hessian_i), hinv_v)\n",
    "        hinv_v = np.add(hinv_v, v)\n",
    "    return hinv_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First-order influence computation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_order_influence(del_L_del_theta, hinv_v, n):\n",
    "    infs = []\n",
    "    for i in range(n):\n",
    "        inf = -np.dot(del_L_del_theta[i].transpose(), hinv_v)\n",
    "        inf *= -1/n\n",
    "        infs.append(inf[0][0].tolist())\n",
    "    return infs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Second-order influence computation for a group of points in subset U**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_order_influence(X_train, U, size, del_L_del_theta, hessian_all_points):\n",
    "    u = len(U)\n",
    "    s = len(X_train)\n",
    "    p = u/s\n",
    "    c1 = (1 - 2*p)/(s * (1-p)**2)\n",
    "    c2 = 1/((s * (1-p))**2)\n",
    "    num_params = len(del_L_del_theta[0])\n",
    "    del_L_del_theta_hinv = np.zeros((num_params, 1))\n",
    "    del_L_del_theta_sum = np.zeros((num_params, 1))\n",
    "    hessian_U = np.zeros((num_params, num_params))\n",
    "    for i in range(u):\n",
    "        idx = U[i]\n",
    "        hessian_U = np.add(hessian_U, s * hessian_all_points[idx])\n",
    "        del_L_del_theta_sum = np.add(del_L_del_theta_sum, del_L_del_theta[idx])\n",
    "    \n",
    "    hinv_del_L_del_theta= np.matmul(hinv_exact, del_L_del_theta_sum)\n",
    "    hinv_hessian_U = np.matmul(hinv_exact, hessian_U)\n",
    "    term1 = c1 * hinv_del_L_del_theta\n",
    "    term2 = c2 * np.matmul(hinv_hessian_U, hinv_del_L_del_theta)\n",
    "    sum_term = np.add(term1, term2)\n",
    "    return sum_term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Metrics: Initial state**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial statistical parity:  -0.20044233691822827\n",
      "Initial TPR parity:  -0.17393358242162493\n",
      "Initial loss:  0.3597551530603338\n",
      "Initial accuracy:  0.8310092961487384\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "num_params = len(clf.coef_.transpose()) + 1 #weights and intercept; params: clf.coef_, clf.intercept_\n",
    "y_pred_test = clf.predict_proba(X_test)\n",
    "y_pred_train = clf.predict_proba(X_train)\n",
    "\n",
    "\n",
    "spd_0 = computeFairness(y_pred_test, X_test_orig, y_test, 0)\n",
    "print(\"Initial statistical parity: \", spd_0)\n",
    "\n",
    "tpr_parity_0 = computeFairness(y_pred_test, X_test_orig, y_test, 1)\n",
    "print(\"Initial TPR parity: \", tpr_parity_0)\n",
    "\n",
    "loss_0 = logistic_loss(y_test, y_pred_test)\n",
    "print(\"Initial loss: \", loss_0)\n",
    "\n",
    "accuracy_0 = computeAccuracy(y_test, y_pred_test)\n",
    "print(\"Initial accuracy: \", accuracy_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-compute: (1) Hessian (2) del_L_del_theta for each training data point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_L_del_theta = []\n",
    "for i in range(int(len(X_train))):\n",
    "    del_L_del_theta.insert(i, del_L_del_theta_i(num_params, y_train[i], X_train[i], y_pred_train[i]))\n",
    "\n",
    "hessian_all_points = []\n",
    "for i in range(len(X_train)):\n",
    "    hessian_all_points.insert(i, hessian_one_point(num_params, X_train[i], y_pred_train[i])\n",
    "                              /len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*H^{-1} computation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "hexact = 1\n",
    "# v1 = del_spd_del_theta(num_params, X_test_orig, X_test, y_pred_test)\n",
    "v1 = del_tpr_parity_del_theta(num_params, X_test_orig, X_test, y_pred_test, y_test)\n",
    "if hexact == 1: \n",
    "    H_exact = np.zeros((num_params, num_params))\n",
    "    for i in range(len(X_train)):\n",
    "        H_exact = np.add(H_exact, hessian_all_points[i])\n",
    "    hinv_exact = np.linalg.pinv(H_exact) \n",
    "    hinv_v = np.matmul(hinv_exact, v1)\n",
    "else: #using Hessian vector product\n",
    "    size_hvp = int(len(X_train) * .01)\n",
    "    hinv_v = hessian_vector_product(num_params, len(X_train), size_hvp, v1, hessian_all_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ground truth influence of each training data point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth influence\n",
    "# spdgt = ground_truth_influence(X_train, y_train, X_test, X_test_orig)\n",
    "# with open('delta_spd_ground_truth_v0.txt', 'w') as filehandle:\n",
    "#     for listitem in delta_spd:\n",
    "#         filehandle.write('%s\\n' % listitem)\n",
    "gt_spd = pd.read_csv('delta_spd_ground_truth_v0.txt', names=[\"Values\"], sep=\",\")\n",
    "gt_spd = gt_spd.values.tolist()\n",
    "spdgt=[]\n",
    "for i in range(len(gt_spd)):\n",
    "    spdgt.append(gt_spd[i][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First-order influence of each training data point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "infs_1 = first_order_influence(del_L_del_theta, hinv_v, len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correlation between first-order and ground truth influences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2-D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman rank correlation between 1st order inf and ground truth inf:  0.9758993417638199\n",
      "Pearson correlation coefficient between 1st order inf and ground truth inf:  0.990548953880444\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAasAAAEGCAYAAADbk7pdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy86wFpkAAAACXBIWXMAAAsTAAALEwEAmpwYAABCMElEQVR4nO3de3xcZ3Xo/d+aPVdpdJdsOb4nUaIm3JLIgEtJwQ0QKG9C25Tk5W0gLbe3hdLLewqhNyinPQdKbxRoe9KUA+S0DSEHigskgWBC8gYnthJIjIMSOb7EsiVbsqQZjTT3WeePvUcZySNprNuM7PX9fPTRzNbez3722Nbys5+11yOqijHGGFPLfNXugDHGGLMQC1bGGGNqngUrY4wxNc+ClTHGmJpnwcoYY0zN81e7A2tRe3u7btu2rdrdMMaYNeWJJ54YUdWOxRxrwWoRtm3bRm9vb7W7YYwxa4qIHFvssXYb0BhjTM2zYGWMMabmWbAyxhhT8yxYGWOMqXkWrIwxxtQ8ywY0xlzQhvqH6NvTR2woRlNnE927uuns6qx2t8wsNrIyxlywhvqH2HvXXpLxJI3rGknGk+y9ay9D/UPV7pqZxYKVMeaC1benj3BDmEhjBPEJkcYI4YYwfXv6qt01M4sFK2PMBSs2FCMcDc/YFo6GiQ3FqtQjMxcLVsaYC1ZTZxOpRGrGtlQiRVNnU5V6ZOZiwcoYc8Hq3tVNaiJFMp5EC0oyniQ1kaJ7V3e1u2ZmsWBljLlgdXZ1svPWnUQaI8RPx4k0Rth5607LBqxBlrpujLmgdXZ1WnBaA2xkZYwxpuZVNViJyPUi8qyIHBKR28v8PCQiX/F+/riIbCv52Ue97c+KyJsWalNEPuhtUxFpL9n+OhGJiciPva8/XcFLNsYYswhVuw0oIg7weeANwACwX0R2q+ozJbu9GxhT1UtF5BbgU8DNInIFcAtwJXAR8KCIXOYdM1ebjwLfBB4q051HVPWty36RxhhjlkU1R1avBA6p6mFVzQB3AzfO2udG4Eve63uBXxAR8bbfrappVT0CHPLam7NNVf2Rqh5d6Ysyxhiz/KoZrDYCx0veD3jbyu6jqjkgBrTNc2wlbZazU0SeEpH7ROTKcjuIyPtEpFdEeoeHhyto0hhjzHKxBAt4Etiqqi8HPgv8R7mdVPUOVe1R1Z6Ojo7V7J8xxlzwqhmsTgCbS95v8raV3UdE/EATcGaeYytpcwZVjatqwnv9bSBQmoBhjDGm+qoZrPYDXSKyXUSCuAkTu2ftsxt4l/f6JmCPqqq3/RYvW3A70AXsq7DNGUSk05sHQ0ReifuZnFmWKzTGGLMsqpYNqKo5Efkg8ADgAF9Q1YMi8gmgV1V3A/8C3CUih4BR3OCDt989wDNADviAqubBTVGf3aa3/UPAh4FO4GkR+baqvgc3CP6miOSAJHCLFxCNMcbUCLHfy+eup6dHe3t7q90NY4xZU0TkCVXtWcyxlmBhjDGm5lmwMsYYU/MsWBljjKl5FqyMMcbUPAtWxhhjap4FK2OMMTXPgpUxxpiaZ8HKGGNMzbNgZYwxpuZZsDLGGFPzLFgZY4ypeRasjDHG1DwLVsYYY2qeBStjjDE1z4KVMcaYmmfByhhjTM2zYGWMMabmWbAyxhhT8yxYGWOMqXkWrIwxxtQ8C1bGGGNqnr/aHTDGGFP7hvqH6NvTR2woRlNnE927uuns6ly189vIyhhjzLyG+ofYe9dekvEkjesaScaT7L1rL0P9Q6vWBwtWxhhj5tW3p49wQ5hIYwTxCZHGCOGGMH17+latD1UNViJyvYg8KyKHROT2Mj8PichXvJ8/LiLbSn72UW/7syLypoXaFJEPettURNpLtouI/L33s6dF5OoVvGRjjFlzYkMxwtHwjG3haJjYUGzV+lC1OSsRcYDPA28ABoD9IrJbVZ8p2e3dwJiqXioitwCfAm4WkSuAW4ArgYuAB0XkMu+Yudp8FPgm8NCsrrwZ6PK+XgX8o/fdGGNq2mrMIw31DzF2YoyBAwPUt9bTvq2daFuUVCJFU2fTsp5rPtVMsHglcEhVDwOIyN3AjUBpsLoR+Lj3+l7gcyIi3va7VTUNHBGRQ157zNWmqv7I2za7HzcCX1ZVBR4TkWYR2aCqg8t6tcYYs4yK80jhhvCMeaTLrr2M4eeHKw5g8wW84jka1jUwFZsiOZHk+NPH6bi4A8fvcNXbrlqty61qsNoIHC95P8DZI5rpfVQ1JyIxoM3b/tisYzd6rxdqs5J+bARmBCsReR/wPoAtW7Ys0KQxxqycof4h7v/0/UyOTs4Y7UyOTfLInY/QfnE7ieEEAwcGOPDAAdZfup5QfeisYHTwwYM8cucj5PN56prryGVz7L1rLztv3UlnV+eMuapQfYiRIyNMjk2SGElw/R9cv6rZgJa6XiFVvQO4A6Cnp0er3B1jzAWqONqZHJsk0hwhm84y8PQAm162iTMvnGFscIzxU+MEQ0GC0SCJkQSxUzEa1zXiBBwOPHCAho4GMpMZRo6NEIgEaOxoJJfJcfrQadZduo6+PX10dnUSG3KPA4i2Rom2RtGCEj8dX9VABRUGKxHZCnSp6oMiEgH8qjqxxHOfADaXvN/kbSu3z4CI+IEm4MwCxy7U5mL6YYwxy2qx803F0U59Sz3ZdJZAKADAyWdOMnZ8DC0owUgQFWX85DiqioiQmcpQyBXIZXJMjk3iBBzyuTyk4cyxM4gjaEGZOD3BcOcw3bu6aepsIhlPEmmMTJ9/teeqihbMBhSR9+LOF/0Pb9Mm4D+W4dz7gS4R2S4iQdyEid2z9tkNvMt7fROwx5tb2g3c4mULbsdNjthXYZuz7Qbe6WUFvhqI2XyVMWYlLeW5pWJmXvv2dnLpHNl0FifgMD40js/vw+e4X47jUMgX0LxSyBWYHJ0klUiRTWVJT6ZJxVMUsgWyk1myqSyZZAYtKKmpFIV8gb137aXjkg5SEymS8SRaUJLxJKmJFN27ulfhU5qpktT1DwCvAeIAqtoPrFvqiVU1B3wQeAD4KXCPqh4UkU+IyA3ebv8CtHkJFL8P3O4dexC4BzcZ437gA6qan6tNABH5kIgM4Abbp0XkTu8c3wYOA4eAfwZ+a6nXZowx81nKc0tNnU2kEikAnIBDbDDGyJERtKBsvXor/oCfzFSGqfEpNK9owf1CQfPudwpQyBVmNlyAQqGA4zj4A37CDWGGnx9m5607iTRGiJ+OE2mMTM9nrbZKbgOmVTVTzKLzbscty5yNqn4bN1iUbvvTktcp4FfnOPYvgL+opE1v+98Df19mu+IGZGOMWRWlc0FFlT631L2rmz3/sIfRF0YJ1gdp6mwiPZlG84oTcOi4tIMXfvwChWxhwbZmK+QKtGxtoVAoTPens6uzKsFptkqC1Q9E5A+BiIi8AXfk8Z8r2y1jjDl/LXUuaGJ4gvjpOPlsHgQiDRFaNrdw8pmTZNPZxQ0nfOBzfITqQwRCgarNTc2lktuAtwPDwAHg/bijlj9eyU4ZY8z5rHtX96Lmgg4+eJCv/8nXGTkyQjadRVF8Ph/5XJ6TPz3JxPAEyfHk2bf4FuDz+/D5fTg+h2wqS8O6hqrNTc2lkpFVBPiCqv4zTFeeiABTK9kxY4w5X3V2dXLZtZex/579TAxP0NDRwI6371jw4d1H7nwEBAr5wvQcVL6QJ5fNuXNOFPAFz72KXqAuQD6dp+miJlo2tdC2uW3Vq6ovpJJg9T3gOiDhvY8A3wF+dqU6ZYwx57Oh/iGee/g51netZ+tVW0klUjz38HO0bW0DmJHS3nFJB8PPD9P3gz7iI3Ea15fMdSm40+4lm/Lndg9QROi8tJMdb9/BldddueRrWymVBKuwqhYDFaqaEJG6FeyTMcasGefyvFRx374f9OEEHDZ0b5jOBgTovbeXbDJLPpcnMZzg6BNHSU4k2fTSTagqjt8hPhTH5/fNeavvXIKVP+Rn45Ubue2O2875uldbJePFydJK5CJyDZBcuS4ZY8zacC7PS5Xui0JmKsNP9/yUA985wNEnjpLL5hg4MEA+l2fk8AjZTNZ9TkqVF558gfipOIV8gXw+jxNwltx3cQSf42PH23csua3VUMnI6neBr4rISUCATuDmleyUMcasBaXPSwFEGiNMjk1y/6fvp2Vjy1m38ZyAw4bLN5DP5t3qEii5TA7H75B4IkE2k+X4U8fJptzRVWYyM32ubCqLOII4gt/vd38bLyLrT3wC6mb+XfSSi2r61l+pBYOVqu4XkW7gcm/Ts6qaXdluGWNM7Zv9vFTiTILBnw6SjCdJTiQ58cwJUt9IseUVW9y5JYUj+44wMTpBQd1RU34qz9jxMYJ1QbLpLIVcwU1JL0PziuaVTCbj3hebL1iVBLNiZYtAJAAKwUiQS372kkU9i1UtlRay3QFs8/a/WkRQ1S+vWK+MMWaZrcTaT7Oflzr2o2PEhmKIT0hNpMilcuTzeUZfGCXS4BadTYwnyE69+P998QkFCkyNTyE+tz5fJXx+H4VM+WDjBB3CDWE3vT2ndFzS4QYugVw6x+aXb8bxO0TaImWPr0ULBisRuQu4BPgxUAz3CliwMsasCbPXfho5NsLX/+TrNG9sZsNlGxYduLp3dbP3rr1MxaYYOTrCyNERAMKNYbKpLKl4Cnxwqv8U0Y4oyXhyRqAC0IIiKtOvKzVXoAI3kOUyOUSElm0tbLh8A4f3HSbSFGHTyzbh+B1SE6lVXY9qqSoZWfUAV+js/EhjjKlxZ2XfXb6BybFJRg6PgLi38RIjCZ6+72kuftXF9NzUc1bQmm9EVnxe6uE7H2ZiZAIRwef3uQFJvLTyHCjKxPDEnJl6S7odVzp35QNB3PYKsK5rHZe++lJe9/7XzbiOSFuEq952VU09R7WQSoLVT3CTKqwSuTFmzSgdTRXniwaeHkD8ghNyl8cYPzlO25Y2wo1hBvsGZyw8WGxjz+f3MDk2ST6T5/Th05z86Ul2fWDX9D7Dzw+z7ZptHPvRMXw+H6nJFJpTChRmzCmd6/NPFSs2K+D4HXx+Hxsu3+BWWE9mp6tQ1EqNv8WqJFi1A8+IyD4gXdyoqjfMfYgxxlRXaaZecb7ICblVytu2thE/HScYChIIBUhPpokPx8lMZbj/0/dPr4Lb+9VeRo+PEoqGCEVD5DI5Th06xe4/2836rvU0dTYx+Owg0dYoqXiKXCYHCgUtLK4+3xI5AQef4yM9mSYcDRNuDK/pAFWqkmD18ZXuhDHGLLfSTL327e0cf+o4TtB9PimVcJMfmjc2k5nKEBuK4QQdIk0RJkcnp0dYAz8ZmC7smp5KM3F6guREkqnRKTZcsYFkPMnI4RFO9Z8iWB8kk8rgqDNnNt9SBaNBsik3aWIGYXppj46LO9h2zbazCuWudQs+FKyqPwCOAgHv9X7gyRXulzHGLEnpuk/R1iibX74ZESHUEEJUaFjXgM/nY+KMu+h5Q3sD+Wye+tb6GWtLKTodqLLJLD6fD8S9pZjP5XFCDlPjU4wPjpOaSLnPRi3zqMof8VPXWkc2mcVxHMQRd65KINwQpnVLK8H6ILlsjrZtbVVdJHGlVJIN+F7gfUArblbgRuCfgF9Y2a4ZY8ziFTP1wF0ryvE7tG9tZ+etOwHo/Wovh/cdJp/J09jZOJ1uXsgXOPrkUUSEuuY6BvsGySQz04VjVRVxhJFjI8QGY/gCPrLpLP6gf8XmpQKhAOsuXcfkmUmmxqbITGUIhAOEoiEKuQKBUABfm49AMEAhW1iTCRQLqeQ24AeAVwKPg7tSsIgseaVgY4xZbrMz9y679jKGnx+efl/6C/ytf/hWhvqHuP/T9xMbipFL50hPpQlFQ4SjYRAYPjKMz+ebDlLFEVNxBd50dnoa362EvhLErYwxfGiYa37pGsQnJM4kGHh6ACfokMvm3GK4E6mqreK7Gqq6UrAxxiyX2c9SJeNJnnv4uXl/gXd2ddL12i4e+cIj5NI5xCfu81GJFIFgwK0wkcnj8/vQgs4sHjvrt+CyV4MQrzQSkIwnKWQLpBIpIo0Rom1RNr1sE4PPDiLiFsI930ZSs9lKwcaY80K5On3F7Z1dnWWflwJ4+ltPU99ST/x0HBRyKbdWX3oqjRNwFyNcbB2+pdK84gQdVJVAOEBqwp2DC0fDOIEXb2uez0GqqJJgdTvwbmauFHznSnbKGGPO1ew6feD+Uo8NxcqOuvbetZdAJEAhV3BLHmUL07fyitl80yOp1QhUPqB0cOaVR9KCW+x23SXr2HnrzhkB93wfTZWqpJBtAfhn78sYY2pSaZ2+xGiCkSMjTI5NUt9ST+9Xe6dHXYkzCUaOjjA5OkkynsQf9hM/FS9f6mg1R1OzzlVcBsTxO9S11rH9mu1r/sHepagkG/AIZf7IVPXiFemRMeaCtZRis6V1+k71n0J87npN0fYoh/cdZnvP9hcTE0IOTtBx54JGq1N5XBxvqY7iQoru9BSKm8jRurmVSJP7MHMqfn6loS9GJYsv9uBWXd8BvBb4e+B/rWSnjDEXnnNZyLCczq5Odt66k4nTbg0+n+PD8TuMHB0hm87ywtMvMHJ0BCfkUMgXGDk6MudquyvCB4i7Om8gHKBtSxsN6xvwh/yEGkJE26NuBQqfj4b2BjJTGdKTaUSEi1918QU7oiqq5DbgmVmb/k5EngD+dGW6ZIy5EM2VINF7by/R1mhFo63Ork5aNrbQtqWNEz85gS/kIxQJkc/liQ/FyaVyNKxrYOTYCPnMylSZmIs/4CdYF3RX6MXNLuza2cXw0WFiJ2Kkk2lCdSGcgEO0LTojJb3npp5V7WstquQ24NUlb324I61K18FaqO3rgc8ADnCnqn5y1s9DuEuRXAOcAW5W1aPezz6Km/iRBz6kqg/M16aIbAfuBtqAJ4BbvZT824BPAye8035OVS2BxJgVVO52X7kEiVw2x5F9R+h6TdeM0dbs56dKA1hTZxP9P+zHCTkEQgHAXWywaUMTmckM8dPxs5bpWEn+kJ9AJEA4GiY9lSaXztG4rpHmDc30/GoPfXv6SHa9WBopcSZxQaWkV6qSoPPXJa9zuKWX3r7UE4uIA3weeAMwAOwXkd2q+kzJbu8GxlT1UhG5BfgUcLOIXAHcAlwJXAQ8KCKXecfM1eangL9V1btF5J+8tv/RO+YrqvrBpV6TMWZh82XmFZ8jmt732SEiTZEZo60zx89w36fuI9Icoa65jlw2N6Naeveubp6+72nCjWHGh8aZOD1BIV/AH/LTtKGJbDJ7TutGLZY/4icYCeL4HTa9dBP5bJ50Ik2oIXTWGlozKm1cYCnplarkNuDrV+jcrwQOqephABG5G7gRKA1WN/JiId17gc+J+3TyjcDdqpoGjojIIa89yrUpIj8FdgHv8Pb5ktduMVgZY1ZJ354+8rk8p/pPkUqkCEfDRNujBPTF54jiw3FOPH2CxFiCSFOE04dPs+7idSRGEwwcGCCXzqGipBIpEmcStGxq4f5P30/LxhaaOpuoa67jZN/JFwu+ivv81Jkjs2c1VogDPvHRtK6J19z2Gq687so5dy3OtV2oKemVmjNYicjvz3egqv7NEs+9EThe8n4AeNVc+6hqTkRiuLfxNgKPzTp2o/e6XJttwLiq5srsD/ArInIt8Bzwe6pa2oYxZhkNPjvI+MlxN7GgPkQ2nWX48DDNFzXz+t98PQ/f+TCHHzuMP+wn0hShkC9weN9hAMZPjrvFZB0f+XSeTC7D1NgUYyfHcByHU4dOkc/lz77Ntwop6E7AQXxCoC7AFbuuKLuQ41wu5JT0Ss03smpYtV5U138C/66qaRF5P+6oa9fsnUTkfbgFfdmyZcvq9tCY80g6kQZhej4pEAqQy+RIJ9J0dnUyNTZF88ZmIg2R6WrnefKc+MkJd2HDgpLL5dy1o2A6EOVyOXLp3BxnXTmtW1vZ3rOdfCZ/zun2pnLzBas6Vf2IiPyqqn51Bc59Athc8n4TLyY5zN5nwKtJ2ISbaDHfseW2nwGaRcTvja6m95+V7Xgn8JflOquqdwB3APT09FhtRGMWKdQQYio2NV2pPJfJoQUl1BBiqH+IU4dOuQsITqSpa66jYV0DU2NTTI1Pkc/mX5xvqoV/hQLZZJbtO7bPe6vPLN18z1m9xZsf+ugKnXs/0CUi20UkiJswsXvWPruBd3mvbwL2qKp6228RkZCX5dcF7JurTe+Y73tt4LX5DQAR2VByvhuAny7zdRpjSmy4bAPru9ZPr9AbCAVY37WehvYG9t61F3/I/T90Pp9n7MQYsZMxEqMJdyRVyZOhq6h9WzuRpgj779lf7a6c9+YbWd0PjAFREYmXbBdAVbWx/GGV8eagPgg8gJtm/gVVPSginwB6VXU38C/AXV4CxShu8MHb7x7cZIwc8AFVzQOUa9M75UeAu0Xkz4EfeW0DfEhEbvDaGQVuW8p1GWPmV6w0sb5rPeFomFQi5SZWqLuQ4OaXbebwvsNk0hlyydyMEdRKrRe1GIG6APUt9RQKBSaGJ6rdnfOeuIOOeXYQ+Yaq3rhK/VkTenp6tLe3t9rdMGbNKvec1eP/9jiN69xFEJ/74XMMPjNYG7f6yhE3zbxlUwv5XJ5IQ4Tb7rit2r2qeSLyhKou6gnnSlLXLVAZY5ZVuey3YiHaieEJTj13qnYDFRCsC+IEHWKnYgQjQa5997XV7tJ5r5IKFr+M+0DtOtxbgMtyG9AYY+DFUdbgc4OMHB4hfjq+/AsZLgefVwJKwPG5K/Q6fofrfvs6S65YBZVUsPhL4P9SVUs8MMacs/kqqQ/1D7Hn83uYHJskn8kzNT5VlfTzSgTCAYLhoDtX1VzP+q71RBojFqhWSSXB6pQFKmPMYpQrrbTnH/bQ2NFIPptnqH+IZDxJfUs9yURyuoJFrQnWBfEH/WQzWbLpLNlUdrrShFkdlQSrXhH5CvAfQLq4UVW/tlKdMsacH/r29FEoFKZLK/l8PqbiU0yOTqKqDPW5y3/ETsaq3NO5BaNBIlG3DuHU+BSpyRSBQsBq962ySoJVIzAFvLFkmwIWrIwx8zr65FFOP396epHBZCxJIV+o6eBUJH7BcRwEt4RSIBKg3qknWB+kZVOLBapVVkk24K+vRkeMMWtf6fyUE3TcrD4fCMLkmclqd68s8Ym7Om8BEDeoAkRbotS31lPXWkculZsuutu6uZW2zW3V7fQFaL5Cth9W1b8Ukc9Sfln7D61oz4wxa0rp/JQv4OO5HzznzkEJtZuGLuBzfPj8PgKRAI3rGsmlctS31nP9H1wPMH1NpQ8wX+hLzFfDfCOrYlKFPf1qjFlQcaXffC7P0f1HmTjjVXWo0UDlD/vp2NbhrqHVFKGzqxN/yE9qIjVjPsqW76gNcwYrVf1P7/uXVq87xpi1aKh/iL4f9KGqxE/HScVqM6uvyOf30dDewA0fuwFgOhiVW5nXlu+oDcuyPL0x5sJ18MGDPHLnI4wNjVHIFmr2OalS0bYov/DBX5gOQhaMap8FK2NMxWY/4NtxSQcP3/kw2XQW8UnNByqf42PrNVt54++90QLUGmPByhhTkbIP+H5uD7HTMfKZfLW7Nz8f1LfU8+Y/eLNVnFijKqkN2AG8F9hWur+q/sbKdcsYU2v69vSRz+WnH/AVnzA2NIbmajCDwstA9Pl9tGxqYesrtlLIFyxQrWGVjKy+ATwCPAjU+H+fjDErZfDZQcZPjuMP+RGfMPTsUE1l+vkcH+GmMPl0HnGEUF2IS3/2UqJtUZLxpFuE1qxZlQSrOlX9yIr3xBhT09KJNLlMjpEXRihkaqsqel1zHeHGMP6gn4Z1DZw5doaNV250aw7G3ZqDVsdvbaskWH1TRN6iqt9e8d4YY2pWJpVh9IXRanfjLKH6EJtevon0RJpQNMSGyzdw1Q1XMfz8sD0bdR6Zr4LFBO4gX4A/FJE0kMXWszLmvFVuOY8zx87wzf/+zZp8dsoJOrzk+pfw1o++9ewfXrf6/TErZ76HghtWsyPGmOqaXS6p/4f9/PBff0h2KlvtrpUnsPHKjfTctKhV0s0a41toBxH5XiXbjDFrW2m5pIGnBzh16FRtBSofhBpD+IJuLb/tO7bz5g+/2W7vXSDmuw0YBuqBdhFpwb39B+6SIRtXoW/GmFUUG4rRuK6R/h/2c/rwabcKeRX5w34CoQCN6xuJNEdIx9OkJ9M0XNrAjrfvsDT0C8x8CRbvB34XuAh4smR7HPjcCvbJGLPK/uYX/4aJUxPV7gYAjRsa6b62+6yCsubCNt+c1WeAz4jIb6vqZ1exT8aYVXDwwYN87U+/Vjtp6D4IRoJ0dnWWLShrLmyVpK7HROSdszeq6pdXoD/GmBVSzPR7/CuPk4rXWGafQOumVnb91i67vWfKqiRY7Sh5HQZ+Afe2oAUrY9aAgw8e5Duf+Q7xwXi1u3I2cVfq3XrNVt70e2+ykZSZUyXL2v926XsRaQbuXo6Ti8j1wGcAB7hTVT856+ch3KB4DXAGuFlVj3o/+yjwbtwSUB9S1Qfma1NEtnv9bgOeAG5V1cx85zBmrRrqH2L3n+9m8OBgtbsCuPNQW16+BZ/Px7qudfQ/0s/E8AQNHZYsYSqzmKrrk8D2pZ5YRBzg88AbgAFgv4jsVtVnSnZ7NzCmqpeKyC3Ap4CbReQK4BbgStwEkAdF5DLvmLna/BTwt6p6t4j8k9f2P851jqVenzGrbah/iN57ezlw3wEyU5lqdweA6Pool7/mcvLZ/PRDxp1dnbzm1tdUu2tmjamk6vp/8mK5Sh9wBXDPMpz7lcAhVT3snedu4EagNFjdCHzce30v8DkREW/73aqaBo6IyCGvPcq1KSI/BXYB7/D2+ZLX7j/OdQ5VraESncbMbah/iIfvfJhDjx4im6qR56J8cMnOS/i1z/xatXtizhOVjKz+quR1DjimqgPLcO6NwPGS9wPAq+baR1VzIhLDvY23EXhs1rHFZ7/KtdkGjKtqrsz+c51jpLQjIvI+4H0AW7ZsOZfrNGZFDPUP8Z2//Q5H9h2pdldo6mxix807bMRkVsy8wcq7VfdxVX39KvWnZqnqHcAdAD09PTbqMqvu4IMH2X/Pfk4dOkV6Mo3mq/vX8Lrfuc6Ck1k18wYrVc2LSEFEmlQ1tsznPgFsLnm/ydtWbp8BEfEDTbhJEPMdW277GaBZRPze6Kp0/7nOYUzVFNPMB58dZPSFUeKn4mSStTEPZUHKVEMltwETwAER+S5ucgUAqvqhJZ57P9DlZemdwE2YeMesfXYD7wL2AjcBe1RVRWQ38G8i8je4CRZdwD7cklBntekd832vjbu9Nr8x3zmWeG3GLNpQ/xD//rv/TvxU7aSa+0I+3vvF91pquamaSoLV17yvUkv+Ze7ND30QeAA3zfwLqnpQRD4B9KrqbuBfgLu8BIpR3OCDt989uMkYOeADqpoHKNemd8qPAHeLyJ8DP/LaZq5zGFMNj971KA9+5sFqd2OGmz55k6WWm6qThQYRIvI7XumlebddSHp6erS3t7fa3TDnmfv/5n4e/7fHq92NaR/r/Vi1u2DOMyLyhKouak2XBZcIwb1FNtttizmZMaa8R+96tGYC1XW/c50FKlNz5lsi5P/GnUPa7s0RFTXg3i4zxpyj4jNRzz/2PJnJ2kiYKKpvq+fXPvdrNi9latJ8c1Y/BAaBduCvS7ZPAE+vZKeMOZ8M9Q/R+9VejjxxhNhgjHwmX+0unaVxfSNX3WBVzk3tmm+JkGPAMWDn6nXHmPNHsfzRc488Ry6dI1/I12Sg8kf8bLtmG927uqvdFWPmtJjagMaYBQz1D7H3rr0cf+o4EyMTVV91dy7iCBt/ZqMtcmhqngUrY5bZwQcP8t2/+y4TZyYoZGs0SuEuzVHXWMf1f3C9BSpT8yxYGbMEpZUm0ok0mVSG0eOj5NK5mg5UAOIXdr7TRlRmbZgvG/AA8zz8q6ovW5EeGbNGDPUPsecf9jB2YoyJ4QkA0hPpKveqMnVtdbzlD95iD/uaNWO+kdVbve8f8L7f5X3/f1auO8asHb339jL6wijpqTQ+x0c6UfuByuf3cfnPX87bP/X2anfFmHOyUDYgIvIGVb2q5Ee3i8iTwO0r3TljqqV4ey82FMMJOqCQz+anX0+MTHBk3xFyuRyaWxulJH0BH+1b27n2PddWuyvGnLNK5qxERF6jqo96b36WyipfGLMmFTP5CoUCI0dGGB0YxfE7NG9q5syxM+7DvGsjPrkEnICDP+Tn2vdca3NUZk2qJFi9G/iCiDThVjUfA35jRXtlTJUM9Q9x/6fvZ3xonGwyi6oSjATJZXIMPjPo7lTDgUp8gqIIQqg+RKg+RLgxjBNw2HD5BpujMmvWgsFKVZ8AXu4FK1ZgXStjakJxRDU5Okk2lSWTzJDL5HD8DvlsvqaD1DQBx3Eo5AsE64Nc8upL8If8pCZS9PzqouqHGlMTFgxWIhICfgXYBvhFBABV/cSK9syYFfboXY+y/yv7ScaTRBojtGxpIdoaJTWRYmp0yr2PoNRk1YmzCDh+B5/jwx/yU99az9artpLP5ok0RrjqbVZKyaxtldwG/AYQA54Aaj/dyZgKPHrXozz0Tw+hqiCQGE0QOxUjFA29uCLvWhhJAYhbiaK+tZ5gXZCLfuYiq0hhzjuVBKtNqnr9ivfEmBU0I7sv4PDUt54il87h8/vw+X2II+Qz+TXznNQ0wU13KkB6Mk19S70FKnNeqiRY/VBEXqqqB1a8N8asgOJcVLghTCqR4vnHnyeXzgFQyBUo5Gq70kQpX9CHz/Hh8/nITLlZiX6/n/q2evwBP9GOaLW7aMyKqCRY/Rxwm4gcwb0NKIBaBQuzVvTt6SPcECafzXN432GyU9lqd+ncCIgIoYYQ6y9ZT+JMwi3nVCggCA0dDTS0N9C+vR3H79C3p89GVua8U0mwevOK98KYZVJ6u6+ps4nuXd0MPjdIbCjG6LFRsqk1FqiAuuY6Wje3kp3Ksr5rPVuv2koqkaL/0X6292ynoaNhel8tKLEhS9g1559KgtVamWY2F7jS232N6xpJxpPs+Yc9nHruFKmJFNnM2gtUABe/6mJ8Ph+XXXsZw88PTwfii195MU7AmbFvKpGiqbOpSj01ZuVUEqy+hRuwBAgD24FnAXu60NSU3q/2Mtg3yNT4FAAN6xrIZXKkp9Juht8a/G9XIBygbXMb3bu63Vt71734s2JwBghH3fm41ESKq9521RytGbN2VfJQ8EtL34vI1cBvrViPjJlDuVt8wPQSHUd7j4LP/QUvCLHBGNlM1n1Oaq0FKh9EW6Nc/vOX87r3v67sLp1dney8deeMz8SepzLnq3Nez0pVnxSRV61EZ4yZS3E5jsnRSXKZHCcOnuBH//kjsuksjt8hl86RTWdBIBgO4vgdBCGbzqL5GopU3oPG8/1cHCHaHKXzZzrpuWn+qhOdXZ0WnMwFoZIKFr9f8tYHXA2cXLEeGVNGcTmOUDSEz+cjdjpGciIJePXwSiqfJ84kEBG04D7wWysCkQChuhAFLVDfUk8+nyd2IkY+nycQCuAP+cln84SjYbp+rouem3osEBnjqWRk1VDyOoc7h/W/l3JSEWkFvoJbwuko8HZVHSuz37uAP/be/rmqfsnbfg3wRSACfBv4HVXVudoVt0bUZ4C3AFPAbar6pNdWHig+Q/aCqt6wlGszK2PgwADB+iCBUIDxM+OICBQfj5odkBS3MoX3uhY4QYcrr7uSGz9248wHlK9xmBqbYnRgFIBNL91kQcqYMiqZs/ozABGJeu8Ty3De24HvqeonReR27/1HSnfwAs/HgB7cXzlPiMhuL6j9I/Be4HHcYHU9cN887b4Z6PK+XuUdX7yVmVTVVyzDNZllUm4tqdGBUUQFJ+je8tOSKCQiqKNQqyX8HIg0Raaz9OzWnTHnrpLbgC/BXSW41Xs/ArxLVX+yhPPeCLzOe/0l4CFmBSvgTcB3VXXUO+93getF5CGgUVUf87Z/GXgbbrCaq90bgS+r+9/tx0SkWUQ2qOrgEq7BVKhcYsRcv6yH+ofY8/k9TI5NkkqkSI4nEUcQEXLZHPlcfvp1Ua1UoPD53WXeZvRHwOfz0bKpZTohxBhz7ipZRPEO4PdVdauqbgX+P2/bUqwvCRRDwPoy+2wEjpe8H/C2bfRez94+X7tztQUQFpFeEXlMRN42V4dF5H3efr3Dw8PzXpx5UTG9OhlPTj/7tPeuvQz1D5Xdv/ervYwed2+J5VI5xBEykxnEJwTDQcSpoUko3PmyQF3A7ZeXHEHJo08iwpartvCWD7/FRlPGLEElc1b1qvr94htVfUhE6hc6SEQeBMr96/yj0jfeXNOyzyycQ7tbVfWEiFwM7BGRA6r6fJn27sAL0j09PTUyE1L7iqWOIo0RgOnvc5UEGvjJAKH6EIFQgHw2jz/oJzOZIZ/J03FxhzvimkjhiEM+Xb37foG6AM2dzUSaIqQSKSZHJ8ln8uRzeZywQyASINoc5bXvea0teGjMMqgkWB0WkT/BvRUI8GvA4YUOUtXr5vqZiJwq3oYTkQ3A6TK7neDFW3oAm3Bv653wXpduP+G9nqvdE8DmcseoavH7Ye8W41XAWcHKLE5sKEbjusYZ28LRMLGh2Fm3Bzsu6SAxkiCfy7tZc/kCmXhmuujs8GF3RKsFpaBVuPUngAPtm9sp5Ao4QYf0ZJpINELzhmZe/5uvr/h2pzHm3FQSrH4D+DPga7iJDo+w9GXtdwPvAj7pff9GmX0eAP6biLR4798IfFRVR0UkLiKvxk2weCfw2QXa3Q18UETuxk2siHkBrQWYUtW0iLQDrwH+conXZko0dTZNL25YlEqkcALOdGkkX8DHM997hti/xhBHUFWmYlNkkzPLI+UyOTdNfbWfmxLwh/w0rmskVBeavhUZCAXYds226euzxAljVs68wUpEHOBrqvr6ZT7vJ4F7ROTdwDHg7d75eoD/V1Xf4wWl/wrs9475RDHZAreCxhdxU9fv877mbBc3Y/AtwCHc1PVf97b/DPA/RKSAO3/3SVV9Zpmv9YLWvau7bEmgQCTgVkLP5Rl4eoDkRBJ/yE8umyMzOU9ppNWOU343Rb59azsbX+JOcx5/6jhO0CE1kSIZT1qJI2NWgUw/jzLXDiLfA35ZVa2Us6enp0d7e3ur3Y01o1w24OP/9jg+x8fzjz1PJpUhl8rhC/rITmVXP7uvmLPhVcCMNEbIZdxbj4FIABHhyuuunB4dJkYTDPYNks/m6f75brvdZ0yFROQJVZ2/LMscKrkNmAAOeKnjk8WNqvqhxZzQXHiKt8eKQevxf3ucof4hkvEkmWQGf9hPZipDNr76VdGLafGFQmF61KaqBMIB6lvq3eDVHCE1kQLc0aHjd2jf2m4r8hqziioJVl/zvoxZtNnLd5w4eIJkLOlm+0252X7V4HN8+AN+nIBDKuEGJM0r4eYwdc11NKxrmK56bgVjjameSipYfGk1OmLOb317+sjn8pzqP0UqkXJXu83mppdmr5ZCvkBe8m7x2PYojt/BCThcseuK6fm14m0+C07GVM+cwUpEbgQ2qernvfePAx3ejz+sqveuQv/MGjHf8h2xoRgvPPWCWyYpryQnk+SSuQVaXB1aUESElotauOiKi9xAOpIgfjpuIyhjash8I6sPA7eUvA8BO4B64H8CFqwMUH6F3vv+8j4mhidw/A71LfUkRhNkU1n8AT+51MoHKvHJ9HzU9C1GL5HC5/jcNa9EUJRLd15K2+Y2N6Xe73D9H1xvAcqYGjNfsAqqammJov9fVc8AZyqpYGEuHL339jJybGR6eYu6ljqGnx9G/EL71naymay7Um8esrmVT6LwBd15KIBCoUCwLki0I4ogiE/cJe6TWepa67j6l64mO5W1uShjatx8waql9I2qfrDkbQfG4I6qDj9+mHBjmFB9iGw6y7Enj7lrNPnd0Ut6Mr1qFdGj66K0bmwlk8yQmczQ0NHAjrfvoG1rG71f7WXgJwPUt9bbUhzGrDHzBavHReS9qvrPpRtF5P3AvpXtlqk1c1VO79vTR6TJff5oanyK8cHx6dt8mckMqYkU+ezqRKrG9Y10/VwXjt8h0hg5azn4t/7hW1elH8aY5TdfsPo94D9E5B3Ak962a3Dnrt62wv0yVTZjTamAQ3w4TstFLTMqp++8ded07b8j+464I6hZVitQiSN0/VwX0dYoWlBiQ/YMuzHnkzmDlaqeBn5WRHYBxbLR31LVPavSM1M1sxMmDj12iHQiTeO6RsQnMyqnOwGHY08eKxuoVoWAP+inY3sH0dYo4NYeLC50aIw5P1TynNUewALUBWKof4j7P30/k2OT1LfUU9dSx5ljZ0hPphk9Pkp9Sz2bX7GZSFOEvh/0ET8dJxlLVqWv/rAfn99HqC5E27Y2tKDTz0ZZrT5jzi+VVLAw57niLb/B5wYZPzFOZipDw7oG4qfjvPDUCy9WOReYik3R91Af4hP8fr+b5bfKnJBDqD5EPpOn87JOdrx9B8PPD1tGnzHnMQtWF7jSW36peAoEssksiZEEEyMTM5bj0IKiBfe95pVMtgqBKujQsa1jupbf9DNRc66eZow5H1iwusCVruSbnkwTjobJTGWIDcYo5KuwwOEsTsgBdQNlpDmC4zjkMjkcx+G173mtjaCMuUBYsLrADT47SHoiTWoyRSqeIj2ZJjOZqWqgCkQCIJBL5dCC4vP52HDlBrKTWZouamLD5RtsWQ5jLjAWrNaouZ57Otc2YidjZNNZcpkcqYmUW1i2GgRQ8AV8hOvdiuetW1qJnYqRz+a55JWXWIAy5gJmwWoNKleLr/jc07n8Mu/b00d0XZSBAwPumk5VGk35Aj6CkSCI+yBxLptj40s24g/5CYQDtm6UMcaC1VpUOs8EzHjuaa5f6rNHYqnJFE9+/UmyySziiJs4sZpLdQg4AYeWTS3UN7ulJrPpLNlUlrqmOgr5ApHGiGX2GWMAC1ZrUrFqRKlwNDxn1YbZI7Hn9z3PiQMnwOf+vDTjb1UIXLLzEsYGxtyswlQGwa0h2Lq5lV0f2GUByhgzg6/aHTDnrqmzaXpV26L5qjaUjsTEJ5x67hSqiuaqsOqhD0L1Ieqb69n1W7vY1rONQq5APpdn2zXbLFAZY8qykdUa1L2rm7137QXcEdVcVRuKt/4O3H+AaHuU+tZ6hg8Pk02u/DIdTsghGA4SrAtS31pPIVcgMZogM5WhdVPr9DzUlddduXBjxpgLngWrNaizq5Odt+6cMQc1e26neOuvUCiQy+Q4+dOTq7LoIUB9Wz2Xv/ZyEqMJVJXJ0UkKhQKN6xqpb3VHVDZ6MsacCwtWa1RnV+e8yRT3f/p+zhw/Q2oiRS6Tg1VK9Nu2YxtbX7GVZDw5/TzUUlPsjTHGgtV5pjiiOvX8KVKx1MIHLBPxCY0bGtnysi0k48np25LzBVVjjKmUBavzwMEHD7L/nv1MDE+QmcqQTqbJTq38vBSAiBCMBmm+qJlNV24ifjpuxWSNMcuuKsFKRFqBrwDbgKPA21V1rMx+7wL+2Hv756r6JW/7NcAXgQjwbeB3VFXnaldEuoH/CVwN/JGq/lXJOa4HPgM4wJ2q+sllvtwVdfDBgzz42QfJ5/JMjEys2vLxjt+hZXMLrZtbrfyRMWbFVWtkdTvwPVX9pIjc7r3/SOkOXuD5GNCD+7jqEyKy2wtq/wi8F3gcN1hdD9w3T7ujwIeYtcKxiDjA54E3AAPAfu8cz6zIVS+jYqZf7//uJZvOkplcnTJJvqCPSH2EN3/kzZbJZ4xZNdUKVjcCr/Nefwl4iFnBCngT8F1VHQUQke8C14vIQ0Cjqj7mbf8ybhC6b652vVWPT4vIL846xyuBQ6p62Gvrbq+NqgWrSmr+Feel8rk8qUSKfGblh1N1rXUEwgHCdWFe+57XWqAyxqyqagWr9ao66L0eAtaX2WcjcLzk/YC3baP3evb2Sttd6ByvKrejiLwPeB/Ali1bFmh2cRaq+VcMZH0/6KOQK5CeTFPILX+aX+u2VsL1YfLpPNF1UXKpHC0bWyybzxhTNSsWrETkQaDcb7U/Kn3jzTUteymF5W5XVe8A7gDo6elZkdIP89X8A6YDmaqSGE2QnkyjSyzoJz7BCTj4/D7atrWRT+cp5AoEggFaNrbg+B0rJGuMqboVC1aqOufarSJySkQ2qOqgiGwATpfZ7QQv3tID2IR7W++E97p0+wnvdSXtzj7H5jnaWnHTy8k/O0g6kWbsxBgtF7XQvr2dqfEpTj5zkvRUGsfvcPrwaZyAw6n+U0yemSQ1kUIcwSc+Cot4iMoX8NG6qRUn4BCOhmnb1kYhW+BV73iVPRdljKk51boNuBt4F/BJ7/s3yuzzAPDfRKTFe/9G4KOqOioicRF5NW6CxTuBz55Du6X2A10ish03SN0CvGPRV3UOSuedxk+Ou4sNpnNMjEwwdmKMVCKFP+yfXjaj7/t9+EN+mi9qpmFdA5Pjk2hWEZ+c03nDjWFaLmqhbVsbbZvbprcn40kibRF7LsoYU5OqVcj2k8AbRKQfuM57j4j0iMidAF5ixX/FDSj7gU8Uky2A3wLuBA4Bz+MmV8zXbqeIDAC/D/yxiAyISKOq5oAP4gbGnwL3qOrBlb10V/GWX2IkgT/kJ9IQob6tnlQixVR8yq2ErpBNZglEAghCNp1lcnQSESHS4N4iXPAuoLi3+upa6rj6bVfT/fPd3PCxG/D5fCTjSbSg0w/xdu/qXvHrNsaYxRDVKlTeXuN6enq0t7d3UceWFpdtaG9g4swE0bYoIjI9FxUfjFNQd97ICTgEwgHiI3HIQ6Qlgj/gJxQNMT447h5XULLpLCJCXXMddc11xE/HQaH5ombC0TDt29pxAg6Rxgive//rlmWlYWOMORci8oSq9izmWKtgsYpKs/2i7VGSiSTpRBqf30d9cz25TI6GtgYyUxkK+QKC4AQdAPyOn4KvgD/gJ5PM0LKxhcb1jeRSOVKJFIVcAX/ITyFfIBwN07i+kYnTE2y9amvZyux2u88Ys5ZYsFpFpdl+HRd3cPyp44TqQ0yNTeFzfGhBad3cSqFQYPzkOPlcnnw2j6oijlAfrSfcGKb5ombWd60nNZFi5607gRczBWcEphuuYvj54TkrsxtjzFphwWoVla7wG22Nsvnlmxk+PEwuk8Pn+MhkMgwfHmbTSzdx+c9fzsEHDnLmhTME64Nc/KqLcQIOw4eHCTeGz1ryfc4lQ+bMyTTGmLXDgtUqaupscrPuvOenoq1RHL9Dx/YO4sNxJkcnyWVyDPYNEj8d54aP3QC4I7LB5wZJjiRpvqiZDZedXYuv+LoYsIrPZtlIyhhzPrBl7VdR965uUhOps7LwpmJTjL7gJjqGo2EARl8YpffeXjq7Oune1U24Psz6rvV0dnVOV7YY6h+abrs4H5aMJ2dUvyjdxxhj1ioLVquouMJvpDFC/HScSGOEnbfuZPT4KMH6IIFQABEhEAoQrA8ycMCtKlU61yU+IdIYIdwQnh49VbqPMcasVXYbcJXNlYUnyJzvS+e6isLRMLGh2DntY4wxa5WNrGrAppdsIj2ZJpvOouo+M5WeTLPpJW5VqabOJlKJmav+phIpmjqbpt9Xso8xxqxVFqxqQM+v9tC6uRWAdCINQOvmVnp+1X12bq65rtKKE5XsY4wxa5VVsFiEpVSwmMtCFSUqXefKqlIYY2rVUipYWLBahJUIVsYYc75bSrCy24DGGGNqngUrY4wxNc9S11eRzSkZY8zi2MhqlViFCWOMWTwLVqvEKkwYY8ziWbBaJbGh2HTdvyKrMGGMMZWxYLVKrMKEMcYsngWrVWIVJowxZvEsWK2SuSquWzagMcYszFLXV9FcFdeNMcbMz0ZWxhhjap4FK2OMMTXPgpUxxpiaZ8HKGGNMzbNgZYwxpubZelaLICLDwLFq92MR2oGRaneixthnUp59Lmezz+Rs5/qZbFXVjsWcyILVBUREehe78Nn5yj6T8uxzOZt9Jmdbzc/EbgMaY4ypeRasjDHG1DwLVheWO6rdgRpkn0l59rmczT6Ts63aZ2JzVsYYY2qejayMMcbUPAtWxhhjap4FqzVCRFpF5Lsi0u99b5ljv3d5+/SLyLtKtl8jIgdE5JCI/L2IyHztiki3iOwVkbSI/JdZ57heRJ712rp9Ja97IVX4XMTb75CIPC0iV5e0lReRH3tfu1f62stc47x/LiISEpGveD9/XES2lfzso972Z0XkTQu1KSLbvTYOeW0GFzpHNdTIZ3KbiAyX/N14zwpf9rxW+TP5oLdNRaS9ZPuc/47mpKr2tQa+gL8Ebvde3w58qsw+rcBh73uL97rF+9k+4NWAAPcBb56vXWAdsAP4C+C/lJzDAZ4HLgaCwFPAFRfQ5/IWbz/xjnu85DyJKn4OC/65AL8F/JP3+hbgK97rK7z9Q8B2rx1nvjaBe4BbvNf/BPzmfOe4wD+T24DPVetzqPJnchWwDTgKtJecY85/R3N92chq7bgR+JL3+kvA28rs8ybgu6o6qqpjwHeB60VkA9Coqo+p+zflyyXHl21XVU+r6n4gO+scrwQOqephVc0Ad3ttVMuqfi7e9i+r6zGg2Wun2ir5cym9pnuBX/BGkjcCd6tqWlWPAIe89sq26R2zy2sDzv58yp2jGmrlM6klq/aZAKjqj1T1aJl+nPO/IwtWa8d6VR30Xg8B68vssxE4XvJ+wNu20Xs9e3ul7VZyjmpZ7c9lvusPi0iviDwmIm9bxLUsRSV/LtP7qGoOiAFt8xw71/Y2YNxrY/a55jpHNdTKZwLwK97trntFZPNSLmqJVvMzWWo/ZrCVgmuIiDwIlFtK+I9K36iqisiyP3OwUu0u1Rr6XLaq6gkRuRjYIyIHVPX55e6PWXP+E/h3VU2LyPtxRy27qtynNceCVQ1R1evm+pmInBKRDao66A2XT5fZ7QTwupL3m4CHvO2bZm0/4b2upN3Z5yj9n2FpWyuixj6XOa9fVYvfD4vIQ7j361crWFXy51LcZ0BE/EATcGaBY8ttP4N728bv/c+7dP+5zlENNfGZqGrp9d+JOx9aLav5mSy1HzPYbcC1YzdQzGJ7F/CNMvs8ALxRRFrEzV57I/CAdzsrLiKv9u49v7Pk+EraLbUf6PIyn4K4E7CrnvlWYrU/l93AO71splcDMS+gtYhICMDLenoN8MyyXun8KvlzKb2mm4A93lzdbuAWLwtsO9CFm3hStk3vmO97bcDZn0+5c1RDTXwms+ZibgB+uszXeS5W7TNZoB9l/x3Ne8RyZZnY14pn8bQB3wP6gQeBVm97D3BnyX6/gTvxeQj49ZLtPcBPcP+n/zlerF4yV7uduPeR48C497rR+9lbgOe8tv7oAvtcBPi8t/8BoMfb/rPe+6e87++uwmdx1p8L8AngBu91GPiq9xnsAy4uOfaPvOOexcuInO/PGjfza5/X1leB0ELnqNLfj1r4TP47cND7u/F9oPsC+kw+hPu7IwecxPs3Ode/o/m+rNySMcaYmme3AY0xxtQ8C1bGGGNqngUrY4wxNc+ClTHGmJpnwcoYY0zNs2BljEdmVk3/sYhsE5EfnmMbvysidcvcry+KyE0L7znn8TdIBdXxReTTInLQ+/5xmVVt35hqstR1YzwiklDVaAX7FasUlPvZUdxnRkYW2Yez2haRLwLfVNV7yx9Vef8WOC6G+zxZXkQ+jltF/q/OtR1jVoKNrIyZh4gkvO+vE5FHxF2n6hkRqReRb4nIUyLyExG5WUQ+BFwEfF9Evl+mLfFGLT8Rdw2tm+doW0Tkc+KuD/Qg7nItxTauEZEfiMgTIvJAsTqCiDwkIn8nIr3A78w6720i8jnv9RfFXUfohyJyuDhi884dBZ4o9qvk+IdEpMd73e4FZETE8a5nv7hFWt9fcj0PiVu0tU9E/tWrEIKI7PDO/ZSI7BORhrnaMaaU1QY05kUREfmx9/qIqv7SrJ9fDbxEVY+IyK8AJ1X1FwFEpElVYyLy+8Dr5xhZ/TLwCuDlQDuwX0QeLtP2LwOX464ftB63bNMXRCQAfBa4UVWHvaDyF7jVOQCCqtpTwXVuAH4O6MYte3Ovqt7gjSxf4V3Pxyto5924ZXJ2iFtq6lER+Y73s6uAK3GrFjwKvEZE9gFfAW5W1f0i0ggk52pH3WUojAEsWBlTKln8ZT2HfSW/QA8Afy0in8K9RfdIBe3/HG717Txuodwf4C5wGZ/V9rUl+50UkT3e9suBlwDf9QYqDlBaT+0rFfQB4D9UtYA7iltoSZj5vBF4Wcl8WhNuvbgM7vUMAHj/AdiGu9TEoLrrpKGqce/nc7VjwcpMs2BlTOUmiy9U9Tlxl+J+C/DnIvI9Vf1E6c4i8kvAx7y3Cy1lPrnAz8Gtp3ZQVXcuoQ2A9Kw2F5LjxSmD8Kxjf1tVH5jRSZHXzTpHnvl/15Rtx5hSNmdlzCKIyEXAlKr+L+DTuLfxACaABgBV/bqqvsL76gUeAW725mg6cEdQ+8o0/3DJfhuA13vbnwU6RGSn14eAiFy5UtdY4ihwjfe6NCvxAeA3vduTiMhlIlI/TzvPAhtEZIe3f4O4S1CcazvmAmQjK2MW56XAp0WkAGSB3/S23wHcLyInVfX1s475OrATt/q2Ah9W1SER6S6z3y7cuaoXgL0AqprxbpX9vYg04f77/Tvcit4r6a+Ae0TkfcC3SrbfiXt770kvgWKYeZZy9/p/M/BZEYngzlddd67tmAuTpa4bY4ypeXYb0BhjTM2zYGWMMabmWbAyxhhT8yxYGWOMqXkWrIwxxtQ8C1bGGGNqngUrY4wxNe//AA4jw/ck6DpOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Spearman rank correlation between 1st order inf and ground truth inf: \", \n",
    "      stats.spearmanr(spdgt, infs_1)[0])\n",
    "print(\"Pearson correlation coefficient between 1st order inf and ground truth inf: \", \n",
    "      stats.pearsonr(spdgt, infs_1)[0])\n",
    "\n",
    "colors = (0.5,0.2,0.5)\n",
    "fig = plt.figure()\n",
    "plt.scatter(infs_1, spdgt, c=colors, alpha=0.5)\n",
    "plt.xlabel('First-order influence')\n",
    "plt.ylabel('Ground truth influence')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verification of first-order influence (implementation) on log-loss of a single point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ground_truth_influence_loss(X_train, y_train, X_test, y_test, idx):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict_proba([X_test[idx]])[0]\n",
    "    loss_0 = - y_test[idx] * math.log(y_pred[1]) - (1 - y_test[idx]) * math.log(y_pred[0])\n",
    "\n",
    "    delta_loss = []\n",
    "    for i in range(len(X_train)):\n",
    "        X_removed = np.delete(X_train, i, 0)\n",
    "        y_removed = y_train.drop(index=i, inplace=False)\n",
    "        clf.fit(X_removed, y_removed)\n",
    "        y_pred = clf.predict_proba([X_test[idx]])[0]\n",
    "        loss_i = - y_test[idx] * math.log(y_pred[1]) - (1 - y_test[idx]) * math.log(y_pred[0])\n",
    "        delta_loss_i = loss_i - loss_0\n",
    "        delta_loss.append(delta_loss_i)\n",
    "    \n",
    "    return delta_loss\n",
    "\n",
    "verify = 0\n",
    "if verify:\n",
    "    # Identify data points misclassified by the model\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict_proba(X_test)\n",
    "    for i in range(len(X_test)):\n",
    "        if (y_pred[i][y_test[i]] < y_pred[i][1 - y_test[i]]):\n",
    "            print(i)\n",
    "\n",
    "    # compute loss approximated by first-order influence for a misclassified test data point\n",
    "    ix = 203 \n",
    "    v1 = del_L_del_theta_i(num_params, y_test[ix], X_test[ix], y_pred_test[ix])\n",
    "    H_exact = np.zeros((num_params, num_params))\n",
    "    for i in range(len(X_train)):\n",
    "        H_exact = np.add(H_exact, hessian_all_points[i])\n",
    "    hinv_exact = np.linalg.pinv(H_exact) \n",
    "    hinv_v = np.matmul(hinv_exact, v1)\n",
    "\n",
    "    infs_1 = first_order_influence(del_L_del_theta, hinv_v, len(X_train))\n",
    "    delta_loss_gt = ground_truth_influence_loss(X_train, y_train, X_test, y_test, ix)\n",
    "\n",
    "    colors = (0.5,0.2,0.5)\n",
    "    # fig = plt.figure()\n",
    "    fig, ax = plt.subplots(figsize=(4,4))\n",
    "    plt.scatter(infs_1, delta_loss_gt, c=colors, alpha=0.5)\n",
    "    plt.xlabel('First-order influence')\n",
    "    plt.ylabel('Ground truth influence')\n",
    "    ax.plot((0,1), 'r--')\n",
    "    # ax.plot([0,1],[0,1], transform=ax.transAxes)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'education.num', 'hours', 'gender_Female', 'gender_Male',\n",
       "       'race_Amer-Indian-Eskimo', 'race_Asian-Pac-Islander', 'race_Black',\n",
       "       'race_Other', 'race_White', 'marital_Divorced',\n",
       "       'marital_Married-AF-spouse', 'marital_Married-civ-spouse',\n",
       "       'marital_Married-spouse-absent', 'marital_Never-married',\n",
       "       'marital_Separated', 'marital_Widowed', 'workclass_Federal-gov',\n",
       "       'workclass_Local-gov', 'workclass_Private', 'workclass_Self-emp-inc',\n",
       "       'workclass_Self-emp-not-inc', 'workclass_State-gov',\n",
       "       'workclass_Without-pay', 'relationship_Husband',\n",
       "       'relationship_Not-in-family', 'relationship_Other-relative',\n",
       "       'relationship_Own-child', 'relationship_Unmarried', 'relationship_Wife',\n",
       "       'occupation_Adm-clerical', 'occupation_Armed-Forces',\n",
       "       'occupation_Craft-repair', 'occupation_Exec-managerial',\n",
       "       'occupation_Farming-fishing', 'occupation_Handlers-cleaners',\n",
       "       'occupation_Machine-op-inspct', 'occupation_Other-service',\n",
       "       'occupation_Priv-house-serv', 'occupation_Prof-specialty',\n",
       "       'occupation_Protective-serv', 'occupation_Sales',\n",
       "       'occupation_Tech-support', 'occupation_Transport-moving'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_orig.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking ground truth, first-order and second-order influences for a set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Rows removed:  20380\n",
      "#Rows left:  9782\n",
      "Ground truth statistical parity of subset:  -0.1225835505238218\n",
      "Ground truth influence of subset (on statistical parity):  0.07785878639440647\n",
      "Ground truth tpr parity of subset:  -0.01100904749147602\n",
      "Ground truth influence of subset (on tpr parity):  0.1629245349301489\n",
      "First-order influence:  0.000545399652561193\n",
      "Second-order influence:  0.0018931003951599456\n",
      "After statistical parity:  -0.1225835505238218\n",
      "After tpr parity:  -0.01100904749147602\n",
      "After loss:  0.3789946670357515\n",
      "After accuracy:  0.8205179282868525\n"
     ]
    }
   ],
   "source": [
    "active = 1\n",
    "if active:\n",
    "    predicates = [ 'gender_Male']\n",
    "    idx=X_train_orig.index \n",
    "    for pred in predicates:\n",
    "       idx0 = X_train_orig[(X_train_orig[pred] == 1)].index \n",
    "       idx=idx.intersection(idx0)\n",
    "      \n",
    "    print(\"#Rows removed: \", len(idx))\n",
    "    print(\"#Rows left: \", len(X_train) - len(idx))\n",
    "    X = np.delete(X_train, idx, 0)\n",
    "    y = y_train.drop(index=idx, inplace=False)\n",
    "    clf.fit(X, y)\n",
    "    y_pred_test = clf.predict_proba(X_test)\n",
    "    print(\"Ground truth statistical parity of subset: \", computeFairness(y_pred_test, X_test_orig, y_test, 0))\n",
    "    print(\"Ground truth influence of subset (on statistical parity): \", computeFairness(y_pred_test, X_test_orig, y_test, 0) - spd_0)\n",
    "    \n",
    "    print(\"Ground truth tpr parity of subset: \", computeFairness(y_pred_test, X_test_orig, y_test, 1))\n",
    "    print(\"Ground truth influence of subset (on tpr parity): \", computeFairness(y_pred_test, X_test_orig, y_test, 1) - tpr_parity_0)\n",
    "\n",
    "    del_f_1 = 0\n",
    "    for i in range(len(idx)):\n",
    "        del_f_1 += infs_1[idx[i]]\n",
    "    print(\"First-order influence: \", del_f_1)\n",
    "\n",
    "    size_hvp = 1\n",
    "    params_f_2 = second_order_influence(X_train, idx, size_hvp, del_L_del_theta, hessian_all_points)\n",
    "    del_f_2 = np.dot(v1.transpose(), params_f_2)[0][0]\n",
    "    print(\"Second-order influence: \", del_f_2)\n",
    "    \n",
    "    spd_1 = computeFairness(y_pred_test, X_test_orig, y_test, 0)\n",
    "    print(\"After statistical parity: \", spd_1)\n",
    "    \n",
    "    tpr_parity_1 = computeFairness(y_pred_test, X_test_orig, y_test, 1)\n",
    "    print(\"After tpr parity: \", tpr_parity_1)\n",
    "\n",
    "    loss_1 = logistic_loss(y_test, y_pred_test)\n",
    "    print(\"After loss: \", loss_1)\n",
    "\n",
    "    accuracy_1 = computeAccuracy(y_test, y_pred_test)\n",
    "    print(\"After accuracy: \", accuracy_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.2004423369182276 0.3597551530603337 0.7697879897394229\n"
     ]
    }
   ],
   "source": [
    "print(spd_0, loss_0, accuracy_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fairness: Ground-truth subset influence vs. computed subset influences: Random subset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground-truth subset, Add 1st-order inf individual, Add ground-truth inf individual, Second-order subset influence\n"
     ]
    }
   ],
   "source": [
    "print(\"Ground-truth subset, Add 1st-order inf individual, Add ground-truth inf individual, Second-order subset influence\")\n",
    "sampleSize = int(.2 * len(X_train))\n",
    "for i in range(100):\n",
    "    idx = random.sample(range(1, len(X_train)), sampleSize) \n",
    "    \n",
    "    # Ground truth subset influence\n",
    "    X = np.delete(X_train, idx, 0)\n",
    "    y = y_train.drop(index=idx, inplace=False)\n",
    "    clf.fit(X, y)\n",
    "    y_pred_test = clf.predict_proba(X_test)\n",
    "    inf_gt = computeFairness(y_pred_test, X_test_orig, y_test, 0) - spd_0\n",
    "    \n",
    "    # First-order subset influence\n",
    "    del_f_1 = 0\n",
    "    for i in range(len(idx)):\n",
    "        del_f_1 += infs_1[idx[i]]\n",
    "    \n",
    "    # Second-order subset influence\n",
    "    size_hvp = 1\n",
    "    params_f_2 = second_order_influence(X_train, idx, size_hvp, del_L_del_theta, hessian_all_points)\n",
    "    del_f_2 = np.dot(v1.transpose(), params_f_2)[0][0]\n",
    "    \n",
    "#     print(inf_gt, del_f_1, del_f_2, sep=\", \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fairness: Ground-truth subset influence vs. computed subset influences: Coherent subset** \n",
    "\n",
    "(by coherent, we mean group of data points that share some properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute, Value, Ground-truth subset, Add 1st-order inf individual, Second-order subset influence, #rowsRemoved, Accuracy\n",
      "age, 2, -0.007453227399407347, -0.004561340921681142, -0.007000589959553, 7807, 0.8301460823373173\n",
      "age, 3, 0.026976250549081537, 0.0071221879274020634, 0.009759114869138679, 5621, 0.8314741035856573\n",
      "age, 1, -0.002909203490587209, -0.002501518018348619, -0.003203512268641094, 8041, 0.8322045152722444\n",
      "age, 0, 0.007181328545780963, 0.0031670098225457044, 0.003681382074898113, 4869, 0.8321381142098273\n",
      "age, 4, 0.008203805327275437, 3.7130736104260634e-05, -0.0006521602535437208, 2849, 0.8294156706507304\n",
      "age, 5, -0.008795013969089105, -0.0032829341468768336, -0.004192035259921015, 975, 0.8286188579017264\n",
      "education.num, 13, 0.024157870415062843, 0.002337475148891333, 0.003480169618975517, 5044, 0.8296812749003984\n",
      "education.num, 9, 0.006045179764556208, 0.0008135813673282421, 0.001334704723881855, 9840, 0.8305444887118194\n",
      "education.num, 7, 0.0011589974243867984, -0.00017908852751208828, -0.00017292154910017042, 1048, 0.8312749003984063\n",
      "education.num, 14, -0.001136148781224755, 0.00012997643148317936, 0.00037399871580437216, 1627, 0.8307436918990704\n",
      "education.num, 5, 0.00031816735602929747, -0.0001485596376160031, -0.00014232739034567194, 455, 0.8314077025232404\n",
      "education.num, 10, 0.005295173052767332, 0.00010412020657717088, 7.149722418130107e-05, 6678, 0.8318725099601594\n",
      "education.num, 12, -0.00022734399946072736, -0.0012852181080157698, -0.001316963038188299, 1008, 0.8306772908366534\n",
      "education.num, 4, 0.003704336272620956, 0.0004675881658873283, 0.00047195501987073166, 557, 0.8310092961487384\n",
      "education.num, 16, -0.004113326985218602, -0.0004909255981198, -0.00047630218171802063, 375, 0.8308100929614873\n",
      "education.num, 11, -0.003499840916321939, -0.0027405275116027736, -0.002907389100937686, 1307, 0.8311420982735723\n",
      "education.num, 15, 0.007613167901540707, 0.0004523049599181904, 0.0006126092677693183, 542, 0.8315405046480744\n",
      "education.num, 3, -0.0017953321364452268, -0.0005275374277894744, -0.0005325910752750816, 288, 0.8317397078353254\n",
      "education.num, 6, 0.006136003121124667, 0.0006977410686593088, 0.0007074829118119231, 820, 0.8320053120849934\n",
      "education.num, 1, 0.0, 3.126885010584351e-05, 3.170259419944941e-05, 45, 0.8310092961487384\n",
      "education.num, 8, -0.00031816735602918644, 0.0002075627687053004, 0.00020644148851926974, 377, 0.8316069057104913\n",
      "education.num, 2, -0.00390883162891964, 0.00011077324224543436, 0.00010903815320453179, 151, 0.8314077025232404\n",
      "hours, 1, 0.04799757347409628, 0.0062604288039281464, 0.013290884370639805, 14251, 0.8306772908366534\n",
      "hours, 0, -0.03190698774341649, -0.011435837906120969, -0.015525550259687876, 6714, 0.8296148738379814\n",
      "hours, 2, -0.02211291685207384, 0.005155944501338173, 0.0038194126238460394, 9197, 0.8282204515272245\n",
      "gender_Female, 1, 0.18914620903880908, -0.0005648642534157585, -0.0008824687107138809, 9782, 0.8237715803452855\n",
      "gender_Male, 1, 0.1629245349301489, 0.000545399652561193, 0.0018931003951599456, 20380, 0.8205179282868525\n",
      "race_Amer-Indian-Eskimo, 1, 0.00211349949247458, -0.0004678895102328362, -0.00047384910162570366, 286, 0.8310756972111554\n",
      "race_Asian-Pac-Islander, 1, -0.0013863414238473593, -0.0005263956821446861, -0.0005363049213010948, 895, 0.8312084993359894\n",
      "race_Black, 1, 0.006136003121124667, 0.00387591151540029, 0.004166179582012109, 2817, 0.8312749003984063\n",
      "race_Other, 1, -0.0038180082723512365, -0.0001650151135464672, -0.00016714947991255578, 231, 0.8308764940239044\n",
      "race_White, 1, -0.05492756694509637, -0.002736075810330897, -0.020692400192797118, 25933, 0.8272244355909695\n",
      "marital_Divorced, 1, 0.01645330794087463, -0.0003205804210533788, -0.00024236803626794676, 4214, 0.8294820717131474\n",
      "marital_Married-AF-spouse, 1, -0.0035906642728904536, -0.00032100055205141223, -0.00032381209385375537, 21, 0.8308764940239044\n",
      "marital_Married-civ-spouse, 1, 0.2959464793382577, 0.00046820259080641944, 0.0020077149362841946, 14065, 0.7680610889774236\n",
      "marital_Married-spouse-absent, 1, 0.0005226627123282035, -0.00014800066236693871, -0.00015030303863577526, 370, 0.8313413014608234\n",
      "marital_Never-married, 1, 0.006362775904506401, -0.0002950705849875863, -0.0006144554415817261, 9726, 0.8230411686586986\n",
      "marital_Separated, 1, -0.002022676135905954, 8.595674599163704e-05, 8.969098220945913e-05, 939, 0.8311420982735723\n",
      "marital_Widowed, 1, 0.008658493326197059, 0.0005110282828067054, 0.0005428954297933083, 827, 0.8315405046480744\n",
      "workclass_Federal-gov, 1, 0.011772192173083118, 0.0009413723644640648, 0.0010313873877629835, 943, 0.8304780876494023\n",
      "workclass_Local-gov, 1, 0.004772510340439129, -0.0019454025273059582, -0.001458463842950334, 2067, 0.8316069057104913\n",
      "workclass_Private, 1, 0.07020017125058053, 0.006948754689291812, 0.03154734820872521, 22286, 0.8297476759628154\n",
      "workclass_Self-emp-inc, 1, 0.009431348681147866, 0.0004213954441423237, 0.0004295775732095097, 1074, 0.8313413014608234\n",
      "workclass_Self-emp-not-inc, 1, -0.011022185461294076, -0.005017242779168457, -0.005536632291251646, 2499, 0.8278884462151395\n",
      "workclass_State-gov, 1, -0.005613340408796463, -0.0013683409399650596, -0.0014734530854894161, 1279, 0.8317397078353254\n",
      "workclass_Without-pay, 1, -0.00031816735602918644, -8.523133552989651e-10, 1.0848501963855323e-09, 14, 0.8309428950863214\n",
      "relationship_Husband, 1, -0.029680387467290625, 0.00037115615188446115, 0.0011597101224033529, 12463, 0.8278220451527224\n",
      "relationship_Not-in-family, 1, 0.0012955180672790112, -0.0003273340517566312, -0.0005705023628141329, 7726, 0.8317397078353254\n",
      "relationship_Other-relative, 1, 0.00031816735602929747, -0.0001225032650038297, -9.547434190749235e-05, 889, 0.8314077025232404\n",
      "relationship_Own-child, 1, -0.0042269989849489376, -0.0003317726534826106, -0.00044377887046278457, 4466, 0.8312749003984063\n",
      "relationship_Unmarried, 1, 0.011953838886220092, 0.0004338061067102675, 0.0005069705424842299, 3212, 0.8311420982735723\n",
      "relationship_Wife, 1, -0.2879802998998658, -4.281688920623941e-05, -5.676119414267977e-06, 1406, 0.8264940239043824\n",
      "occupation_Adm-clerical, 1, -0.018680479433079433, -0.005764393630004226, -0.007657624586630567, 3721, 0.8316733067729084\n",
      "occupation_Armed-Forces, 1, -0.0006363347120584839, 2.1035049660999143e-05, 2.114711177729486e-05, 9, 0.8311420982735723\n",
      "occupation_Craft-repair, 1, 0.0057041637653650334, -0.00014342755067230168, -0.00022852614125112283, 4030, 0.8308764940239044\n",
      "occupation_Exec-managerial, 1, 0.03372631095518186, 0.0031696664282016584, 0.0036354628797744463, 3992, 0.8258964143426295\n",
      "occupation_Farming-fishing, 1, 0.00020449535629901705, 0.0006172579636785695, 0.0006200621137173082, 989, 0.8292828685258964\n",
      "occupation_Handlers-cleaners, 1, -0.0004318393557595779, -0.0001067185929898429, -0.00011036692737237569, 1350, 0.8310756972111554\n",
      "occupation_Machine-op-inspct, 1, 0.003908831628919807, 0.0016867786497300646, 0.0017759678695880355, 1966, 0.8314077025232404\n",
      "occupation_Other-service, 1, -0.00222717149220486, -0.0009494978843654229, -0.0010925823456608317, 3212, 0.8294156706507304\n",
      "occupation_Priv-house-serv, 1, 0.0032724969168613227, 0.00011006752575419094, 0.00010966344019056336, 143, 0.8306772908366534\n",
      "occupation_Prof-specialty, 1, -0.023634065270576432, -0.0038331608805992675, -0.004402696464679664, 4038, 0.8284196547144754\n",
      "occupation_Protective-serv, 1, 0.009954011393476014, 1.9539469906558373e-06, 9.330384683671923e-06, 644, 0.8316733067729084\n",
      "occupation_Sales, 1, 0.0229988729906761, 0.005836581339600306, 0.006724048204293831, 3584, 0.8304116865869854\n",
      "occupation_Tech-support, 1, 0.004477191627571764, -0.00030379640037924013, -0.0003243723340730043, 912, 0.8311420982735723\n",
      "occupation_Transport-moving, 1, 0.0015908367801463763, -0.00036181056546065725, -0.00035906462947903403, 1572, 0.8303452855245684\n"
     ]
    }
   ],
   "source": [
    "print(\"Attribute, Value, Ground-truth subset, Add 1st-order inf individual, \\\n",
    "Second-order subset influence, #rowsRemoved, Accuracy\")\n",
    "clf.fit(X_train, y_train)\n",
    "continuous_cols = ['age', 'education.num', 'hours',]\n",
    "for col in X_train_orig.columns:\n",
    "    if col in continuous_cols:\n",
    "        vals = X_train_orig[col].unique()\n",
    "    else:\n",
    "        vals = [1]\n",
    "    for val in vals:\n",
    "#         print(col, val, sep=\": \")\n",
    "        idx = X_train_orig[X_train_orig[col] == val].index \n",
    "    \n",
    "        X = np.delete(X_train, idx, 0)\n",
    "        y = y_train.drop(index=idx, inplace=False)\n",
    "        inf_gt = 0\n",
    "        if len(y.unique()) > 1:\n",
    "            # Ground truth subset influence\n",
    "            clf.fit(X, y)\n",
    "            y_pred = clf.predict_proba(X_test)\n",
    "#             inf_gt = computeFairness(y_pred, X_test_orig, y_test, 0) - spd_0\n",
    "            inf_gt = computeFairness(y_pred, X_test_orig, y_test, 1) - tpr_parity_0\n",
    "            accuracy = computeAccuracy(y_test, y_pred)\n",
    "\n",
    "        # First-order subset influence\n",
    "        del_f_1 = 0            \n",
    "        for i in range(len(idx)):\n",
    "            del_f_1 += infs_1[idx[i]]\n",
    "\n",
    "        # Second-order subset influence\n",
    "        size_hvp = 1\n",
    "        params_f_2 = second_order_influence(X_train, idx, size_hvp, del_L_del_theta, hessian_all_points)\n",
    "        del_f_2 = np.dot(v1.transpose(), params_f_2)[0][0]\n",
    "\n",
    "        print(col, val, inf_gt, del_f_1, del_f_2, len(idx), accuracy, sep=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['age', 'workclass', 'fnlwgt', 'education', 'education.num', 'marital', 'occupation', 'relationship', 'race', 'gender', 'capgain', 'caploss', 'hours', 'country', 'income']\n",
    "df_train = pd.read_csv('adult.data', names=cols, sep=\",\")\n",
    "df_test = pd.read_csv('adult.test', names=cols, sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Space Partitioner for reducing bias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['age', 'workclass', 'fnlwgt', 'education', 'education.num', 'marital', 'occupation', 'relationship', 'race', 'gender', 'capgain', 'caploss', 'hours', 'country', 'income']\n",
    "df_train = pd.read_csv('adult.data', names=cols, sep=\",\")\n",
    "df_test = pd.read_csv('adult.test', names=cols, sep=\",\")\n",
    "\n",
    "def preprocess(df):\n",
    "    df.isin(['?']).sum(axis=0)\n",
    "\n",
    "    # replace missing values (?) to nan and then drop the columns\n",
    "    df['country'] = df['country'].replace('?',np.nan)\n",
    "    df['workclass'] = df['workclass'].replace('?',np.nan)\n",
    "    df['occupation'] = df['occupation'].replace('?',np.nan)\n",
    "\n",
    "    df.loc[(df['age'] >= 15) & (df['age'] <= 24) , 'age'] = 0\n",
    "    df.loc[(df['age'] >= 25) & (df['age'] <= 34) , 'age'] = 1\n",
    "    df.loc[(df['age'] >= 35) & (df['age'] <= 44) , 'age'] = 2\n",
    "    df.loc[(df['age'] >= 45) & (df['age'] <= 54) , 'age'] = 3\n",
    "    df.loc[(df['age'] >= 55) & (df['age'] <= 64) , 'age'] = 4\n",
    "    df.loc[(df['age'] >= 65) , 'age'] = 5\n",
    "\n",
    "    df.loc[(df['hours'] < 40), 'hours'] = 0\n",
    "    df.loc[(df['hours'] == 40), 'hours'] = 1\n",
    "    df.loc[(df['hours'] > 40), 'hours'] = 2\n",
    "    \n",
    "    # dropping the NaN rows now\n",
    "    df.dropna(how='any',inplace=True)\n",
    "    df['income'] = df['income'].map({'<=50K': 0, '>50K': 1}).astype(int)\n",
    "    df = df.drop(columns=['fnlwgt', 'education.num', 'country', 'capgain', 'caploss'])\n",
    "    return df\n",
    "\n",
    "df_train = preprocess(df_train)\n",
    "df_test = preprocess(df_test)\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "X_train_ = df_train.drop(columns='income')\n",
    "y_train_ = df_train['income']\n",
    "\n",
    "X_test_ = df_test.drop(columns='income')\n",
    "y_test_ = df_test['income']\n",
    "\n",
    "# size=2000\n",
    "# X_train = X_train[0:size]\n",
    "# y_train = y_train[0:size]\n",
    "\n",
    "# X_train_ = X_train_[0:size]\n",
    "# y_train_ = y_train_[0:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root:  {'splitCol': 'workclass', 'predCols': [], 'predVals': [], 'numRows': 30162}\n",
      "Depth:  1\n",
      "Depth:  2\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  2\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  2\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  2\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  2\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  2\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  2\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n",
      "Depth:  3\n"
     ]
    }
   ],
   "source": [
    "def computeFairness(y_pred, X_test): \n",
    "    protected_idx = X_test[X_test['gender']=='Female'].index\n",
    "    numProtected = len(protected_idx)\n",
    "    privileged_idx = X_test[X_test['gender']=='Male'].index\n",
    "    numPrivileged = len(privileged_idx)\n",
    "    \n",
    "    p_protected = 0\n",
    "    for i in range(len(protected_idx)):\n",
    "        p_protected += y_pred[protected_idx[i]][1]\n",
    "    p_protected /= len(protected_idx)\n",
    "    \n",
    "    p_privileged = 0\n",
    "    for i in range(len(privileged_idx)):\n",
    "        p_privileged += y_pred[privileged_idx[i]][1]\n",
    "    p_privileged /= len(privileged_idx)\n",
    "    \n",
    "    spd = p_protected - p_privileged\n",
    "    return spd\n",
    "\n",
    "def getInfluenceOfSet(indices, f, X_train, y_train, X_test, X_test_, method): \n",
    "    del_f = 0\n",
    "    if (method == 1):\n",
    "        X = X_train.drop(index=indices, inplace=False)\n",
    "        y = y_train.drop(index=indices, inplace=False)\n",
    "        if len(y.unique()) < 2:\n",
    "            return 0\n",
    "        clf.fit(X, y)\n",
    "        y_pred = clf.predict_proba(X_test)\n",
    "        del_f = computeFairness(y_pred, X_test_)\n",
    "    elif (method == 2):\n",
    "        for i in range(len(indices)):\n",
    "            del_f += infs_1[indices[i]]\n",
    "    elif (method == 3):\n",
    "        size_hvp = 1\n",
    "        params_f_2 = second_order_influence(X_train, indices, size_hvp, del_L_del_theta, hessian_all_points)\n",
    "        del_f = np.dot(v1.transpose(), params_f_2)[0][0]\n",
    "    return  del_f\n",
    "\n",
    "def getSplitVal(infs):\n",
    "    score = np.Inf\n",
    "    splitColIdx = -1\n",
    "    for i in range(len(infs)):\n",
    "        for j in range(len(infs[i])):\n",
    "            if (abs(infs[i][j]) < score):\n",
    "                splitColIdx = i\n",
    "                score = abs(infs[i][j])\n",
    "    return splitColIdx\n",
    "\n",
    "def getSplitAttribute(cols, predCols, predVals, \n",
    "                      X_train, y_train, X_test, X_train_, X_test_, method):\n",
    "    splitCol, numRows, score, idx = None, len(X_train_), abs(spd_0), []\n",
    "    X_ = copy.deepcopy(X_train_)\n",
    "    \n",
    "    if len(predCols) > 0:\n",
    "        for i in range(len(predCols)):\n",
    "            pred = predCols[i]\n",
    "            val = predVals[i]\n",
    "            idx = X_[X_[pred] == val].index \n",
    "            X_ = X_[X_[pred] == val]\n",
    "    \n",
    "    numRows = len(X_train_) - len(idx)\n",
    "    infs = []\n",
    "    for i in range(len(cols)):\n",
    "        col = cols[i]\n",
    "        infs_i = []\n",
    "        vals_i = []\n",
    "        colVals = X_train_[col].unique()\n",
    "        for val in colVals:\n",
    "            idx_i = X_[X_[col] == val].index\n",
    "            infs_i.append(getInfluenceOfSet(idx_i, spd_0, X_train, y_train, X_test, X_test_, method))\n",
    "        infs.append(infs_i)\n",
    "           \n",
    "    colIdx = getSplitVal(infs)\n",
    "    splitCol = cols[colIdx]\n",
    "    return {'splitCol': splitCol, 'predCols': predCols, 'predVals': predVals, 'numRows': numRows}\n",
    "\n",
    "def partition(node, maxDepth, minSize, depth, cols, \n",
    "              X_train_, y_train_, X_train, X_test_, X_test, method):\n",
    "    print(\"Depth: \", depth)\n",
    "    if depth >= maxDepth or node['numRows'] < minSize:\n",
    "        node['children'] = None\n",
    "        return\n",
    "    \n",
    "    X_ = copy.deepcopy(X_train_)\n",
    "    if len(node['predCols']) > 0:\n",
    "        for i in range(len(node['predCols'])):\n",
    "            pred = node['predCols'][i]\n",
    "            val = node['predVals'][i]\n",
    "            idx = X_[X_[pred] == val].index \n",
    "            X_ = X_[X_[pred] == val]\n",
    "    \n",
    "    col = node['splitCol']\n",
    "    vals = X_train_[col].unique()\n",
    "    child = [None] * len(vals)\n",
    "    for i in range(len(vals)):\n",
    "        idx = X_[X_[col] == vals[i]].index \n",
    "        X = X_train.drop(index=idx, inplace=False)\n",
    "        y = y_train.drop(index=idx, inplace=False)\n",
    "        X_ = X_train_.drop(index=idx, inplace=False)\n",
    "        if len(X) < minSize:\n",
    "            node['children'] = None\n",
    "        else:\n",
    "            cols_ = copy.deepcopy(cols)\n",
    "            cols_.remove(col)\n",
    "            predCols_temp = copy.deepcopy(node['predCols'])\n",
    "            predCols_temp.append(col)\n",
    "            predVals_temp = copy.deepcopy(node['predVals'])\n",
    "            predVals_temp.append(vals[i])\n",
    "            child[i] = getSplitAttribute(cols_, predCols_temp, predVals_temp, \n",
    "                                         X_train, y_train, X_test,  X_train_, X_test_, method)\n",
    "            child[i]['predCols'] = predCols_temp\n",
    "            child[i]['predVals'] = predVals_temp\n",
    "            partition(child[i], maxDepth, minSize, depth + 1, cols_,  \n",
    "                      X_train_, y_train_, X_train, X_test_, X_test, method)\n",
    "    node['children'] = child\n",
    "\n",
    "def buildTree(X_train_, X_train, maxDepth, minSize, method):\n",
    "    cols = copy.deepcopy(X_train_.columns).tolist()\n",
    "    X_train = pd.DataFrame(data=X_train, columns=X_train_orig.columns)\n",
    "    root = getSplitAttribute(cols, [], [], X_train, y_train, X_test, X_train_, X_test_, method)\n",
    "    print(\"Root: \", root)\n",
    "    partition(root, maxDepth, minSize, 1, cols,\n",
    "              X_train_, y_train_, X_train, X_test_, X_test, method)\n",
    "    return root\n",
    "\n",
    "method = 3\n",
    "dtree = buildTree(X_train_, X_train, 3, 100, method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'splitCol': 'workclass',\n",
       " 'predCols': [],\n",
       " 'predVals': [],\n",
       " 'numRows': 30162,\n",
       " 'children': [{'splitCol': 'occupation',\n",
       "   'predCols': ['workclass'],\n",
       "   'predVals': ['State-gov'],\n",
       "   'numRows': 28883,\n",
       "   'children': [{'splitCol': 'education',\n",
       "     'predCols': ['workclass', 'occupation'],\n",
       "     'predVals': ['State-gov', 'Adm-clerical'],\n",
       "     'numRows': 29911,\n",
       "     'children': None},\n",
       "    {'splitCol': 'education',\n",
       "     'predCols': ['workclass', 'occupation'],\n",
       "     'predVals': ['State-gov', 'Exec-managerial'],\n",
       "     'numRows': 29976,\n",
       "     'children': None},\n",
       "    {'splitCol': 'age',\n",
       "     'predCols': ['workclass', 'occupation'],\n",
       "     'predVals': ['State-gov', 'Handlers-cleaners'],\n",
       "     'numRows': 30153,\n",
       "     'children': None},\n",
       "    {'splitCol': 'education',\n",
       "     'predCols': ['workclass', 'occupation'],\n",
       "     'predVals': ['State-gov', 'Prof-specialty'],\n",
       "     'numRows': 29759,\n",
       "     'children': None},\n",
       "    {'splitCol': 'education',\n",
       "     'predCols': ['workclass', 'occupation'],\n",
       "     'predVals': ['State-gov', 'Other-service'],\n",
       "     'numRows': 30039,\n",
       "     'children': None},\n",
       "    {'splitCol': 'education',\n",
       "     'predCols': ['workclass', 'occupation'],\n",
       "     'predVals': ['State-gov', 'Sales'],\n",
       "     'numRows': 30151,\n",
       "     'children': None},\n",
       "    {'splitCol': 'education',\n",
       "     'predCols': ['workclass', 'occupation'],\n",
       "     'predVals': ['State-gov', 'Transport-moving'],\n",
       "     'numRows': 30121,\n",
       "     'children': None},\n",
       "    {'splitCol': 'education',\n",
       "     'predCols': ['workclass', 'occupation'],\n",
       "     'predVals': ['State-gov', 'Farming-fishing'],\n",
       "     'numRows': 30147,\n",
       "     'children': None},\n",
       "    {'splitCol': 'education',\n",
       "     'predCols': ['workclass', 'occupation'],\n",
       "     'predVals': ['State-gov', 'Machine-op-inspct'],\n",
       "     'numRows': 30149,\n",
       "     'children': None},\n",
       "    {'splitCol': 'age',\n",
       "     'predCols': ['workclass', 'occupation'],\n",
       "     'predVals': ['State-gov', 'Tech-support'],\n",
       "     'numRows': 30106,\n",
       "     'children': None},\n",
       "    {'splitCol': 'education',\n",
       "     'predCols': ['workclass', 'occupation'],\n",
       "     'predVals': ['State-gov', 'Craft-repair'],\n",
       "     'numRows': 30107,\n",
       "     'children': None},\n",
       "    {'splitCol': 'education',\n",
       "     'predCols': ['workclass', 'occupation'],\n",
       "     'predVals': ['State-gov', 'Protective-serv'],\n",
       "     'numRows': 30046,\n",
       "     'children': None},\n",
       "    {'splitCol': 'age',\n",
       "     'predCols': ['workclass', 'occupation'],\n",
       "     'predVals': ['State-gov', 'Armed-Forces'],\n",
       "     'numRows': 30162,\n",
       "     'children': None},\n",
       "    {'splitCol': 'age',\n",
       "     'predCols': ['workclass', 'occupation'],\n",
       "     'predVals': ['State-gov', 'Priv-house-serv'],\n",
       "     'numRows': 30162,\n",
       "     'children': None}]},\n",
       "  {'splitCol': 'education',\n",
       "   'predCols': ['workclass'],\n",
       "   'predVals': ['Self-emp-not-inc'],\n",
       "   'numRows': 27663,\n",
       "   'children': [{'splitCol': 'occupation',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Self-emp-not-inc', 'Bachelors'],\n",
       "     'numRows': 29775,\n",
       "     'children': None},\n",
       "    {'splitCol': 'occupation',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Self-emp-not-inc', 'HS-grad'],\n",
       "     'numRows': 29305,\n",
       "     'children': None},\n",
       "    {'splitCol': 'marital',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Self-emp-not-inc', '11th'],\n",
       "     'numRows': 30103,\n",
       "     'children': None},\n",
       "    {'splitCol': 'age',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Self-emp-not-inc', 'Masters'],\n",
       "     'numRows': 30042,\n",
       "     'children': None},\n",
       "    {'splitCol': 'marital',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Self-emp-not-inc', '9th'],\n",
       "     'numRows': 30128,\n",
       "     'children': None},\n",
       "    {'splitCol': 'marital',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Self-emp-not-inc', 'Some-college'],\n",
       "     'numRows': 29681,\n",
       "     'children': None},\n",
       "    {'splitCol': 'marital',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Self-emp-not-inc', 'Assoc-acdm'],\n",
       "     'numRows': 30092,\n",
       "     'children': None},\n",
       "    {'splitCol': 'marital',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Self-emp-not-inc', '7th-8th'],\n",
       "     'numRows': 30069,\n",
       "     'children': None},\n",
       "    {'splitCol': 'age',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Self-emp-not-inc', 'Doctorate'],\n",
       "     'numRows': 30116,\n",
       "     'children': None},\n",
       "    {'splitCol': 'marital',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Self-emp-not-inc', 'Assoc-voc'],\n",
       "     'numRows': 30054,\n",
       "     'children': None},\n",
       "    {'splitCol': 'age',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Self-emp-not-inc', 'Prof-school'],\n",
       "     'numRows': 30032,\n",
       "     'children': None},\n",
       "    {'splitCol': 'age',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Self-emp-not-inc', '5th-6th'],\n",
       "     'numRows': 30143,\n",
       "     'children': None},\n",
       "    {'splitCol': 'marital',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Self-emp-not-inc', '10th'],\n",
       "     'numRows': 30097,\n",
       "     'children': None},\n",
       "    {'splitCol': 'age',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Self-emp-not-inc', 'Preschool'],\n",
       "     'numRows': 30162,\n",
       "     'children': None},\n",
       "    {'splitCol': 'marital',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Self-emp-not-inc', '12th'],\n",
       "     'numRows': 30144,\n",
       "     'children': None},\n",
       "    {'splitCol': 'age',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Self-emp-not-inc', '1st-4th'],\n",
       "     'numRows': 30150,\n",
       "     'children': None}]},\n",
       "  {'splitCol': 'occupation',\n",
       "   'predCols': ['workclass'],\n",
       "   'predVals': ['Private'],\n",
       "   'numRows': 7876,\n",
       "   'children': [{'splitCol': 'education',\n",
       "     'predCols': ['workclass', 'occupation'],\n",
       "     'predVals': ['Private', 'Adm-clerical'],\n",
       "     'numRows': 27369,\n",
       "     'children': None},\n",
       "    {'splitCol': 'education',\n",
       "     'predCols': ['workclass', 'occupation'],\n",
       "     'predVals': ['Private', 'Exec-managerial'],\n",
       "     'numRows': 27515,\n",
       "     'children': None},\n",
       "    {'splitCol': 'education',\n",
       "     'predCols': ['workclass', 'occupation'],\n",
       "     'predVals': ['Private', 'Handlers-cleaners'],\n",
       "     'numRows': 28907,\n",
       "     'children': None},\n",
       "    {'splitCol': 'education',\n",
       "     'predCols': ['workclass', 'occupation'],\n",
       "     'predVals': ['Private', 'Prof-specialty'],\n",
       "     'numRows': 27908,\n",
       "     'children': None},\n",
       "    {'splitCol': 'education',\n",
       "     'predCols': ['workclass', 'occupation'],\n",
       "     'predVals': ['Private', 'Other-service'],\n",
       "     'numRows': 27497,\n",
       "     'children': None},\n",
       "    {'splitCol': 'education',\n",
       "     'predCols': ['workclass', 'occupation'],\n",
       "     'predVals': ['Private', 'Sales'],\n",
       "     'numRows': 27267,\n",
       "     'children': None},\n",
       "    {'splitCol': 'education',\n",
       "     'predCols': ['workclass', 'occupation'],\n",
       "     'predVals': ['Private', 'Transport-moving'],\n",
       "     'numRows': 28915,\n",
       "     'children': None},\n",
       "    {'splitCol': 'education',\n",
       "     'predCols': ['workclass', 'occupation'],\n",
       "     'predVals': ['Private', 'Farming-fishing'],\n",
       "     'numRows': 29712,\n",
       "     'children': None},\n",
       "    {'splitCol': 'education',\n",
       "     'predCols': ['workclass', 'occupation'],\n",
       "     'predVals': ['Private', 'Machine-op-inspct'],\n",
       "     'numRows': 28280,\n",
       "     'children': None},\n",
       "    {'splitCol': 'education',\n",
       "     'predCols': ['workclass', 'occupation'],\n",
       "     'predVals': ['Private', 'Tech-support'],\n",
       "     'numRows': 29439,\n",
       "     'children': None},\n",
       "    {'splitCol': 'education',\n",
       "     'predCols': ['workclass', 'occupation'],\n",
       "     'predVals': ['Private', 'Craft-repair'],\n",
       "     'numRows': 27016,\n",
       "     'children': None},\n",
       "    {'splitCol': 'education',\n",
       "     'predCols': ['workclass', 'occupation'],\n",
       "     'predVals': ['Private', 'Protective-serv'],\n",
       "     'numRows': 29976,\n",
       "     'children': None},\n",
       "    {'splitCol': 'age',\n",
       "     'predCols': ['workclass', 'occupation'],\n",
       "     'predVals': ['Private', 'Armed-Forces'],\n",
       "     'numRows': 30162,\n",
       "     'children': None},\n",
       "    {'splitCol': 'education',\n",
       "     'predCols': ['workclass', 'occupation'],\n",
       "     'predVals': ['Private', 'Priv-house-serv'],\n",
       "     'numRows': 30019,\n",
       "     'children': None}]},\n",
       "  {'splitCol': 'education',\n",
       "   'predCols': ['workclass'],\n",
       "   'predVals': ['Federal-gov'],\n",
       "   'numRows': 29219,\n",
       "   'children': [{'splitCol': 'occupation',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Federal-gov', 'Bachelors'],\n",
       "     'numRows': 29955,\n",
       "     'children': None},\n",
       "    {'splitCol': 'occupation',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Federal-gov', 'HS-grad'],\n",
       "     'numRows': 29902,\n",
       "     'children': None},\n",
       "    {'splitCol': 'age',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Federal-gov', '11th'],\n",
       "     'numRows': 30153,\n",
       "     'children': None},\n",
       "    {'splitCol': 'age',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Federal-gov', 'Masters'],\n",
       "     'numRows': 30097,\n",
       "     'children': None},\n",
       "    {'splitCol': 'age',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Federal-gov', '9th'],\n",
       "     'numRows': 30159,\n",
       "     'children': None},\n",
       "    {'splitCol': 'occupation',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Federal-gov', 'Some-college'],\n",
       "     'numRows': 29911,\n",
       "     'children': None},\n",
       "    {'splitCol': 'age',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Federal-gov', 'Assoc-acdm'],\n",
       "     'numRows': 30107,\n",
       "     'children': None},\n",
       "    {'splitCol': 'age',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Federal-gov', '7th-8th'],\n",
       "     'numRows': 30160,\n",
       "     'children': None},\n",
       "    {'splitCol': 'age',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Federal-gov', 'Doctorate'],\n",
       "     'numRows': 30147,\n",
       "     'children': None},\n",
       "    {'splitCol': 'marital',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Federal-gov', 'Assoc-voc'],\n",
       "     'numRows': 30124,\n",
       "     'children': None},\n",
       "    {'splitCol': 'age',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Federal-gov', 'Prof-school'],\n",
       "     'numRows': 30136,\n",
       "     'children': None},\n",
       "    {'splitCol': 'age',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Federal-gov', '5th-6th'],\n",
       "     'numRows': 30161,\n",
       "     'children': None},\n",
       "    {'splitCol': 'age',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Federal-gov', '10th'],\n",
       "     'numRows': 30156,\n",
       "     'children': None},\n",
       "    {'splitCol': 'age',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Federal-gov', 'Preschool'],\n",
       "     'numRows': 30162,\n",
       "     'children': None},\n",
       "    {'splitCol': 'age',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Federal-gov', '12th'],\n",
       "     'numRows': 30157,\n",
       "     'children': None},\n",
       "    {'splitCol': 'age',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Federal-gov', '1st-4th'],\n",
       "     'numRows': 30162,\n",
       "     'children': None}]},\n",
       "  {'splitCol': 'marital',\n",
       "   'predCols': ['workclass'],\n",
       "   'predVals': ['Local-gov'],\n",
       "   'numRows': 28095,\n",
       "   'children': [{'splitCol': 'occupation',\n",
       "     'predCols': ['workclass', 'marital'],\n",
       "     'predVals': ['Local-gov', 'Never-married'],\n",
       "     'numRows': 29638,\n",
       "     'children': None},\n",
       "    {'splitCol': 'occupation',\n",
       "     'predCols': ['workclass', 'marital'],\n",
       "     'predVals': ['Local-gov', 'Married-civ-spouse'],\n",
       "     'numRows': 29149,\n",
       "     'children': None},\n",
       "    {'splitCol': 'education',\n",
       "     'predCols': ['workclass', 'marital'],\n",
       "     'predVals': ['Local-gov', 'Divorced'],\n",
       "     'numRows': 29799,\n",
       "     'children': None},\n",
       "    {'splitCol': 'age',\n",
       "     'predCols': ['workclass', 'marital'],\n",
       "     'predVals': ['Local-gov', 'Married-spouse-absent'],\n",
       "     'numRows': 30141,\n",
       "     'children': None},\n",
       "    {'splitCol': 'education',\n",
       "     'predCols': ['workclass', 'marital'],\n",
       "     'predVals': ['Local-gov', 'Separated'],\n",
       "     'numRows': 30102,\n",
       "     'children': None},\n",
       "    {'splitCol': 'age',\n",
       "     'predCols': ['workclass', 'marital'],\n",
       "     'predVals': ['Local-gov', 'Married-AF-spouse'],\n",
       "     'numRows': 30162,\n",
       "     'children': None},\n",
       "    {'splitCol': 'age',\n",
       "     'predCols': ['workclass', 'marital'],\n",
       "     'predVals': ['Local-gov', 'Widowed'],\n",
       "     'numRows': 30076,\n",
       "     'children': None}]},\n",
       "  {'splitCol': 'education',\n",
       "   'predCols': ['workclass'],\n",
       "   'predVals': ['Self-emp-inc'],\n",
       "   'numRows': 29088,\n",
       "   'children': [{'splitCol': 'marital',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Self-emp-inc', 'Bachelors'],\n",
       "     'numRows': 29903,\n",
       "     'children': None},\n",
       "    {'splitCol': 'marital',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Self-emp-inc', 'HS-grad'],\n",
       "     'numRows': 29892,\n",
       "     'children': None},\n",
       "    {'splitCol': 'age',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Self-emp-inc', '11th'],\n",
       "     'numRows': 30149,\n",
       "     'children': None},\n",
       "    {'splitCol': 'age',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Self-emp-inc', 'Masters'],\n",
       "     'numRows': 30085,\n",
       "     'children': None},\n",
       "    {'splitCol': 'marital',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Self-emp-inc', '9th'],\n",
       "     'numRows': 30153,\n",
       "     'children': None},\n",
       "    {'splitCol': 'marital',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Self-emp-inc', 'Some-college'],\n",
       "     'numRows': 29939,\n",
       "     'children': None},\n",
       "    {'splitCol': 'age',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Self-emp-inc', 'Assoc-acdm'],\n",
       "     'numRows': 30127,\n",
       "     'children': None},\n",
       "    {'splitCol': 'age',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Self-emp-inc', '7th-8th'],\n",
       "     'numRows': 30152,\n",
       "     'children': None},\n",
       "    {'splitCol': 'age',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Self-emp-inc', 'Doctorate'],\n",
       "     'numRows': 30129,\n",
       "     'children': None},\n",
       "    {'splitCol': 'marital',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Self-emp-inc', 'Assoc-voc'],\n",
       "     'numRows': 30125,\n",
       "     'children': None},\n",
       "    {'splitCol': 'age',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Self-emp-inc', 'Prof-school'],\n",
       "     'numRows': 30083,\n",
       "     'children': None},\n",
       "    {'splitCol': 'age',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Self-emp-inc', '5th-6th'],\n",
       "     'numRows': 30159,\n",
       "     'children': None},\n",
       "    {'splitCol': 'age',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Self-emp-inc', '10th'],\n",
       "     'numRows': 30143,\n",
       "     'children': None},\n",
       "    {'splitCol': 'age',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Self-emp-inc', 'Preschool'],\n",
       "     'numRows': 30162,\n",
       "     'children': None},\n",
       "    {'splitCol': 'age',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Self-emp-inc', '12th'],\n",
       "     'numRows': 30156,\n",
       "     'children': None},\n",
       "    {'splitCol': 'age',\n",
       "     'predCols': ['workclass', 'education'],\n",
       "     'predVals': ['Self-emp-inc', '1st-4th'],\n",
       "     'numRows': 30161,\n",
       "     'children': None}]},\n",
       "  {'splitCol': 'age',\n",
       "   'predCols': ['workclass'],\n",
       "   'predVals': ['Without-pay'],\n",
       "   'numRows': 30148,\n",
       "   'children': [{'splitCol': 'education',\n",
       "     'predCols': ['workclass', 'age'],\n",
       "     'predVals': ['Without-pay', 2],\n",
       "     'numRows': 30162,\n",
       "     'children': None},\n",
       "    {'splitCol': 'education',\n",
       "     'predCols': ['workclass', 'age'],\n",
       "     'predVals': ['Without-pay', 3],\n",
       "     'numRows': 30160,\n",
       "     'children': None},\n",
       "    {'splitCol': 'education',\n",
       "     'predCols': ['workclass', 'age'],\n",
       "     'predVals': ['Without-pay', 1],\n",
       "     'numRows': 30161,\n",
       "     'children': None},\n",
       "    {'splitCol': 'education',\n",
       "     'predCols': ['workclass', 'age'],\n",
       "     'predVals': ['Without-pay', 0],\n",
       "     'numRows': 30158,\n",
       "     'children': None},\n",
       "    {'splitCol': 'education',\n",
       "     'predCols': ['workclass', 'age'],\n",
       "     'predVals': ['Without-pay', 4],\n",
       "     'numRows': 30160,\n",
       "     'children': None},\n",
       "    {'splitCol': 'education',\n",
       "     'predCols': ['workclass', 'age'],\n",
       "     'predVals': ['Without-pay', 5],\n",
       "     'numRows': 30157,\n",
       "     'children': None}]}]}"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
