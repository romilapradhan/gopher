{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import copy\n",
    "import random\n",
    "import math\n",
    "from scipy import stats\n",
    "from scipy.stats import rankdata\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Markdown, display\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['age', 'workclass', 'fnlwgt', 'education', 'education.num', 'marital', 'occupation', 'relationship', 'race', 'gender', 'capgain', 'caploss', 'hours', 'country', 'income']\n",
    "df_train = pd.read_csv('adult.data', names=cols, sep=\",\")\n",
    "df_test = pd.read_csv('adult.test', names=cols, sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One-hot encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " def one_hot_encode(df):\n",
    "    df.isin(['?']).sum(axis=0)\n",
    "\n",
    "    # replace missing values (?) to nan and then drop the columns\n",
    "    df['country'] = df['country'].replace('?',np.nan)\n",
    "    df['workclass'] = df['workclass'].replace('?',np.nan)\n",
    "    df['occupation'] = df['occupation'].replace('?',np.nan)\n",
    "\n",
    "    # dropping the NaN rows now\n",
    "    df.dropna(how='any',inplace=True)\n",
    "    df['income'] = df['income'].map({'<=50K': 0, '>50K': 1}).astype(int)\n",
    "    df = pd.concat([df, pd.get_dummies(df['gender'], prefix='gender')],axis=1)\n",
    "    df = pd.concat([df, pd.get_dummies(df['race'], prefix='race')],axis=1)\n",
    "    df = pd.concat([df, pd.get_dummies(df['marital'], prefix='marital')],axis=1)\n",
    "    df = pd.concat([df, pd.get_dummies(df['workclass'], prefix='workclass')],axis=1)\n",
    "    df = pd.concat([df, pd.get_dummies(df['relationship'], prefix='relationship')],axis=1)\n",
    "    df = pd.concat([df, pd.get_dummies(df['occupation'], prefix='occupation')],axis=1)\n",
    "\n",
    "    df = df.drop(columns=['workclass', 'gender', 'fnlwgt', 'education', 'occupation', \\\n",
    "                      'relationship', 'marital', 'race', 'country', 'capgain', \\\n",
    "                      'caploss'])\n",
    "    return df\n",
    "\n",
    "# one-hot encoding (for regression mdoels)\n",
    "df_train = one_hot_encode(df_train)\n",
    "df_test = one_hot_encode(df_test)\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Protected, privileged**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# protected: 'gender_Female'=1\n",
    "# privileged: 'gender_Male'=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parametric Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns='income')\n",
    "y_train = df_train['income']\n",
    "\n",
    "X_test = df_test.drop(columns='income')\n",
    "y_test = df_test['income']\n",
    "\n",
    "# size=500\n",
    "# X_train = X_train[0:size]\n",
    "# y_train = y_train[0:size]\n",
    "\n",
    "X_train_orig = copy.deepcopy(X_train)\n",
    "X_test_orig = copy.deepcopy(X_test)\n",
    "\n",
    "# Scale data: regularization penalty default: ‘l2’, ‘lbfgs’ solvers support only l2 penalties. \n",
    "# Regularization makes the predictor dependent on the scale of the features.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression(random_state=0, max_iter=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute statistical parity difference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeFairness(y_pred, X_test): \n",
    "    protected_idx = X_test[X_test['gender_Female']==1].index\n",
    "    numProtected = len(protected_idx)\n",
    "    privileged_idx = X_test[X_test['gender_Male']==1].index\n",
    "    numPrivileged = len(privileged_idx)\n",
    "    \n",
    "    p_protected = 0\n",
    "    for i in range(len(protected_idx)):\n",
    "        p_protected += y_pred[protected_idx[i]][1]\n",
    "    p_protected /= len(protected_idx)\n",
    "    \n",
    "    p_privileged = 0\n",
    "    for i in range(len(privileged_idx)):\n",
    "        p_privileged += y_pred[privileged_idx[i]][1]\n",
    "    p_privileged /= len(privileged_idx)\n",
    "    \n",
    "    spd = p_protected - p_privileged\n",
    "    return spd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Influence of points computed using ground truth**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ground_truth_influence(X_train, y_train, X_test, X_test_orig):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict_proba(X_test)\n",
    "    spd_0 = computeFairness(y_pred, X_test_orig)\n",
    "\n",
    "    delta_spd = []\n",
    "    for i in range(len(X_train)):\n",
    "        X_removed = np.delete(X_train, i, 0)\n",
    "        y_removed = y_train.drop(index=i, inplace=False)\n",
    "        clf.fit(X_removed, y_removed)\n",
    "        y_pred = clf.predict_proba(X_test)\n",
    "        delta_spd_i = computeFairness(y_pred, X_test_orig) - spd_0\n",
    "        delta_spd.append(delta_spd_i)\n",
    "    \n",
    "    return delta_spd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss function** (Log loss for logistic regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_loss(y_true, y_pred):\n",
    "    loss = 0\n",
    "    for i in range(len(y_true)):\n",
    "        if (y_pred[i][1] != 0 and y_pred[i][0] != 0):\n",
    "            loss += - y_true[i] * math.log(y_pred[i][1]) - (1 - y_true[i]) * math.log(y_pred[i][0])\n",
    "    loss /= len(y_true)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute Accuracy** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeAccuracy(y_true, y_pred):\n",
    "    accuracy = 0\n",
    "    for i in range(len(y_true)):\n",
    "        idx = y_true[i]\n",
    "        accuracy += y_pred[i][idx]\n",
    "    accuracy /= len(y_true)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First-order derivative of loss function at z with respect to model parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_L_del_theta_i(num_params, y_true, x, y_pred):\n",
    "#     del_L_del_theta = np.ones((num_params, 1)) * ((1 - y_true) * y_pred[1] - y_true * y_pred[0])\n",
    "    del_L_del_theta = np.ones((num_params, 1)) * (- y_true + y_pred[1])\n",
    "    for j in range(1, num_params):\n",
    "            del_L_del_theta[j] *=  x[j-1]\n",
    "    return del_L_del_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hessian: Second-order partial derivative of loss function with respect to model parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hessian_one_point(num_params, x, y_pred):\n",
    "    H = np.ones((num_params, num_params)) * (y_pred[0] * y_pred[1])\n",
    "    for i in range(1, num_params):\n",
    "        for j in range(i + 1):\n",
    "            if j == 0:\n",
    "                H[i][j] *= x[i-1]\n",
    "            else:\n",
    "                H[i][j] *= x[i-1] * x[j-1] \n",
    "    i_lower = np.tril_indices(num_params, -1)\n",
    "    H.T[i_lower] = H[i_lower]     \n",
    "    return H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First-order derivative of $P(y \\mid \\textbf{x})$ with respect to model parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_f_del_theta_i(num_params, x, y_pred):\n",
    "    del_f_del_theta = np.ones((num_params, 1)) * (y_pred[0] * y_pred[1])\n",
    "    for j in range(1, num_params):\n",
    "            del_f_del_theta[j] *=  x[j-1]\n",
    "    return del_f_del_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Computing $v=\\nabla($Statistical parity difference$)$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return v = del(SPD)/del(theta)\n",
    "def del_spd_del_theta(num_params, X_test_orig, X_test, y_pred):\n",
    "    del_f_protected = np.zeros((num_params, 1))\n",
    "    del_f_privileged = np.zeros((num_params, 1))\n",
    "    numProtected = X_test_orig['gender_Female'].sum()\n",
    "    numPrivileged = X_test_orig['gender_Male'].sum()\n",
    "    for i in range(len(X_test)):\n",
    "        del_f_i = del_f_del_theta_i(num_params, X_test[i], y_pred[i])\n",
    "        if X_test_orig.iloc[i]['gender_Male'] == 1: #privileged\n",
    "            del_f_privileged = np.add(del_f_privileged, del_f_i)\n",
    "        elif X_test_orig.iloc[i]['gender_Female'] == 1:\n",
    "            del_f_protected = np.add(del_f_protected, del_f_i)\n",
    "    del_f_privileged /= numPrivileged\n",
    "    del_f_protected /= numProtected\n",
    "    v = np.subtract(del_f_protected, del_f_privileged)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stochastic estimation of Hessian vector product (involving del fairness): $H_{\\theta}^{-1}v = H_{\\theta}^{-1}\\nabla_{\\theta}f(z, \\theta) = v + [I - \\nabla_{\\theta}^2L(z_{s_j}, \\theta^*)]H_{\\theta}^{-1}v$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniformly sample t points from training data \n",
    "def hessian_vector_product(num_params, n, size, v, hessian_all_points):\n",
    "    if (size > n):\n",
    "        size = n\n",
    "    sample = random.sample(range(n), size)\n",
    "    hinv_v = copy.deepcopy(v)\n",
    "    for idx in range(size):\n",
    "        i = sample[idx]\n",
    "        hessian_i = hessian_all_points[i]\n",
    "        hinv_v = np.matmul(np.subtract(np.identity(num_params), hessian_i), hinv_v)\n",
    "        hinv_v = np.add(hinv_v, v)\n",
    "    return hinv_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First-order influence computation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_order_influence(del_L_del_theta, hinv_v, n):\n",
    "    infs = []\n",
    "    for i in range(n):\n",
    "        inf = -np.dot(del_L_del_theta[i].transpose(), hinv_v)\n",
    "        inf *= -1/n\n",
    "        infs.append(inf[0][0].tolist())\n",
    "    return infs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Second-order influence computation for a group of points in subset U**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_order_influence(X_train, U, size, del_L_del_theta, hessian_all_points):\n",
    "    u = len(U)\n",
    "    s = len(X_train)\n",
    "    p = u/s\n",
    "    c1 = (1 - 2*p)/(s * (1-p)**2)\n",
    "    c2 = 1/((s * (1-p))**2)\n",
    "    num_params = len(del_L_del_theta[0])\n",
    "    del_L_del_theta_hinv = np.zeros((num_params, 1))\n",
    "    del_L_del_theta_sum = np.zeros((num_params, 1))\n",
    "    hessian_U = np.zeros((num_params, num_params))\n",
    "    for i in range(u):\n",
    "        idx = U[i]\n",
    "        hessian_U = np.add(hessian_U, s * hessian_all_points[idx])\n",
    "        del_L_del_theta_sum = np.add(del_L_del_theta_sum, del_L_del_theta[idx])\n",
    "    \n",
    "    hinv_del_L_del_theta= np.matmul(hinv_exact, del_L_del_theta_sum)\n",
    "    hinv_hessian_U = np.matmul(hinv_exact, hessian_U)\n",
    "    term1 = c1 * hinv_del_L_del_theta\n",
    "    term2 = c2 * np.matmul(hinv_hessian_U, hinv_del_L_del_theta)\n",
    "    sum_term = np.add(term1, term2)\n",
    "    return sum_term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Metrics: Initial state**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial fairness:  -0.20059371090978573\n",
      "Initial loss:  0.360972684923813\n",
      "Initial accuracy:  0.7683939044369612\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "num_params = len(clf.coef_.transpose()) + 1 #weights and intercept; params: clf.coef_, clf.intercept_\n",
    "y_pred_test = clf.predict_proba(X_test)\n",
    "y_pred_train = clf.predict_proba(X_train)\n",
    "    \n",
    "spd_0 = computeFairness(y_pred_test, X_test_orig)\n",
    "print(\"Initial fairness: \", spd_0)\n",
    "\n",
    "loss_0 = logistic_loss(y_test, y_pred_test)\n",
    "print(\"Initial loss: \", loss_0)\n",
    "\n",
    "accuracy_0 = computeAccuracy(y_test, y_pred_test)\n",
    "print(\"Initial accuracy: \", accuracy_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-compute: (1) Hessian (2) del_L_del_theta for each training data point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_L_del_theta = []\n",
    "for i in range(int(len(X_train))):\n",
    "    del_L_del_theta.insert(i, del_L_del_theta_i(num_params, y_train[i], X_train[i], y_pred_train[i]))\n",
    "\n",
    "hessian_all_points = []\n",
    "for i in range(len(X_train)):\n",
    "    hessian_all_points.insert(i, hessian_one_point(num_params, X_train[i], y_pred_train[i])\n",
    "                              /len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*H^{-1} computation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "hexact = 1\n",
    "v1 = del_spd_del_theta(num_params, X_test_orig, X_test, y_pred_test)\n",
    "if hexact == 1: \n",
    "    H_exact = np.zeros((num_params, num_params))\n",
    "    for i in range(len(X_train)):\n",
    "        H_exact = np.add(H_exact, hessian_all_points[i])\n",
    "    hinv_exact = np.linalg.pinv(H_exact) \n",
    "    hinv_v = np.matmul(hinv_exact, v1)\n",
    "else: #using Hessian vector product\n",
    "    size_hvp = int(len(X_train) * .01)\n",
    "    hinv_v = hessian_vector_product(num_params, len(X_train), size_hvp, v1, hessian_all_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ground truth influence of each training data point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth influence\n",
    "# spdgt = ground_truth_influence(X_train, y_train, X_test, X_test_orig)\n",
    "# with open('delta_spd_ground_truth_v0.txt', 'w') as filehandle:\n",
    "#     for listitem in delta_spd:\n",
    "#         filehandle.write('%s\\n' % listitem)\n",
    "gt_spd = pd.read_csv('delta_spd_ground_truth_v0.txt', names=[\"Values\"], sep=\",\")\n",
    "gt_spd = gt_spd.values.tolist()\n",
    "spdgt=[]\n",
    "for i in range(len(gt_spd)):\n",
    "    spdgt.append(gt_spd[i][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First-order influence of each training data point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "infs_1 = first_order_influence(del_L_del_theta, hinv_v, len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correlation between first-order and ground truth influences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 30162 and the array at index 1 has size 500",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-d46aab0f573b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m print(\"Spearman rank correlation between 1st order inf and ground truth inf: \", \n\u001b[0;32m----> 2\u001b[0;31m       stats.spearmanr(spdgt, infs_1)[0])\n\u001b[0m\u001b[1;32m      3\u001b[0m print(\"Pearson correlation coefficient between 1st order inf and ground truth inf: \", \n\u001b[1;32m      4\u001b[0m       stats.pearsonr(spdgt, infs_1)[0])\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/scipy/stats/stats.py\u001b[0m in \u001b[0;36mspearmanr\u001b[0;34m(a, b, axis, nan_policy)\u001b[0m\n\u001b[1;32m   4181\u001b[0m         \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_chk_asarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxisout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4183\u001b[0;31m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4184\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4185\u001b[0m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mcolumn_stack\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/site-packages/numpy/lib/shape_base.py\u001b[0m in \u001b[0;36mcolumn_stack\u001b[0;34m(tup)\u001b[0m\n\u001b[1;32m    654\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m         \u001b[0marrays\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 656\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 30162 and the array at index 1 has size 500"
     ]
    }
   ],
   "source": [
    "print(\"Spearman rank correlation between 1st order inf and ground truth inf: \", \n",
    "      stats.spearmanr(spdgt, infs_1)[0])\n",
    "print(\"Pearson correlation coefficient between 1st order inf and ground truth inf: \", \n",
    "      stats.pearsonr(spdgt, infs_1)[0])\n",
    "\n",
    "colors = (0.5,0.2,0.5)\n",
    "fig = plt.figure()\n",
    "plt.scatter(infs_1, spdgt, c=colors, alpha=0.5)\n",
    "plt.xlabel('First-order influence')\n",
    "plt.ylabel('Ground truth influence')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verification of first-order influence (implementation) on log-loss of a single point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ground_truth_influence_loss(X_train, y_train, X_test, y_test, idx):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict_proba([X_test[idx]])[0]\n",
    "    loss_0 = - y_test[idx] * math.log(y_pred[1]) - (1 - y_test[idx]) * math.log(y_pred[0])\n",
    "\n",
    "    delta_loss = []\n",
    "    for i in range(len(X_train)):\n",
    "        X_removed = np.delete(X_train, i, 0)\n",
    "        y_removed = y_train.drop(index=i, inplace=False)\n",
    "        clf.fit(X_removed, y_removed)\n",
    "        y_pred = clf.predict_proba([X_test[idx]])[0]\n",
    "        loss_i = - y_test[idx] * math.log(y_pred[1]) - (1 - y_test[idx]) * math.log(y_pred[0])\n",
    "        delta_loss_i = loss_i - loss_0\n",
    "        delta_loss.append(delta_loss_i)\n",
    "    \n",
    "    return delta_loss\n",
    "\n",
    "verify = 0\n",
    "if verify:\n",
    "    # Identify data points misclassified by the model\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict_proba(X_test)\n",
    "    for i in range(len(X_test)):\n",
    "        if (y_pred[i][y_test[i]] < y_pred[i][1 - y_test[i]]):\n",
    "            print(i)\n",
    "\n",
    "    # compute loss approximated by first-order influence for a misclassified test data point\n",
    "    ix = 203 \n",
    "    v1 = del_L_del_theta_i(num_params, y_test[ix], X_test[ix], y_pred_test[ix])\n",
    "    H_exact = np.zeros((num_params, num_params))\n",
    "    for i in range(len(X_train)):\n",
    "        H_exact = np.add(H_exact, hessian_all_points[i])\n",
    "    hinv_exact = np.linalg.pinv(H_exact) \n",
    "    hinv_v = np.matmul(hinv_exact, v1)\n",
    "\n",
    "    infs_1 = first_order_influence(del_L_del_theta, hinv_v, len(X_train))\n",
    "    delta_loss_gt = ground_truth_influence_loss(X_train, y_train, X_test, y_test, ix)\n",
    "\n",
    "    colors = (0.5,0.2,0.5)\n",
    "    # fig = plt.figure()\n",
    "    fig, ax = plt.subplots(figsize=(4,4))\n",
    "    plt.scatter(infs_1, delta_loss_gt, c=colors, alpha=0.5)\n",
    "    plt.xlabel('First-order influence')\n",
    "    plt.ylabel('Ground truth influence')\n",
    "    ax.plot((0,1), 'r--')\n",
    "    # ax.plot([0,1],[0,1], transform=ax.transAxes)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking ground truth, first-order and second-order influences for a set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Rows removed:  4312\n",
      "#Rows left:  25850\n",
      "Ground truth fairness of subset:  -0.20625215414793924\n",
      "Ground truth influence of subset:  -0.00565844323815351\n",
      "First-order influence:  -0.0022943232829864472\n",
      "Second-order influence:  -0.004167267551007168\n"
     ]
    }
   ],
   "source": [
    "predicates = ['marital_Never-married', 'gender_Female']\n",
    "idx = X_train_orig[(X_train_orig[predicates[0]] == 1)\n",
    "                   & (X_train_orig[predicates[1]] == 1) \n",
    "                  ].index \n",
    "print(\"#Rows removed: \", len(idx))\n",
    "print(\"#Rows left: \", len(X_train) - len(idx))\n",
    "X = np.delete(X_train, idx, 0)\n",
    "y = y_train.drop(index=idx, inplace=False)\n",
    "clf.fit(X, y)\n",
    "y_pred_test = clf.predict_proba(X_test)\n",
    "print(\"Ground truth fairness of subset: \", computeFairness(y_pred_test, X_test_orig))\n",
    "print(\"Ground truth influence of subset: \", computeFairness(y_pred_test, X_test_orig) - spd_0)\n",
    "\n",
    "del_f_1 = 0\n",
    "for i in range(len(idx)):\n",
    "    del_f_1 += infs_1[idx[i]]\n",
    "print(\"First-order influence: \", del_f_1)\n",
    "\n",
    "size_hvp = 1\n",
    "params_f_2 = second_order_influence(X_train, idx, size_hvp, del_L_del_theta, hessian_all_points)\n",
    "del_f_2 = np.dot(v1.transpose(), params_f_2)[0][0]\n",
    "print(\"Second-order influence: \", del_f_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fairness: Ground-truth subset influence vs. computed subset influences: Random subset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground-truth subset, Add 1st-order inf individual, Add ground-truth inf individual, Second-order subset influence\n",
      "0.0009629809259190658, 0.0007608505954095434, 0, 0.0009548758946811795\n",
      "-0.0024558415138332956, -0.0019834973549170565, 0, -0.0024435206041296758\n",
      "0.0007159796115257799, 0.0005817511282417933, 0, 0.0007062044545100855\n",
      "0.0016977733073159085, 0.0012353292323012293, 0, 0.0016106707249222418\n",
      "-0.0008390032699661376, -0.000794650035863751, 0, -0.0009214936138884197\n",
      "0.0018752947121944419, 0.0015120618885418689, 0, 0.0018605853483757773\n",
      "0.0047508936878143115, 0.003793923999265885, 0, 0.004636187042642229\n",
      "-0.0008180093770101537, -0.000686133938715342, 0, -0.0009453824554443728\n",
      "-0.00097319105268176, -0.0007660839715716599, 0, -0.0009792674820370327\n",
      "0.0016469861163182498, 0.001342382859108319, 0, 0.001636853984906911\n",
      "0.001218346289418748, 0.001030334564643214, 0, 0.0012184676544054083\n",
      "0.001000833245967725, 0.0008488569873065311, 0, 0.0010078183911659024\n",
      "-0.0004866763661370843, -0.0003610104910981604, 0, -0.0004696710812161898\n",
      "0.001897270729228101, 0.0016216638341432067, 0, 0.0018785835633862566\n",
      "0.0005126457310338783, 0.0004148293082061451, 0, 0.000498007473479655\n",
      "-0.0033166825604644956, -0.002760899935410087, 0, -0.0033718175976245267\n",
      "0.0015996123182563382, 0.0011676365840611763, 0, 0.001515948707055887\n",
      "0.0017862504540413493, 0.0013116510956466345, 0, 0.0016891358379195083\n",
      "-0.000788163619832527, -0.0005897112813646712, 0, -0.0008268387150507074\n",
      "0.0007814030675673544, 0.0006028884311215365, 0, 0.0007511530685115982\n",
      "-0.0029330770898801928, -0.0023617218220201323, 0, -0.0029424724407913975\n",
      "0.00018397668377040377, 0.0001508727687988297, 0, 0.00017343792221683504\n",
      "-0.0006119343924154141, -0.00047845619425279174, 0, -0.0006155946044609082\n",
      "-0.0014446061656331333, -0.0011560722188584417, 0, -0.0014677557358784357\n",
      "0.002581664698908831, 0.0020623365473811882, 0, 0.002579302432104428\n",
      "-0.0017758382790217797, -0.0014027229510277816, 0, -0.0017817514190464233\n",
      "0.0002823116836558337, 0.00023959811736561906, 0, 0.00027694305069504374\n",
      "0.0004140306048781017, 0.0003597864998594199, 0, 0.0004264580329534955\n",
      "0.0007853702364644943, 0.0006347760302722921, 0, 0.000765184958458794\n",
      "-0.0025744148122749666, -0.0020906455596325646, 0, -0.0025811495459200154\n",
      "0.0013765749237405478, 0.0011297618574626698, 0, 0.0013784656755750063\n",
      "-0.0026536447281900744, -0.002108167632683453, 0, -0.0026623838851322582\n",
      "-0.002384489315734817, -0.0019639555804021017, 0, -0.0024855504626290622\n",
      "0.0011706860470001024, 0.0009977991219201473, 0, 0.0011885498994256638\n",
      "0.0017465390698883088, 0.0013990661334447143, 0, 0.001723660996562753\n",
      "-0.000663880864949562, -0.0005512432402986463, 0, -0.000676702145445332\n",
      "-0.001979001753355969, -0.0015646815590200454, 0, -0.0019642446366532314\n",
      "-0.0003303485157434838, -0.000252432564812675, 0, -0.00032319325671608637\n",
      "-0.0001339909354330926, -4.9123881547759165e-05, 0, -0.0001242568468023787\n",
      "-0.0016916847746257235, -0.001377720686715722, 0, -0.0017004150055899999\n",
      "-0.0041432359749130065, -0.0032739260832998574, 0, -0.004101889257349411\n",
      "0.00031426674893736406, 0.00018532552053032475, 0, 0.0002872615689118645\n",
      "-0.0016456620412285683, -0.0013932065144303919, 0, -0.0016325648962430299\n",
      "-0.0002128359586353601, -0.000142774271627157, 0, -0.00019358541126560813\n",
      "0.003026383956078127, 0.002460885279225245, 0, 0.0030233284866769588\n",
      "0.0014111152879023037, 0.0011224400382774404, 0, 0.0013988413295908336\n",
      "-0.00030194693419416385, -0.0002816327866695278, 0, -0.0002991950592661133\n",
      "0.0008134415571311171, 0.0006131270543370073, 0, 0.000798341393579644\n",
      "0.003571513521543085, 0.0028383531433927144, 0, 0.0035384688502375556\n",
      "-0.0013815400497401154, -0.001097174582016734, 0, -0.0013956002061057782\n",
      "0.0005183001741060622, 0.00039392895511939524, 0, 0.000495941337923552\n",
      "-0.0013884391060253187, -0.001156743418387385, 0, -0.0013766424837659069\n",
      "-0.002063856838974698, -0.0017367387187512378, 0, -0.0021893394848039\n",
      "-0.002010938031109133, -0.0015862804332853681, 0, -0.0020084751669779545\n",
      "-0.002097578424681612, -0.001680479677621414, 0, -0.0020947984659661044\n",
      "0.0008220032165865976, 0.0006713033972622203, 0, 0.0008089611022243778\n",
      "0.0011637112290045493, 0.0009563645012852659, 0, 0.0011609046590201578\n",
      "0.00042757335062776347, 0.0003116084799377974, 0, 0.0004189694093757642\n",
      "-0.0003546114704571224, -0.0003544117897699137, 0, -0.00043242924571638145\n",
      "0.00017810045251359652, 6.269251007299923e-05, 0, 5.896504075385078e-05\n",
      "-0.000718286476464769, -0.0005348799891589659, 0, -0.000765563906554442\n",
      "0.0017400315061928961, 0.0014206008020637157, 0, 0.001731165579627519\n",
      "-0.004449256931221723, -0.003509861827745763, 0, -0.004455398313043082\n",
      "0.0006706335906658534, 0.0004331177947721401, 0, 0.0005862210557979619\n",
      "-0.00020920858841899648, -0.00026132562901767244, 0, -0.00032862233063969584\n",
      "7.065766731031986e-05, 2.202907128354846e-05, 0, -1.9991669664090062e-05\n",
      "0.001893670071651865, 0.0015255818751264377, 0, 0.0018641552423634706\n",
      "0.002036602380625696, 0.0014876960083108097, 0, 0.001947274093341566\n",
      "0.0013765803381068364, 0.0009887540178627322, 0, 0.0012573375026923403\n",
      "0.002812161142812769, 0.0021513285141796417, 0, 0.0027114519304790655\n",
      "-0.0020927018107756157, -0.0016470928723574352, 0, -0.0020954184541991266\n",
      "0.0009004915257797008, 0.0006484736101091581, 0, 0.0007865068519400571\n",
      "-0.00021515038418729038, -0.0001835686888069504, 0, -0.00021820095875251362\n",
      "0.002695507321912316, 0.002173051601476332, 0, 0.002701944627038639\n",
      "0.002144956370262019, 0.0016171062933850128, 0, 0.0019974105912119802\n",
      "-0.0029614439404129222, -0.0023599866788661184, 0, -0.0029531277628888604\n",
      "-0.0032458939311514334, -0.0025837621053616967, 0, -0.0032540477003471283\n",
      "-0.00163451507162915, -0.001306823334942063, 0, -0.0016326703733844257\n",
      "0.0010473135697174896, 0.0008207939303889977, 0, 0.0010463874974744058\n",
      "0.0016012137848195884, 0.0012102573368037424, 0, 0.0015042094462955232\n",
      "0.002310067692904205, 0.0018544180104695224, 0, 0.00231141537640994\n",
      "0.001479551867514417, 0.0010367199882054523, 0, 0.0013885988001444464\n",
      "-0.003251750196952924, -0.0026704278349045296, 0, -0.003254878593442571\n",
      "0.0004479611064798772, 0.0003600377405737655, 0, 0.00045875951992107656\n",
      "-0.0015635853623232332, -0.001305991873088007, 0, -0.0015263438743588745\n",
      "0.000984688100185288, 0.0007831265089833258, 0, 0.0009745384911420683\n",
      "0.0022637955648899533, 0.0017905296683794984, 0, 0.002259809881996047\n",
      "0.002974657157510663, 0.002456753187953795, 0, 0.0029891335805461642\n",
      "0.002053425254916502, 0.0016340558217290326, 0, 0.0020378743278608416\n",
      "-0.002016433949104196, -0.0016234421293230884, 0, -0.002019137813411129\n",
      "0.0010537044880756796, 0.0007155907595263872, 0, 0.0009757116481371524\n",
      "-0.0005869470309735614, -0.0005302487977965715, 0, -0.0006466987664477555\n",
      "0.002324668807249436, 0.0018995129015431129, 0, 0.002312525745099786\n",
      "-0.0038221595534868036, -0.0030407536853617016, 0, -0.003778758989024411\n",
      "0.0029844355074848117, 0.0023736336352308627, 0, 0.0030143890136493973\n",
      "0.0008730092598309702, 0.0006946920571357802, 0, 0.0009005138926727081\n",
      "0.005917311972390205, 0.0047612329907528875, 0, 0.005975419248769056\n",
      "-0.0004181759433323218, -0.0004567982198824131, 0, -0.0005086172734426182\n",
      "-0.0016412586526728667, -0.0012864861003085704, 0, -0.0017063390663525028\n",
      "-0.0013195722374447771, -0.0010831978343757694, 0, -0.0013475757159260038\n"
     ]
    }
   ],
   "source": [
    "print(\"Ground-truth subset, Add 1st-order inf individual, Add ground-truth inf individual, Second-order subset influence\")\n",
    "sampleSize = int(.2 * len(X_train))\n",
    "for i in range(100):\n",
    "    idx = random.sample(range(1, len(X_train)), sampleSize) \n",
    "    X = np.delete(X_train, idx, 0)\n",
    "    y = y_train.drop(index=idx, inplace=False)\n",
    "    clf.fit(X, y)\n",
    "    y_pred_test = clf.predict_proba(X_test)\n",
    "    \n",
    "    # Ground truth subset influence\n",
    "    inf_gt = computeFairness(y_pred_test, X_test_orig) - spd_0\n",
    "    \n",
    "    # First-order subset influence\n",
    "    del_f_1 = 0\n",
    "    for i in range(len(idx)):\n",
    "        del_f_1 += infs_1[idx[i]]\n",
    "    \n",
    "    # Second-order subset influence\n",
    "    size_hvp = 1\n",
    "    params_f_2 = second_order_influence(X_train, idx, size_hvp, del_L_del_theta, hessian_all_points)\n",
    "    del_f_2 = np.dot(v1.transpose(), params_f_2)[0][0]\n",
    "    \n",
    "    print(inf_gt, del_f_1, del_f_gt, del_f_2, sep=\", \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fairness: Ground-truth subset influence vs. computed subset influences: Coherent subset** \n",
    "\n",
    "(by coherent, we mean group of data points that share some properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground-truth subset, Add 1st-order inf individual, Add ground-truth inf individual, Second-order subset influence\n",
      "0.00032155796236454925, 0.00029454082652533996, 0, 0.00030328036997329463, 786\n",
      "0.0011907157004082403, 0.0011543171079813003, 0, 0.001180300970831471, 575\n",
      "2.7218782747251424e-05, 1.2118612942596616e-05, 0, -3.8425141131604313e-07, 791\n",
      "0.0005263499141654471, 0.0005046670273034681, 0, 0.0005148722481624437, 448\n",
      "-0.0008794362696055713, -0.0008384900270714601, 0, -0.0008687648463629457, 808\n",
      "0.0012078108891511452, 0.0011554814772832803, 0, 0.0011815711584213942, 828\n",
      "0.0005324645782582016, 0.0005128287129365049, 0, 0.0005208576370774723, 555\n",
      "0.00024342051822168198, 0.000224524501465064, 0, 0.00023805720152062236, 455\n",
      "-0.00038275424889328, -0.0003772696302561302, 0, -0.00038636324775190507, 851\n",
      "-0.0001571038718774509, -0.00015012975792855852, 0, -0.00016694723767588833, 741\n",
      "8.599345233262223e-05, 7.441341870919887e-05, 0, 8.297223274831478e-05, 813\n",
      "-1.2616298432133188e-05, -1.591757515660045e-05, 0, -1.707605669751515e-05, 824\n",
      "-0.0006265034795917834, -0.0006151169097003863, 0, -0.0006319949692579965, 789\n",
      "0.00046234236732373146, 0.0004383412097503919, 0, 0.0004603031794720993, 836\n",
      "-0.0007597972553145538, -0.0007346542669646196, 0, -0.0007615789130028658, 799\n",
      "-0.0015465853435260857, -0.0014968090315044655, 0, -0.0015495630632829053, 743\n",
      "0.0005896947571366606, 0.0005695171157946065, 0, 0.0005938897198946146, 765\n",
      "0.0004917612016862583, 0.00046657675983447395, 0, 0.0004839552920240453, 394\n",
      "-0.0021425074806072086, -0.0020963695161144956, 0, -0.002138132170522166, 828\n",
      "-0.00021953637352301048, -0.00021796139099687528, 0, -0.0002301776000538358, 332\n",
      "-2.317740572249649e-05, -1.9983169266170817e-05, 0, -2.9089368712692823e-05, 343\n",
      "0.0001774701109040766, 0.0001646000997876807, 0, 0.00017444557443448616, 594\n",
      "-8.012899631282266e-05, -8.599135068836013e-05, 0, -8.615981582030725e-05, 629\n",
      "0.0014382713597071994, 0.0013970745917161432, 0, 0.0014405393277919815, 706\n",
      "-0.00014660269948796323, -0.00014083051059260953, 0, -0.000141650638430337, 674\n",
      "4.40856114009569e-05, 3.993879621529371e-05, 0, 4.315137453986485e-05, 523\n",
      "-0.00033545045939159523, -0.0003415772807185304, 0, -0.0003455037165637193, 621\n",
      "-0.00015141840132365525, -0.00013970512578298776, 0, -0.0001522280668768918, 752\n",
      "0.0003181590992049621, 0.00031687599176761713, 0, 0.00031201075935539664, 337\n",
      "0.0015973207332586337, 0.0015554609542273396, 0, 0.0016004777041835336, 704\n",
      "0.0006081288314586375, 0.0005886232134927224, 0, 0.0006103481182529139, 769\n",
      "-0.0012964234035247046, -0.0012772144082867757, 0, -0.00130842936843885, 774\n",
      "0.0011720522135507117, 0.0011365409849692712, 0, 0.0011677084671562836, 683\n",
      "0.0018944595741498538, 0.0017216950233988708, 0, 0.0017608978833720877, 711\n",
      "0.0010858882257603897, 0.0010456919366174525, 0, 0.0010681897571655466, 852\n",
      "4.7058113933851065e-05, 4.163960919210817e-05, 0, 4.282968577097949e-05, 15\n",
      "-0.0006861288814067057, -0.0006650220951516758, 0, -0.0006947300800384205, 789\n",
      "7.480808504434222e-05, 7.175861905047699e-05, 0, 7.116304425357949e-05, 447\n",
      "-0.0009742231239623089, -0.0009451907268020769, 0, -0.0009626049380202173, 837\n",
      "-7.6957685814949e-05, -8.516420789837932e-05, 0, -8.468575220138666e-05, 29\n",
      "0.0006967378510597255, 0.0006867947604158622, 0, 0.0006943113012041833, 386\n",
      "0.00014519101186666328, 0.0001413302673710197, 0, 0.0001405534475269104, 259\n",
      "-0.0002531496972831837, -0.00025499083325459637, 0, -0.0002594852933192598, 64\n",
      "-0.00023673748305869102, -0.00023720404371523594, 0, -0.0002361376630203082, 173\n",
      "1.9419660994557386e-05, 1.2071889797536357e-05, 0, 1.438579174240417e-05, 54\n",
      "-0.000548201864029374, -0.0005559921595551079, 0, -0.000547665778309979, 110\n",
      "0.0011922138443911379, 0.0011560368146824318, 0, 0.0011869946956356518, 571\n",
      "-0.0007112810414471871, -0.0007024889252264669, 0, -0.0007160369643988918, 344\n",
      "-0.0002700857861620276, -0.00025263984073174933, 0, -0.0002746167426322264, 745\n",
      "8.766926378744877e-07, -6.674661923133518e-07, 0, -9.57918664509615e-07, 328\n",
      "-0.0004030440116353229, -0.000397720553467731, 0, -0.000412023217297811, 276\n",
      "-0.00036355756162814723, -0.00036157362676391574, 0, -0.0003683423534513741, 35\n",
      "-0.0001395588946399018, -0.0001447444269880168, 0, -0.00014260331622470147, 34\n",
      "7.559297527914843e-05, 7.937120166854719e-05, 0, 7.070790996485981e-05, 136\n",
      "-9.710684742342268e-05, -0.00010219790709985764, 0, -9.665216779358282e-05, 20\n",
      "-0.00030539383010913523, -0.00030768943300380625, 0, -0.0003178107756066167, 213\n",
      "-0.00040763527388218423, -0.0004091393664442601, 0, -0.00041157103152627715, 186\n",
      "-0.00048769773708209896, -0.0004859525610761041, 0, -0.0004828388965200132, 111\n",
      "-0.0001537585762270144, -0.00015700228192283675, 0, -0.00015506590964219186, 38\n",
      "-0.00024834669802278886, -0.00025245181052975437, 0, -0.00025360934027386764, 40\n",
      "-0.00017483215903330018, -0.0001740550308040164, 0, -0.00018274294999409677, 80\n",
      "-0.00021376145799739676, -0.00021466750015697748, 0, -0.00021553247674697, 90\n",
      "-0.00015224771575078622, -0.00015351469163729718, 0, -0.0001524580489534062, 49\n",
      "6.547556466435234e-05, 6.058438573660387e-05, 0, 6.111122289457035e-05, 13\n",
      "2.8785131359509997e-05, 2.421166200443489e-05, 0, 2.4075602544748185e-05, 14\n",
      "-7.267367471280872e-05, -7.660122675451024e-05, 0, -7.562865625605524e-05, 3\n",
      "-9.089182909663429e-05, -9.440238623210916e-05, 0, -9.426458145462839e-05, 16\n",
      "-1.1611799495603314e-05, -1.4129975152910941e-05, 0, -1.454595954573108e-05, 8\n",
      "-2.070648807916964e-06, -2.4880313685253235e-06, 0, -4.274451738255856e-06, 5\n",
      "-3.280705808855755e-05, -3.467980552678684e-05, 0, -3.35258091265322e-05, 3\n",
      "-3.8113042764825744e-05, -4.1539658225779434e-05, 0, -4.039797424106678e-05, 7\n",
      "3.1329366654009316e-05, 2.936597152759617e-05, 0, 2.8882827970779387e-05, 1\n",
      "-0.0020538478739760557, -0.0017378041023753726, 0, -0.0020627866171322937, 5044\n",
      "0.002845400670084014, 0.0018766454838229567, 0, 0.0026992009366760845, 9840\n",
      "-0.00047417276146533016, -0.00047045525368188506, 0, -0.0004873259911626047, 1048\n",
      "-0.0013562982206719032, -0.0013575532738796048, 0, -0.001467365886558944, 1627\n",
      "-0.00016907773977045681, -0.00017788901076406434, 0, -0.00017401312466765184, 455\n",
      "0.0037041211392657702, 0.003005712653531026, 0, 0.0036910899864853242, 6678\n",
      "-0.0009547485681621892, -0.0009296190140186864, 0, -0.0009340091138769158, 1008\n",
      "0.00039852318559280286, 0.0003796054716978147, 0, 0.00039397653026614575, 557\n",
      "-0.001521953855123992, -0.0014774144270182823, 0, -0.0015145491823177074, 375\n",
      "-0.0010044519439844357, -0.0009467545515410577, 0, -0.0009957978618249015, 1307\n",
      "0.0009948118512034254, 0.0007728930936374381, 0, 0.0009591311494910542, 542\n",
      "7.079176090052375e-06, -3.4463507590479225e-07, 0, 3.604118810332576e-06, 288\n",
      "0.000742688273737524, 0.0007118978806397987, 0, 0.0007307666795749135, 820\n",
      "-1.0162208394115524e-05, -1.420992709100299e-05, 0, -1.4451729557953283e-05, 45\n",
      "0.0002057855240914508, 0.0002028305899119667, 0, 0.0002003078429584108, 377\n",
      "0.00017364988097190448, 0.00016752204365825927, 0, 0.0001662888032767722, 151\n",
      "0.01065409325610206, 0.005297491198054383, 0, 0.010214954667668476, 14251\n",
      "-6.78177705797367e-05, -6.75653887507256e-05, 0, -6.794762399732062e-05, 18\n",
      "-0.0008817891196927219, -0.0008869490481554328, 0, -0.0008887415437779618, 180\n",
      "0.002241591874339477, 0.002023803197822623, 0, 0.002236857063529733, 1753\n",
      "0.0017704542948810409, 0.0011434500266886006, 0, 0.0016742577009078489, 2718\n",
      "-0.0001961207953383448, -0.00018783475501532742, 0, -0.00020496003206717467, 120\n",
      "-0.0017132896503604944, -0.0016726994049941696, 0, -0.0017058210336561535, 989\n",
      "-0.0008004428646438133, -0.0007553948290822878, 0, -0.0008046107877040569, 1184\n",
      "-0.0018770120313908178, -0.0016119260950003995, 0, -0.0017907681466957774, 1405\n",
      "-0.0020163326112761504, -0.001971666814898436, 0, -0.0020228507806097887, 1054\n",
      "0.00011462499527825631, 0.00010921637054904566, 0, 0.00010734445431704914, 135\n",
      "0.0007363824879399739, 0.0007297166703033698, 0, 0.0007321343031305255, 209\n",
      "-6.432043574366997e-05, -7.935510521870361e-05, 0, -7.705922628828578e-05, 346\n",
      "-7.747725802115246e-05, -0.00010161664129687344, 0, -8.370453670873581e-05, 574\n",
      "0.00031928089660196446, 0.0003108825128747869, 0, 0.0003098882818841855, 146\n",
      "0.000553905937876964, 0.0005428773158334234, 0, 0.0005583626588832011, 456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00020518398030416884, 0.0001806813285455724, 0, 0.0002022562587816609, 672\n",
      "0.0005404065906345901, 0.0005208677799630199, 0, 0.000537101361893004, 494\n",
      "6.3630520586333e-05, 5.801025060591234e-05, 0, 5.724292962436897e-05, 27\n",
      "0.0001080208432066021, 0.00010304875849298792, 0, 0.00010336583355210776, 238\n",
      "-0.0007161247343761001, -0.0006588411761220491, 0, -0.0007146510528770105, 276\n",
      "-1.8217209975857074e-05, -2.2631751387643898e-05, 0, -2.2673887443399418e-05, 39\n",
      "0.00012402612676287728, 0.00011659293601365963, 0, 0.00012048327562802879, 90\n",
      "-0.00017297699364049457, -0.00017995746567534715, 0, -0.00017935087489683404, 34\n",
      "-0.0001794915076853143, -0.00018073967282725714, 0, -0.00018065231137772054, 72\n",
      "0.00015008072553598928, 0.00014764916561869242, 0, 0.00014634816451191012, 202\n",
      "-0.0005155451534887001, -0.0005198843372466437, 0, -0.0005158652373725129, 217\n",
      "-3.6919400352664056e-05, -4.22611711721743e-05, 0, -4.149630324203788e-05, 80\n",
      "1.5124748653089215e-05, 9.827344460343383e-06, 0, 1.1228763763021637e-05, 15\n",
      "0.0004392275610160534, 0.00043689420123216744, 0, 0.00042733134423942985, 213\n",
      "-0.00022235963590910846, -0.00022534512004215683, 0, -0.0002250885982129835, 137\n",
      "-0.000457593642616938, -0.0004601793441765081, 0, -0.00046059777114319285, 241\n",
      "1.5016064755679626e-05, 8.792971121546881e-06, 0, 8.792891671462337e-06, 7\n",
      "-6.784276694665747e-05, -6.795044975147766e-05, 0, -6.702345922844733e-05, 27\n",
      "9.365841637573591e-05, 9.599461307214287e-05, 0, 9.223126436361643e-05, 63\n",
      "-0.0001082645859229181, -0.0001051258269480244, 0, -0.00010733712740548313, 11\n",
      "-5.1515176331035084e-05, -5.108964510776078e-05, 0, -5.201637567923549e-05, 37\n",
      "-5.9618383493220684e-05, -5.9990856892345905e-05, 0, -6.194978120778604e-05, 38\n",
      "-0.0003308144746269892, -0.00032948517205502547, 0, -0.0003290156461097139, 222\n",
      "-2.1069760036684926e-05, -3.9195752973116556e-05, 0, -3.903831308315409e-05, 40\n",
      "0.00016701924592923967, 0.0001612753988712978, 0, 0.00016259995216692265, 14\n",
      "2.6976410470919143e-05, 2.5631142085755527e-05, 0, 2.5531365378952673e-05, 14\n",
      "0.00017884505547435814, 0.00017306270637091082, 0, 0.0001721046789429751, 63\n",
      "-0.0003264598355792736, -0.00032690610010775956, 0, -0.00032818054839647793, 62\n",
      "7.129497166796783e-05, 6.428036925450553e-05, 0, 6.429695521432314e-05, 102\n",
      "5.115362340990526e-06, 7.522610657660884e-06, 0, 6.696789660124142e-06, 17\n",
      "8.988718082081348e-07, -2.2303007377355813e-06, 0, -4.271605674855583e-06, 49\n",
      "-0.00010927948906319651, -0.00011301942776540813, 0, -0.00010897878881464172, 145\n",
      "-0.0001268996870708028, -0.00013634573149325522, 0, -0.0001357159382519729, 23\n",
      "7.466819008933312e-05, 6.870394970426168e-05, 0, 6.894631459107909e-05, 28\n",
      "-5.713396346168631e-06, -1.4032385747574439e-05, 0, -1.3609495416089184e-05, 29\n",
      "0.00013060228223524262, 0.00012716914614244854, 0, 0.00012625758090594098, 38\n",
      "-8.544112596836628e-05, -8.937848979281711e-05, 0, -8.897841983335326e-05, 19\n",
      "-0.0004145215652223144, -0.0003931095829046222, 0, -0.00042422118531730145, 78\n",
      "6.48691098639187e-05, 4.687345398961722e-05, 0, 4.621216529027584e-05, 22\n",
      "-5.026646703637505e-05, -5.350905284351322e-05, 0, -5.190538069259202e-05, 37\n",
      "-0.00011958329888259178, -0.00012658932326280287, 0, -0.00012321092957380262, 18\n",
      "7.37911034298655e-06, 6.088822704863544e-06, 0, 6.1176355237890365e-06, 4\n",
      "-1.9396616080052942e-05, -2.272024381969304e-05, 0, -2.1818368076768805e-05, 17\n",
      "-1.3197681405785477e-05, -1.5708039336534358e-05, 0, -1.5028732159146135e-05, 8\n",
      "-9.843330217831903e-05, -9.416860626819091e-05, 0, -9.606427829788496e-05, 28\n",
      "-0.0002384190787657614, -0.00024090646034658498, 0, -0.000241772691743667, 16\n",
      "-3.2620332697075316e-05, -3.273947435715937e-05, 0, -3.2817294920473826e-05, 9\n",
      "5.7750911668930094e-05, 5.4511322403116574e-05, 0, 5.133689820062005e-05, 26\n",
      "-3.1448969785019543e-06, -5.91240858270914e-06, 0, -8.044947965588524e-06, 40\n",
      "-0.00011195892787146944, -0.00011890360338242194, 0, -0.00011837865764001982, 27\n",
      "-5.372202966999473e-05, -5.969100791235477e-05, 0, -6.005571110633479e-05, 12\n",
      "-0.00010922537177202041, -0.00010927218680562368, 0, -0.00010559991785509693, 24\n",
      "3.556883132482813e-05, 3.3160588506216484e-05, 0, 3.305203240128945e-05, 28\n",
      "1.9594866968619673e-05, 1.672188920064893e-05, 0, 1.7169079398801808e-05, 13\n",
      "1.2448436613965441e-05, 8.796962623092432e-06, 0, 8.921544804743833e-06, 5\n",
      "-6.689833153514235e-05, -7.065559524439783e-05, 0, -6.660135931992472e-05, 13\n",
      "-0.00012262275764834962, -0.00012323323151440917, 0, -0.00012413434926723119, 6\n",
      "3.056234794737711e-05, 2.7178793071057556e-05, 0, 2.6474505661718526e-05, 9\n",
      "3.9525228964193415e-05, 3.406047599412978e-05, 0, 3.435749384980823e-05, 20\n",
      "-0.00012774050091740596, -0.0001324934875985956, 0, -0.00013098710440230313, 27\n",
      "-3.5628098088436033e-06, -7.442337120995933e-06, 0, -7.581263700123328e-06, 1\n",
      "-4.8148300093531216e-05, -5.123865792523426e-05, 0, -5.0850345387146634e-05, 2\n",
      "6.170667816926545e-05, 5.842170215716131e-05, 0, 5.751824017671636e-05, 2\n",
      "-2.1080873788825727e-05, -2.5103791135935805e-05, 0, -2.446963202881064e-05, 2\n",
      "-1.0285089081463195e-05, -1.3457380965655098e-05, 0, -1.3776243892660587e-05, 2\n",
      "-1.4710571312470666e-05, -1.4640473168830473e-05, 0, -1.434235125894472e-05, 1\n",
      "2.1805248865802707e-05, 1.8537994533815147e-05, 0, 1.8201779113755764e-05, 5\n",
      "-8.380717581457642e-05, -8.652040368561996e-05, 0, -8.588202790181275e-05, 5\n",
      "0.00014163773650727185, 0.0001365492419615199, 0, 0.00013502103947238067, 4\n",
      "9.047231390946209e-06, 8.61510472970922e-06, 0, 8.562370128331444e-06, 1\n",
      "-1.9145948269572166e-05, -2.221980571319764e-05, 0, -2.2245094561430217e-05, 2\n",
      "-8.373598579461405e-05, -8.650348076931236e-05, 0, -8.650626304706609e-05, 3\n",
      "-3.763453903993241e-05, -4.001466451372344e-05, 0, -4.122822014267247e-05, 3\n",
      "1.989474209876385e-05, 1.785349007800166e-05, 0, 1.9360287894092007e-05, 3\n",
      "-2.8135578749588497e-05, -3.386158408266271e-05, 0, -3.3117296683072276e-05, 1\n",
      "3.871318058826234e-05, 3.2392774102095634e-05, 0, 3.186217597284489e-05, 2\n",
      "-1.874990384315156e-05, -2.4430382731071843e-05, 0, -2.4079132223191364e-05, 1\n",
      "8.110701064878434e-06, 6.501967485511333e-06, 0, 6.5728728948501605e-06, 2\n",
      "0.0843803045900777, -0.00039916929512216976, 0, -0.0006549249162457642, 9782\n",
      "0.0843803045900777, -0.00039916929512216976, 0, -0.0006549249162457642, 9782\n",
      "0.08002045761292803, 0.00040423231657556706, 0, 0.0005016156249863892, 20380\n",
      "0.08002045761292803, 0.00040423231657556706, 0, 0.0005016156249863892, 20380\n",
      "-0.0005114668816826873, -0.0003430795279765841, 0, -0.00034035901048368915, 286\n",
      "-0.0005114668816826873, -0.0003430795279765841, 0, -0.00034035901048368915, 286\n",
      "-0.001052484592632713, -0.0006503307842282993, 0, -0.0006593236944492516, 895\n",
      "-0.001052484592632713, -0.0006503307842282993, 0, -0.0006593236944492516, 895\n",
      "0.001994781236516918, 0.0018802808869682359, 0, 0.0020160943094911896, 2817\n",
      "0.001994781236516918, 0.0018802808869682359, 0, 0.0020160943094911896, 2817\n",
      "-0.0011475500891248158, -0.00022649545083275568, 0, -0.00023116284922238705, 231\n",
      "-0.0011475500891248158, -0.00022649545083275568, 0, -0.00023116284922238705, 231\n",
      "0.005329785983341245, -0.0006553121024771924, 0, -0.004776205358891391, 25933\n",
      "0.005329785983341245, -0.0006553121024771924, 0, -0.004776205358891391, 25933\n",
      "0.011514899383314126, 0.0015972973206123762, 0, 0.002437647295191667, 4214\n",
      "0.011514899383314126, 0.0015972973206123762, 0, 0.002437647295191667, 4214\n",
      "-0.00011379073603426382, -0.00014314821494868554, 0, -0.00014369485369681174, 21\n",
      "-0.00011379073603426382, -0.00014314821494868554, 0, -0.00014369485369681174, 21\n",
      "0.17231515705421363, -0.0005217175937695872, 0, 0.0009893210727226164, 14065\n",
      "0.17231515705421363, -0.0005217175937695872, 0, 0.0009893210727226164, 14065\n",
      "-6.562463764650528e-05, -0.0001367226303094415, 0, -0.00014035575019295034, 370\n",
      "-6.562463764650528e-05, -0.0001367226303094415, 0, -0.00014035575019295034, 370\n",
      "-0.007759890940738784, -0.003432154395958667, 0, -0.006162757549937273, 9726\n",
      "-0.007759890940738784, -0.003432154395958667, 0, -0.006162757549937273, 9726\n",
      "0.0018376263209688437, 0.0009595191492121792, 0, 0.0010349909247034613, 939\n",
      "0.0018376263209688437, 0.0009595191492121792, 0, 0.0010349909247034613, 939\n",
      "0.0032918920780070915, 0.0016819893866151978, 0, 0.0018052754652791083, 827\n",
      "0.0032918920780070915, 0.0016819893866151978, 0, 0.0018052754652791083, 827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0024088247367832216, 0.0006643311202665592, 0, 0.0007277911134415611, 943\n",
      "0.0024088247367832216, 0.0006643311202665592, 0, 0.0007277911134415611, 943\n",
      "0.0013416282098084875, 0.0001408496774750524, 0, 0.0009035685539643527, 2067\n",
      "0.0013416282098084875, 0.0001408496774750524, 0, 0.0009035685539643527, 2067\n",
      "0.016080198794457323, 0.002171886303439524, 0, 0.016496224471700162, 22286\n",
      "0.016080198794457323, 0.002171886303439524, 0, 0.016496224471700162, 22286\n",
      "0.002050567117793084, 0.0001404393948815077, 0, 0.00012375246478622148, 1074\n",
      "0.002050567117793084, 0.0001404393948815077, 0, 0.00012375246478622148, 1074\n",
      "-0.007413520413749708, -0.002113515182600834, 0, -0.002228453244490122, 2499\n",
      "-0.007413520413749708, -0.002113515182600834, 0, -0.002228453244490122, 2499\n",
      "-0.0017816691742466029, -0.0009986865136153975, 0, -0.0011110382977382476, 1279\n",
      "-0.0017816691742466029, -0.0009986865136153975, 0, -0.0011110382977382476, 1279\n",
      "-0.0002075749550743411, -2.417783930347705e-07, 0, -4.811153277243314e-07, 14\n",
      "-0.0002075749550743411, -2.417783930347705e-07, 0, -4.811153277243314e-07, 14\n",
      "-0.011446196580878448, 0.00020016262055667553, 0, 0.00039956840956267695, 12463\n",
      "-0.011446196580878448, 0.00020016262055667553, 0, 0.00039956840956267695, 12463\n",
      "-0.006172196252192258, -0.0021402477705084583, 0, -0.004471050518641856, 7726\n",
      "-0.006172196252192258, -0.0021402477705084583, 0, -0.004471050518641856, 7726\n",
      "0.00016214904688605092, -0.0002699674198300297, 0, -0.0002642634884385902, 889\n",
      "0.00016214904688605092, -0.0002699674198300297, 0, -0.0002642634884385902, 889\n",
      "-0.0017590046578270235, -0.0009761525574180404, 0, -0.0010686206317899463, 4466\n",
      "-0.0017590046578270235, -0.0009761525574180404, 0, -0.0010686206317899463, 4466\n",
      "0.002548424148924533, 0.0031632358498914466, 0, 0.003982372528117456, 3212\n",
      "0.002548424148924533, 0.0031632358498914466, 0, 0.003982372528117456, 3212\n",
      "-0.034951093353242146, 2.8032298761815304e-05, 0, 1.692290914048758e-05, 1406\n",
      "-0.034951093353242146, 2.8032298761815304e-05, 0, 1.692290914048758e-05, 1406\n",
      "0.0013694625777754266, 0.0007230312681765405, 0, 0.0007472073998790252, 3721\n",
      "0.0013694625777754266, 0.0007230312681765405, 0, 0.0007472073998790252, 3721\n",
      "-0.0001606351330849798, 1.553872094967001e-06, 0, 1.3689799156691226e-06, 9\n",
      "-0.0001606351330849798, 1.553872094967001e-06, 0, 1.3689799156691226e-06, 9\n",
      "-0.00036035964267222553, -0.00025156656770553677, 0, -0.0002827576427789984, 4030\n",
      "-0.00036035964267222553, -0.00025156656770553677, 0, -0.0002827576427789984, 4030\n",
      "0.011607201733277311, -0.0006866949422149813, 0, -0.0011440647842274818, 3992\n",
      "0.011607201733277311, -0.0006866949422149813, 0, -0.0011440647842274818, 3992\n",
      "-0.005765441508572833, 7.303649210554202e-05, 0, 7.265947031271336e-05, 989\n",
      "-0.005765441508572833, 7.303649210554202e-05, 0, 7.265947031271336e-05, 989\n",
      "-0.0030429891187805924, 6.527606192693635e-05, 0, 5.2077657988812914e-05, 1350\n",
      "-0.0030429891187805924, 6.527606192693635e-05, 0, 5.2077657988812914e-05, 1350\n",
      "-0.0009462273701826285, 0.001118537894665689, 0, 0.0011608922250651336, 1966\n",
      "-0.0009462273701826285, 0.001118537894665689, 0, 0.0011608922250651336, 1966\n",
      "-0.0006243881911789928, -0.0009459811654522248, 0, -0.0010158337249513703, 3212\n",
      "-0.0006243881911789928, -0.0009459811654522248, 0, -0.0010158337249513703, 3212\n",
      "0.0035155109378589566, -5.032232798143915e-05, 0, -4.900863018172106e-05, 143\n",
      "0.0035155109378589566, -5.032232798143915e-05, 0, -4.900863018172106e-05, 143\n",
      "0.0015910986911271685, -0.002391180242057327, 0, -0.0026734073446202447, 4038\n",
      "0.0015910986911271685, -0.002391180242057327, 0, -0.0026734073446202447, 4038\n",
      "0.0016340498266165793, -0.0004810624208413037, 0, -0.0004777297277467085, 644\n",
      "0.0016340498266165793, -0.0004810624208413037, 0, -0.0004777297277467085, 644\n",
      "0.006589790823944591, 0.00257756028540891, 0, 0.0029769996690220462, 3584\n",
      "0.006589790823944591, 0.00257756028540891, 0, 0.0029769996690220462, 3584\n",
      "0.0014802543322554873, 0.0004191250478815906, 0, 0.00043821112399851294, 912\n",
      "0.0014802543322554873, 0.0004191250478815906, 0, 0.00043821112399851294, 912\n",
      "-0.0015573142141178664, -0.00016625023455393812, 0, -0.0001668240154025134, 1572\n",
      "-0.0015573142141178664, -0.00016625023455393812, 0, -0.0001668240154025134, 1572\n"
     ]
    }
   ],
   "source": [
    "print(\"Ground-truth subset, Add 1st-order inf individual, Add ground-truth inf individual, Second-order subset influence\")\n",
    "clf.fit(X_train, y_train)\n",
    "continuous_cols = ['age', 'education.num', 'hours',]\n",
    "# y_pred = clf.predict_proba([X_test[ix]])[0]\n",
    "# loss_ix = - y_test[ix] * math.log(y_pred[1]) - (1 - y_test[ix]) * math.log(y_pred[0])\n",
    "for col in X_train_orig.columns:\n",
    "    vals = X_train_orig[col].unique()\n",
    "    for val in vals:\n",
    "#         print(col, val, sep=\": \")\n",
    "        if col in continuous_cols:\n",
    "            idx = X_train_orig[X_train_orig[col] == val].index \n",
    "        else:\n",
    "            idx = X_train_orig[X_train_orig[col] == 1].index \n",
    "        X = np.delete(X_train, idx, 0)\n",
    "        y = y_train.drop(index=idx, inplace=False)\n",
    "        if len(y.unique())>1:\n",
    "            clf.fit(X, y)\n",
    "            y_pred = clf.predict_proba(X_test)\n",
    "#             y_pred = clf.predict_proba([X_test[ix]])[0]\n",
    "#             inf_gt = - y_test[ix] * math.log(y_pred[1]) - (1 - y_test[ix]) * math.log(y_pred[0]) - loss_ix\n",
    "            inf_gt = computeFairness(y_pred, X_test_orig)-spd_0\n",
    "            del_f_gt = 0\n",
    "            del_f_1 = 0\n",
    "            diff = []\n",
    "            for i in range(len(idx)):\n",
    "                del_f_1 += infs_1[idx[i]]\n",
    "#                 del_f_gt += delta_loss_gt[idx[i]] #spdgt[idx[i]]\n",
    "\n",
    "            size_hvp = 1\n",
    "            params_f_2 = second_order_influence(X_train, idx, size_hvp, del_L_del_theta, hessian_all_points)\n",
    "            del_f_2 = np.dot(v1.transpose(), params_f_2)[0][0]\n",
    "\n",
    "            print(inf_gt, del_f_1, del_f_gt, del_f_2, len(idx), sep=\", \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Space Partitioner for reducing bias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['age', 'workclass', 'fnlwgt', 'education', 'education.num', 'marital', 'occupation', 'relationship', 'race', 'gender', 'capgain', 'caploss', 'hours', 'country', 'income']\n",
    "df_train = pd.read_csv('adult.data', names=cols, sep=\",\")\n",
    "df_test = pd.read_csv('adult.test', names=cols, sep=\",\")\n",
    "\n",
    "def preprocess(df):\n",
    "    df.isin(['?']).sum(axis=0)\n",
    "\n",
    "    # replace missing values (?) to nan and then drop the columns\n",
    "    df['country'] = df['country'].replace('?',np.nan)\n",
    "    df['workclass'] = df['workclass'].replace('?',np.nan)\n",
    "    df['occupation'] = df['occupation'].replace('?',np.nan)\n",
    "\n",
    "    # dropping the NaN rows now\n",
    "    df.dropna(how='any',inplace=True)\n",
    "    df['income'] = df['income'].map({'<=50K': 0, '>50K': 1}).astype(int)\n",
    "    df = df.drop(columns=['fnlwgt', 'education.num', 'country', 'capgain', 'caploss'])\n",
    "    return df\n",
    "\n",
    "df_train = preprocess(df_train)\n",
    "df_test = preprocess(df_test)\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "X_train_ = df_train.drop(columns='income')\n",
    "y_train_ = df_train['income']\n",
    "\n",
    "X_test_ = df_test.drop(columns='income')\n",
    "y_test_ = df_test['income']\n",
    "\n",
    "# size=100\n",
    "# X_train = X_train[0:size]\n",
    "# y_train = y_train[0:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column passed:  relationship\n",
      "Val:  Unmarried\n",
      "Column passed:  race\n",
      "Val:  White\n",
      "Column passed:  workclass\n",
      "Val:  Private\n",
      "Column passed:  marital\n",
      "Val:  Married-civ-spouse\n",
      "{'splitCol': 'marital', 'numRows': 30162, 'infs': [-0.2083536018505245, -0.02827855385557211, -0.1890788115264716, -0.20065933554743223, -0.19875608458881688, -0.20070750164582, -0.19730181883177864], 'vals': ['Never-married', 'Married-civ-spouse', 'Divorced', 'Married-spouse-absent', 'Separated', 'Married-AF-spouse', 'Widowed'], 'idxs': [20436, 16097, 25948, 29792, 29223, 30141, 29335]}\n",
      "Depth:  1\n",
      "Column passed:  relationship\n",
      "Val:  Husband\n",
      "Column passed:  relationship\n",
      "Val:  Unmarried\n",
      "Column passed:  race\n",
      "Val:  White\n",
      "Column passed:  gender\n",
      "Val:  Male\n",
      "Depth:  2\n",
      "Column passed:  relationship\n",
      "Val:  Not-in-family\n",
      "Column passed:  relationship\n",
      "Val:  Unmarried\n",
      "Column passed:  workclass\n",
      "Val:  Federal-gov\n",
      "Column passed:  occupation\n",
      "Val:  Adm-clerical\n",
      "Depth:  2\n",
      "Column passed:  relationship\n",
      "Val:  Not-in-family\n",
      "Column passed:  relationship\n",
      "Val:  Own-child\n",
      "Column passed:  relationship\n",
      "Val:  Unmarried\n",
      "Column passed:  workclass\n",
      "Val:  Private\n",
      "Column passed:  occupation\n",
      "Val:  Exec-managerial\n",
      "Column passed:  gender\n",
      "Val:  Male\n",
      "Depth:  2\n",
      "Column passed:  relationship\n",
      "Val:  Unmarried\n",
      "Column passed:  race\n",
      "Val:  White\n",
      "Column passed:  workclass\n",
      "Val:  Private\n",
      "Column passed:  gender\n",
      "Val:  Male\n",
      "Depth:  2\n",
      "Column passed:  relationship\n",
      "Val:  Unmarried\n",
      "Column passed:  race\n",
      "Val:  White\n",
      "Column passed:  workclass\n",
      "Val:  Private\n",
      "Column passed:  gender\n",
      "Val:  Male\n",
      "Depth:  2\n",
      "Column passed:  relationship\n",
      "Val:  Unmarried\n",
      "Column passed:  race\n",
      "Val:  White\n",
      "Column passed:  workclass\n",
      "Val:  Private\n",
      "Column passed:  gender\n",
      "Val:  Male\n",
      "Depth:  2\n",
      "Column passed:  relationship\n",
      "Val:  Own-child\n",
      "Column passed:  relationship\n",
      "Val:  Unmarried\n",
      "Column passed:  race\n",
      "Val:  White\n",
      "Column passed:  occupation\n",
      "Val:  Exec-managerial\n",
      "Column passed:  gender\n",
      "Val:  Male\n",
      "Depth:  2\n"
     ]
    }
   ],
   "source": [
    "def computeFairness(y_pred, X_test): \n",
    "    protected_idx = X_test[X_test['gender']=='Female'].index\n",
    "    numProtected = len(protected_idx)\n",
    "    privileged_idx = X_test[X_test['gender']=='Male'].index\n",
    "    numPrivileged = len(privileged_idx)\n",
    "    \n",
    "    p_protected = 0\n",
    "    for i in range(len(protected_idx)):\n",
    "        p_protected += y_pred[protected_idx[i]][1]\n",
    "    p_protected /= len(protected_idx)\n",
    "    \n",
    "    p_privileged = 0\n",
    "    for i in range(len(privileged_idx)):\n",
    "        p_privileged += y_pred[privileged_idx[i]][1]\n",
    "    p_privileged /= len(privileged_idx)\n",
    "    \n",
    "    spd = p_protected - p_privileged\n",
    "    return spd\n",
    "\n",
    "def getInfluenceOfSet(indices, f, X_train, y_train, X_test, X_test_, method): \n",
    "    del_f = 0\n",
    "    if (method == 1):\n",
    "        X = X_train.drop(index=indices, inplace=False)\n",
    "        y = y_train.drop(index=indices, inplace=False)\n",
    "        if len(y.unique()) < 2:\n",
    "            return 0\n",
    "        clf.fit(X, y)\n",
    "        y_pred = clf.predict_proba(X_test)\n",
    "        del_f = computeFairness(y_pred, X_test_)\n",
    "    elif (method == 2):\n",
    "        for i in range(len(indices)):\n",
    "            del_f += infs_1[indices[i]]\n",
    "    elif (method == 3):\n",
    "#         second_order_influence(X_train, U, size, del_L_del_theta, hessian_all_points)\n",
    "        size_hvp = 1\n",
    "        params_f_2 = second_order_influence(X_train, indices, size_hvp, del_L_del_theta, hessian_all_points)\n",
    "        del_f = np.dot(v1.transpose(), params_f_2)[0][0]\n",
    "    return  del_f\n",
    "\n",
    "def getSplitVal(infs):\n",
    "    return (np.argmax(np.asarray(infs)))\n",
    "\n",
    "def getSplitAttribute(cols, cols_continuous, X_train, y_train, X_test, X_train_, X_test_, method):\n",
    "    splitCol, numRows, score = None, len(X_train_), abs(spd_0)\n",
    "    infs = []\n",
    "    vals = []\n",
    "    idxs = []\n",
    "    for i in range(len(cols)):\n",
    "        col = cols[i]\n",
    "        infs_i = []\n",
    "        vals_i = []\n",
    "        idxs_i = []\n",
    "        if col not in cols_continuous:\n",
    "            colVals = X_train_[col].unique()\n",
    "            for val in colVals:\n",
    "                idx = X_train_[X_train_[col] == val].index\n",
    "                idxs_i.append(len(X_train)-len(idx))\n",
    "                infs_i.append(getInfluenceOfSet(idx, spd_0, X_train, y_train, X_test, X_test_, method))\n",
    "                vals_i.append(val)\n",
    "                ix = getSplitVal(infs_i)\n",
    "                if (abs(infs_i[ix]) < score):\n",
    "                    print(\"Column passed: \", col)\n",
    "                    print(\"Val: \", val)\n",
    "                    splitCol = col\n",
    "                    splitIdx = i\n",
    "                    score = abs(infs_i[ix])\n",
    "        infs.append(infs_i)\n",
    "        vals.append(vals_i)\n",
    "        idxs.append(idxs_i)\n",
    "    return {'splitCol':splitCol, 'numRows':numRows, \n",
    "            'infs': infs[splitIdx], 'vals': vals[splitIdx], 'idxs': idxs[splitIdx]}\n",
    "\n",
    "def partition(node, maxDepth, minSize, depth, cols, cols_continuous, \n",
    "              X_train_, y_train_, X_train, X_test_, X_test, method):\n",
    "    print(\"Depth: \", depth)\n",
    "    if depth >= maxDepth or node['numRows'] < minSize:\n",
    "        node['children'] = None\n",
    "        return\n",
    "    col = node['splitCol']\n",
    "    if col not in cols_continuous:\n",
    "        vals = X_train_[col].unique()\n",
    "        child = [None] * len(vals)\n",
    "        for i in range(len(vals)):\n",
    "            idx = X_train_[X_train_[col] == vals[i]].index \n",
    "            X = X_train.drop(index=idx, inplace=False)\n",
    "            y = y_train.drop(index=idx, inplace=False)\n",
    "            X_ = X_train_.drop(index=idx, inplace=False)\n",
    "            if len(X) < minSize:\n",
    "                node['children'] = None\n",
    "            else:\n",
    "                cols_ = copy.deepcopy(cols)\n",
    "                cols_.remove(col)\n",
    "                child[i] = getSplitAttribute(cols_, cols_continuous,\n",
    "                                             X, y, X_test, X_, X_test_, method)\n",
    "                child[i]['col'] = col\n",
    "                child[i]['val'] = vals[i]\n",
    "                partition(child[i], maxDepth, minSize, depth + 1, cols_, cols_continuous, \n",
    "                  X_, y, X, X_test_, X_test, method)\n",
    "    node['children'] = child\n",
    "\n",
    "def buildTree(X_train_, X_train, maxDepth, minSize, method):\n",
    "    cols = copy.deepcopy(X_train_.columns).tolist()\n",
    "    cols_continuous = ['age', 'hours']\n",
    "    X_train = pd.DataFrame(data=X_train, columns=X_train_orig.columns)\n",
    "    cols = list(set(cols) - set(cols_continuous))\n",
    "    root = getSplitAttribute(cols, cols_continuous,\n",
    "                             X_train, y_train, X_test, X_train_, X_test_, method)\n",
    "    print(root)\n",
    "    partition(root, maxDepth, minSize, 1, cols, cols_continuous,\n",
    "              X_train_, y_train_, X_train, X_test_, X_test, method)\n",
    "    return root\n",
    "\n",
    "method = 1\n",
    "dtree = buildTree(X_train_, X_train, 2, 100, method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'splitCol': 'marital',\n",
       " 'numRows': 30162,\n",
       " 'infs': [-0.2083536018505245,\n",
       "  -0.02827855385557211,\n",
       "  -0.1890788115264716,\n",
       "  -0.20065933554743223,\n",
       "  -0.19875608458881688,\n",
       "  -0.20070750164582,\n",
       "  -0.19730181883177864],\n",
       " 'vals': ['Never-married',\n",
       "  'Married-civ-spouse',\n",
       "  'Divorced',\n",
       "  'Married-spouse-absent',\n",
       "  'Separated',\n",
       "  'Married-AF-spouse',\n",
       "  'Widowed'],\n",
       " 'idxs': [20436, 16097, 25948, 29792, 29223, 30141, 29335],\n",
       " 'children': [{'splitCol': 'gender',\n",
       "   'numRows': 20436,\n",
       "   'infs': [-0.05522396149784553, -0.09339174663761593],\n",
       "   'vals': ['Male', 'Female'],\n",
       "   'idxs': [5470, 14966],\n",
       "   'col': 'marital',\n",
       "   'val': 'Never-married',\n",
       "   'children': None},\n",
       "  {'splitCol': 'occupation',\n",
       "   'numRows': 16097,\n",
       "   'infs': [-0.0089975462644349,\n",
       "    -0.02940095693213822,\n",
       "    -0.04129455247150572,\n",
       "    -0.01219578883237249,\n",
       "    -0.020033867671982286,\n",
       "    -0.013187659058612106,\n",
       "    -0.029191105506546675,\n",
       "    -0.024927399301536438,\n",
       "    -0.026194908337570252,\n",
       "    -0.02611891490945213,\n",
       "    -0.04062035030949793,\n",
       "    -0.04155946504785883,\n",
       "    -0.026674015162344744,\n",
       "    -0.028097924725885404],\n",
       "   'vals': ['Adm-clerical',\n",
       "    'Handlers-cleaners',\n",
       "    'Other-service',\n",
       "    'Prof-specialty',\n",
       "    'Sales',\n",
       "    'Farming-fishing',\n",
       "    'Machine-op-inspct',\n",
       "    'Exec-managerial',\n",
       "    'Tech-support',\n",
       "    'Craft-repair',\n",
       "    'Protective-serv',\n",
       "    'Transport-moving',\n",
       "    'Armed-Forces',\n",
       "    'Priv-house-serv'],\n",
       "   'idxs': [13347,\n",
       "    15204,\n",
       "    13584,\n",
       "    14125,\n",
       "    14144,\n",
       "    15683,\n",
       "    15100,\n",
       "    14500,\n",
       "    15584,\n",
       "    14591,\n",
       "    15832,\n",
       "    15507,\n",
       "    16091,\n",
       "    15969],\n",
       "   'col': 'marital',\n",
       "   'val': 'Married-civ-spouse',\n",
       "   'children': None},\n",
       "  {'splitCol': 'gender',\n",
       "   'numRows': 25948,\n",
       "   'infs': [-0.08535082648751632, -0.09247278611058918],\n",
       "   'vals': ['Male', 'Female'],\n",
       "   'idxs': [7253, 18695],\n",
       "   'col': 'marital',\n",
       "   'val': 'Divorced',\n",
       "   'children': None},\n",
       "  {'splitCol': 'gender',\n",
       "   'numRows': 29792,\n",
       "   'infs': [-0.0994233437389613, -0.12670982665702807],\n",
       "   'vals': ['Male', 'Female'],\n",
       "   'idxs': [9593, 20199],\n",
       "   'col': 'marital',\n",
       "   'val': 'Married-spouse-absent',\n",
       "   'children': None},\n",
       "  {'splitCol': 'gender',\n",
       "   'numRows': 29223,\n",
       "   'infs': [-0.10569201023538384, -0.11201309623842412],\n",
       "   'vals': ['Male', 'Female'],\n",
       "   'idxs': [9208, 20015],\n",
       "   'col': 'marital',\n",
       "   'val': 'Separated',\n",
       "   'children': None},\n",
       "  {'splitCol': 'gender',\n",
       "   'numRows': 30141,\n",
       "   'infs': [-0.12635036811093395, -0.12809545595031435],\n",
       "   'vals': ['Male', 'Female'],\n",
       "   'idxs': [9770, 20371],\n",
       "   'col': 'marital',\n",
       "   'val': 'Married-AF-spouse',\n",
       "   'children': None},\n",
       "  {'splitCol': 'gender',\n",
       "   'numRows': 29335,\n",
       "   'infs': [-0.1158902922570635, -0.11684756683883646],\n",
       "   'vals': ['Male', 'Female'],\n",
       "   'idxs': [9096, 20239],\n",
       "   'col': 'marital',\n",
       "   'val': 'Widowed',\n",
       "   'children': None}]}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
