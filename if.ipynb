{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Markdown, display\n",
    "import copy\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['age', 'workclass', 'fnlwgt', 'education', 'education.num', 'marital', 'occupation', 'relationship', 'race', 'gender', 'capgain', 'caploss', 'hours', 'country', 'income']\n",
    "df_train = pd.read_csv('adult.data', names=cols, sep=\",\")\n",
    "df_test = pd.read_csv('adult.test', names=cols, sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    " def preprocess(df):\n",
    "    df.isin(['?']).sum(axis=0)\n",
    "\n",
    "    # replace missing values (?) to nan and then drop the columns\n",
    "    df['country'] = df['country'].replace('?',np.nan)\n",
    "    df['workclass'] = df['workclass'].replace('?',np.nan)\n",
    "    df['occupation'] = df['occupation'].replace('?',np.nan)\n",
    "\n",
    "    # dropping the NaN rows now\n",
    "    df.dropna(how='any',inplace=True)\n",
    "            \n",
    "    df['income'] = df['income'].map({'<=50K': 0, '>50K': 1}).astype(int)\n",
    "    df['gender'] = df['gender'].map({'Male': 1, 'Female': 0}).astype(int)\n",
    "    df['workclass'] = df['workclass'].map({'State-gov': 0, 'Self-emp-not-inc': 1, 'Private': 2, 'Federal-gov': 3, 'Local-gov': 4, '?': 5,\n",
    "                                           'Self-emp-inc': 6, 'Without-pay': 7, 'Never-worked': 8}).astype(int)\n",
    "    df['education'] = df['education'].map({'Bachelors': 0, 'HS-grad': 1, '11th': 2, 'Masters': 3, '9th': 4, \n",
    "                                           'Some-college': 5, 'Assoc-acdm': 6, 'Assoc-voc': 7, '7th-8th': 8, 'Doctorate': 9, \n",
    "                                           'Prof-school': 10, '5th-6th': 11, '10th': 12, '1st-4th': 13, 'Preschool': 14, '12th': 15}).astype(int)\n",
    "    df['marital'] = df['marital'].map({'Never-married': 0, 'Married-civ-spouse': 1, 'Divorced': 2, 'Married-spouse-absent': 3, \n",
    "                                                     'Separated': 4, 'Married-AF-spouse': 5, 'Widowed': 6}).astype(int)\n",
    "    df['occupation'] = df['occupation'].map({'Adm-clerical': 0, 'Exec-managerial': 1, 'Handlers-cleaners': 2, \n",
    "                                             'Prof-specialty': 3, 'Other-service': 4, 'Sales': 5, 'Craft-repair': 6, 'Transport-moving': 7, 'Farming-fishing': 8, \n",
    "                                             'Machine-op-inspct': 9, 'Tech-support': 10, '?': 11, 'Protective-serv': 12, 'Armed-Forces': 13, 'Priv-house-serv': 14}).astype(int)\n",
    "    df['relationship'] = df['relationship'].map({'Not-in-family': 0, 'Husband': 1, 'Wife': 2, \n",
    "                                                 'Own-child': 3, 'Unmarried': 4, 'Other-relative': 5}).astype(int)\n",
    "    df['race'] = df['race'].map({'White': 0, 'Black': 1, 'Asian-Pac-Islander': 2, 'Amer-Indian-Eskimo': 3, 'Other': 4}).astype(int)\n",
    "    df['country'] = df['country'].map({'United-States': 0, 'Cuba': 1, 'Jamaica': 2, 'India': 3, '?': 4, 'Mexico': 5, 'South': 6, 'Puerto-Rico': 7, \n",
    "                                       'Honduras': 8, 'England': 9, 'Canada': 10, 'Germany': 11, 'Iran': 12, 'Philippines': 13, 'Italy': 14, \n",
    "                                       'Poland': 15, 'Columbia': 16, 'Cambodia': 17, 'Thailand': 18, 'Ecuador': 19, 'Laos': 20, 'Taiwan': 21, \n",
    "                                       'Haiti': 22, 'Portugal': 23, 'Dominican-Republic': 24, 'El-Salvador': 25, 'France': 26, 'Guatemala': 27, \n",
    "                                       'China': 28, 'Japan': 29, 'Yugoslavia': 30, 'Peru': 31, 'Outlying-US(Guam-USVI-etc)': 32, 'Scotland': 33,\n",
    "                                       'Trinadad&Tobago': 34, 'Greece': 35, 'Nicaragua': 36, 'Vietnam': 37, 'Hong': 38, 'Ireland': 39, 'Hungary': 40, \n",
    "                                       'Holand-Netherlands': 41}).astype(int)\n",
    "    \n",
    "    \n",
    "    labels = df['age']\n",
    "    proc = []\n",
    "    for v in labels:\n",
    "            if v <= 30:\n",
    "                proc.append(1)\n",
    "            elif v <= 40:\n",
    "                proc.append(2)\n",
    "            elif v <= 50:\n",
    "                proc.append(3)\n",
    "            else:\n",
    "                proc.append(4)\n",
    "    df['age']=proc \n",
    "    \n",
    "    labels = df['hours']\n",
    "    proc=[]\n",
    "    for v in labels:\n",
    "        if v<=25:\n",
    "            proc.append(1)\n",
    "        elif v<=41:\n",
    "            proc.append(2)\n",
    "        elif v<=55:\n",
    "            proc.append(3)\n",
    "        else:\n",
    "            proc.append(4)\n",
    "    df['hours']=proc\n",
    "    \n",
    "    df = df.drop(['fnlwgt', 'education.num', 'capgain', 'caploss', 'country'], axis = 1, inplace = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One-hot encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    " def one_hot_encode(df):\n",
    "    df.isin(['?']).sum(axis=0)\n",
    "\n",
    "    # replace missing values (?) to nan and then drop the columns\n",
    "    df['country'] = df['country'].replace('?',np.nan)\n",
    "    df['workclass'] = df['workclass'].replace('?',np.nan)\n",
    "    df['occupation'] = df['occupation'].replace('?',np.nan)\n",
    "\n",
    "    # dropping the NaN rows now\n",
    "    df.dropna(how='any',inplace=True)\n",
    "    df['income'] = df['income'].map({'<=50K': 0, '>50K': 1}).astype(int)\n",
    "    df = pd.concat([df, pd.get_dummies(df['gender'], prefix='gender')],axis=1)\n",
    "    df = pd.concat([df, pd.get_dummies(df['race'], prefix='race')],axis=1)\n",
    "    df = pd.concat([df, pd.get_dummies(df['marital'], prefix='marital')],axis=1)\n",
    "    df = pd.concat([df, pd.get_dummies(df['workclass'], prefix='workclass')],axis=1)\n",
    "    df = pd.concat([df, pd.get_dummies(df['relationship'], prefix='relationship')],axis=1)\n",
    "    df = pd.concat([df, pd.get_dummies(df['occupation'], prefix='occupation')],axis=1)\n",
    "\n",
    "    df = df.drop(columns=['workclass', 'gender', 'fnlwgt', 'education', 'occupation', \\\n",
    "                      'relationship', 'marital', 'race', 'country', 'capgain', \\\n",
    "                      'caploss'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not one-hot (for randomforestclassifier and such)\n",
    "# preprocess(df_train)\n",
    "# preprocess(df_test)\n",
    "\n",
    "# one-hot encoding (for regression mdoels)\n",
    "df_train = one_hot_encode(df_train)\n",
    "df_test = one_hot_encode(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parametric Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns='income')\n",
    "y_train = df_train['income']\n",
    "\n",
    "X_test = df_test.drop(columns='income')\n",
    "y_test = df_test['income']\n",
    "\n",
    "# Scale data\n",
    "X_train = preprocessing.scale(X_train)\n",
    "X_test = preprocessing.scale(X_test)\n",
    "\n",
    "# clf = RandomForestClassifier(max_depth=10, random_state=0)\n",
    "\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.pipeline import make_pipeline\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# clf = make_pipeline(StandardScaler(), SVC(gamma='auto'))\n",
    "\n",
    "# Logistic regression?\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression(random_state=0)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict_proba(X_test)\n",
    "num_params = len(clf.coef_.transpose())\n",
    "# print(classification_report(y_test, y_pred, target_names=['0', '1']))\n",
    "# clf.classes_\n",
    "# clf.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss function**\n",
    "\n",
    "Twice differentiable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3609074672032075\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "def logistic_loss(y_test, y_pred):\n",
    "    loss = 0\n",
    "    for i in range(len(y_test)):\n",
    "        loss += - y_test[i] * math.log(y_pred[i][1]) - (1 - y_test[i]) * math.log(y_pred[i][0])\n",
    "    return loss/len(y_test)\n",
    "\n",
    "print(logistic_loss(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First-order derivative of loss function at z with respect to model parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_L_del_theta_i(num_params, y_true, x, y_pred):\n",
    "    del_L_del_theta = []\n",
    "    for j in range(num_params):\n",
    "        del_L_del_theta_j = ((1 - y_true) * y_pred[0] + y_true * (1 - y_pred[1])) * x[j]\n",
    "        del_L_del_theta.append(del_L_del_theta_j)\n",
    "    return del_L_del_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_gradient_at_z(clf.coef_, y_train[0], X_train[0], clf.predict_proba(X_train[0]))\n",
    "# print(len(clf.coef_.transpose()))\n",
    "# print(y_train[0])\n",
    "# print(X_train[0][4])\n",
    "# print(clf.predict_proba(np.reshape(X_train[0], (1, 44))))\n",
    "\n",
    "y_pred = clf.predict_proba(np.reshape(X_train[0], (1, num_params)))\n",
    "# print(y_pred[0][0])\n",
    "loss_grad_at_z = del_L_del_theta_i(num_params, y_train[0], X_train[0], y_pred[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Second-order partial derivative of loss function with respect to model parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "def hessian_one_point(num_params, y_true, x, y_pred):\n",
    "    multiplier = y_pred[0] * y_pred[1]\n",
    "    Hx = numpy.zeros((num_params, num_params))\n",
    "    for i in range(num_params):\n",
    "        for j in range(i + 1):\n",
    "            Hx[i][j] = x[i] * x[j]\n",
    "    \n",
    "    i_lower = np.tril_indices(num_params, -1)\n",
    "    Hx.T[i_lower] = Hx[i_lower]     \n",
    "    return Hx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hessian matrix of loss function with respect to model parameters**\n",
    "\n",
    "Verified symmetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hessian(num_params, X_train, y_train):\n",
    "    H = numpy.zeros((num_params, num_params))\n",
    "    for i in range(len(X_train)):\n",
    "        y_pred = clf.predict_proba(np.reshape(X_train[i], (1, num_params)))\n",
    "        H += hessian_one_point(num_params, y_train[i], X_train[i], y_pred[0])\n",
    "    H /= len(X_train)\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "hxx = compute_hessian(num_params, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.04352609,  0.10159876, ..., -0.02931911,\n",
       "        -0.01847592,  0.03239653],\n",
       "       [ 0.04352609,  1.        ,  0.15252207, ...,  0.02548368,\n",
       "         0.05856886, -0.12592687],\n",
       "       [ 0.10159876,  0.15252207,  1.        , ..., -0.00514497,\n",
       "        -0.02148375,  0.07279196],\n",
       "       ...,\n",
       "       [-0.02931911,  0.02548368, -0.00514497, ...,  1.        ,\n",
       "        -0.06484214, -0.08610771],\n",
       "       [-0.01847592,  0.05856886, -0.02148375, ..., -0.06484214,\n",
       "         1.        , -0.04140508],\n",
       "       [ 0.03239653, -0.12592687,  0.07279196, ..., -0.08610771,\n",
       "        -0.04140508,  1.        ]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
