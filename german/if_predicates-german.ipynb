{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T07:40:04.647041Z",
     "start_time": "2021-06-26T07:40:01.293015Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import copy\n",
    "import random\n",
    "import math\n",
    "from scipy import stats\n",
    "from scipy.stats import rankdata\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import classification_report\n",
    "from operator import itemgetter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Markdown, display\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T07:40:04.677031Z",
     "start_time": "2021-06-26T07:40:04.652185Z"
    }
   },
   "outputs": [],
   "source": [
    "cols = ['status', 'duration', 'credit_hist', 'purpose', 'credit_amt', 'savings', 'employment', 'install_rate', 'personal_status', 'debtors', 'residence', 'property', 'age', 'install_plans', 'housing', 'num_credits', 'job', 'num_liable', 'telephone', 'foreign_worker', 'credit']\n",
    "df = pd.read_table('german.data', names=cols, sep=\" \", index_col=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-processing** (categorical to numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T07:40:04.777754Z",
     "start_time": "2021-06-26T07:40:04.679282Z"
    }
   },
   "outputs": [],
   "source": [
    " def preprocess(df):\n",
    "    df['status'] = df['status'].map({'A11': 0, 'A12': 1, 'A13': 2, 'A14': 3}).astype(int)\n",
    "    \n",
    "    df.loc[(df['duration'] <= 12), 'duration'] = 0\n",
    "    df.loc[(df['duration'] > 12) & (df['duration'] <= 24), 'duration'] = 1\n",
    "    df.loc[(df['duration'] > 24) & (df['duration'] <= 36), 'duration'] = 2\n",
    "    df.loc[(df['duration'] > 36), 'duration'] = 3    \n",
    "    \n",
    "    df['credit_hist'] = df['credit_hist'].map({'A34': 0, 'A33': 1, 'A32': 2, 'A31': 3, 'A30': 4}).astype(int)    \n",
    "    df = pd.concat([df, pd.get_dummies(df['purpose'], prefix='purpose')],axis=1)\n",
    "\n",
    "    df.loc[(df['credit_amt'] <= 2000), 'credit_amt'] = 0\n",
    "    df.loc[(df['credit_amt'] > 2000) & (df['credit_amt'] <= 5000), 'credit_amt'] = 1\n",
    "    df.loc[(df['credit_amt'] > 5000), 'credit_amt'] = 2    \n",
    "    \n",
    "    df['savings'] = df['savings'].map({'A61': 0, 'A62': 1, 'A63': 2, 'A64': 3, 'A65': 4}).astype(int)\n",
    "    df['employment'] = df['employment'].map({'A71': 0, 'A72': 1, 'A73': 2, 'A74': 3, 'A75': 4}).astype(int)    \n",
    "    df['gender'] = df['personal_status'].map({'A91': 1, 'A92': 0, 'A93': 1, 'A94': 1, 'A95': 0}).astype(int)\n",
    "    df['debtors'] = df['debtors'].map({'A101': 0, 'A102': 1, 'A103': 2}).astype(int)\n",
    "    df['property'] = df['property'].map({'A121': 3, 'A122': 2, 'A123': 1, 'A124': 0}).astype(int)        \n",
    "    df['age'] = df['age'].apply(lambda x : 1 if x >= 45 else 0) # 1 if old, 0 if young\n",
    "    df['install_plans'] = df['install_plans'].map({'A141': 1, 'A142': 1, 'A143': 0}).astype(int)\n",
    "    df = pd.concat([df, pd.get_dummies(df['housing'], prefix='housing')],axis=1)\n",
    "    df['job'] = df['job'].map({'A171': 0, 'A172': 1, 'A173': 2, 'A174': 3}).astype(int)    \n",
    "    df['telephone'] = df['telephone'].map({'A191': 0, 'A192': 1}).astype(int)\n",
    "    df['foreign_worker'] = df['foreign_worker'].map({'A201': 1, 'A202': 0}).astype(int)\n",
    "    \n",
    "    df['credit'] = df['credit'].replace(2, 0) #1 = Good, 2= Bad credit risk\n",
    "\n",
    "#     process age\n",
    "#     df.loc[(df['age'] >= 15) & (df['age'] <= 24) , 'age'] = 0\n",
    "#     df.loc[(df['age'] >= 25) & (df['age'] <= 34) , 'age'] = 1\n",
    "#     df.loc[(df['age'] >= 35) & (df['age'] <= 44) , 'age'] = 2\n",
    "#     df.loc[(df['age'] >= 45) & (df['age'] <= 54) , 'age'] = 3\n",
    "#     df.loc[(df['age'] >= 55) & (df['age'] <= 64) , 'age'] = 4\n",
    "#     df.loc[(df['age'] >= 65) , 'age'] = 5\n",
    "\n",
    "    return df\n",
    "\n",
    "df = preprocess(df)\n",
    "df_orig = copy.deepcopy(df)\n",
    "\n",
    "y = df['credit']\n",
    "df = df.drop(columns=['purpose', 'personal_status', 'housing', 'credit'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.2, random_state=1)\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n",
    "y_train = y_train.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Protected, privileged**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T07:40:04.786830Z",
     "start_time": "2021-06-26T07:40:04.782414Z"
    }
   },
   "outputs": [],
   "source": [
    "# protected: 'gender'=0\n",
    "# privileged: 'gender'=1\n",
    "\n",
    "# protected: 'age'=0\n",
    "# privileged: 'age'=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parametric Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T07:40:04.809704Z",
     "start_time": "2021-06-26T07:40:04.796352Z"
    }
   },
   "outputs": [],
   "source": [
    "# size=500\n",
    "# X_train = X_train[0:size]\n",
    "# y_train = y_train[0:size]\n",
    "\n",
    "X_train_orig = copy.deepcopy(X_train)\n",
    "X_test_orig = copy.deepcopy(X_test)\n",
    "\n",
    "# Scale data: regularization penalty default: ‘l2’, ‘lbfgs’ solvers support only l2 penalties. \n",
    "# Regularization makes the predictor dependent on the scale of the features.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression(random_state=0, max_iter=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute fairness metric**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T07:40:04.847928Z",
     "start_time": "2021-06-26T07:40:04.823895Z"
    }
   },
   "outputs": [],
   "source": [
    "def computeFairness(y_pred, X_test, y_test, metric): \n",
    "    fairnessMetric = 0\n",
    "    protected_idx = X_test[X_test['age']==0].index\n",
    "    numProtected = len(protected_idx)\n",
    "    privileged_idx = X_test[X_test['age']==1].index\n",
    "    numPrivileged = len(privileged_idx)\n",
    "        \n",
    "    p_protected = 0\n",
    "    for i in range(len(protected_idx)):\n",
    "        p_protected += y_pred[protected_idx[i]][1]\n",
    "    p_protected /= len(protected_idx)\n",
    "    \n",
    "    p_privileged = 0\n",
    "    for i in range(len(privileged_idx)):\n",
    "        p_privileged += y_pred[privileged_idx[i]][1]\n",
    "    p_privileged /= len(privileged_idx)\n",
    "    \n",
    "    # statistical parity difference\n",
    "    statistical_parity = p_protected - p_privileged\n",
    "    \n",
    "    # equality of opportunity, or \n",
    "    # true positive rate parity\n",
    "    # P(Y=1 | Y=1, G=0)- P(Y=1 | Y=1, G=1)\n",
    "    true_positive_protected = 0\n",
    "    actual_positive_protected = 0\n",
    "    for i in range(len(protected_idx)):\n",
    "        if (y_test[protected_idx[i]] == 1):\n",
    "            actual_positive_protected += 1\n",
    "#             if (y_pred[protected_idx[i]][1] > y_pred[protected_idx[i]][0]):\n",
    "            true_positive_protected += y_pred[protected_idx[i]][1]\n",
    "    tpr_protected = true_positive_protected/actual_positive_protected\n",
    "    \n",
    "    true_positive_privileged = 0\n",
    "    actual_positive_privileged = 0\n",
    "    for i in range(len(privileged_idx)):\n",
    "        if (y_test[privileged_idx[i]] == 1):\n",
    "            actual_positive_privileged += 1\n",
    "#             if (y_pred[privileged_idx[i]][1] > y_pred[privileged_idx[i]][0]):\n",
    "            true_positive_privileged += y_pred[privileged_idx[i]][1]\n",
    "    tpr_privileged = true_positive_privileged/actual_positive_privileged\n",
    "    \n",
    "    tpr_parity = tpr_protected - tpr_privileged\n",
    "    \n",
    "    # equalized odds or TPR parity + FPR parity\n",
    "    # false positive rate parity\n",
    "    \n",
    "    # predictive parity\n",
    "    p_o1_y1_s1 = 0\n",
    "    p_o1_s1 = 0\n",
    "    for i in range(len(protected_idx)):\n",
    "#         if (y_pred[protected_idx[i]][1] > y_pred[protected_idx[i]][0]):\n",
    "        p_o1_s1 += y_pred[protected_idx[i]][1]\n",
    "        if (y_test[protected_idx[i]] == 1):\n",
    "            p_o1_y1_s1 += y_pred[protected_idx[i]][1]\n",
    "    ppv_protected = p_o1_y1_s1/p_o1_s1\n",
    "    \n",
    "    p_o1_y1_s0 = 0\n",
    "    p_o1_s0 = 0\n",
    "    for i in range(len(privileged_idx)):\n",
    "#         if (y_pred[privileged_idx[i]][1] > y_pred[privileged_idx[i]][0]):\n",
    "        p_o1_s0 += y_pred[privileged_idx[i]][1]\n",
    "        if (y_test[privileged_idx[i]] == 1):\n",
    "            p_o1_y1_s0 += y_pred[privileged_idx[i]][1]\n",
    "    ppv_privileged = p_o1_y1_s0/p_o1_s0\n",
    "    \n",
    "    predictive_parity = ppv_protected - ppv_privileged\n",
    "    \n",
    "    if (metric == 0):\n",
    "        fairnessMetric = statistical_parity\n",
    "    elif (metric == 1):\n",
    "        fairnessMetric = tpr_parity\n",
    "    elif (metric == 2):\n",
    "        fairnessMetric = predictive_parity\n",
    "        \n",
    "    return fairnessMetric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Influence of points computed using ground truth**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T07:40:04.864566Z",
     "start_time": "2021-06-26T07:40:04.850827Z"
    }
   },
   "outputs": [],
   "source": [
    "def ground_truth_influence(X_train, y_train, X_test, X_test_orig, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict_proba(X_test)\n",
    "    spd_0 = computeFairness(y_pred, X_test_orig, y_test, 0)\n",
    "\n",
    "    delta_spd = []\n",
    "    for i in range(len(X_train)):\n",
    "        X_removed = np.delete(X_train, i, 0)\n",
    "        y_removed = y_train.drop(index=i, inplace=False)\n",
    "        clf.fit(X_removed, y_removed)\n",
    "        y_pred = clf.predict_proba(X_test)\n",
    "        delta_spd_i = computeFairness(y_pred, X_test_orig, y_test, 0) - spd_0\n",
    "        delta_spd.append(delta_spd_i)\n",
    "    \n",
    "    return delta_spd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss function** (Log loss for logistic regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T07:40:04.876110Z",
     "start_time": "2021-06-26T07:40:04.867464Z"
    }
   },
   "outputs": [],
   "source": [
    "def logistic_loss(y_true, y_pred):\n",
    "    loss = 0\n",
    "    for i in range(len(y_true)):\n",
    "        if (y_pred[i][1] != 0 and y_pred[i][0] != 0):\n",
    "            loss += - y_true[i] * math.log(y_pred[i][1]) - (1 - y_true[i]) * math.log(y_pred[i][0])\n",
    "    loss /= len(y_true)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute Accuracy** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T07:40:04.888240Z",
     "start_time": "2021-06-26T07:40:04.880075Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def computeAccuracy(y_true, y_pred):\n",
    "    accuracy = 0\n",
    "    for i in range(len(y_true)):\n",
    "        idx = y_true[i]\n",
    "        if (y_pred[i][idx] > y_pred[i][1 - idx]):\n",
    "            accuracy += 1\n",
    "#         accuracy += y_pred[i][idx]\n",
    "    accuracy /= len(y_true)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First-order derivative of loss function at z with respect to model parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T07:40:04.899745Z",
     "start_time": "2021-06-26T07:40:04.891065Z"
    }
   },
   "outputs": [],
   "source": [
    "def del_L_del_theta_i(num_params, y_true, x, y_pred):\n",
    "#     del_L_del_theta = np.ones((num_params, 1)) * ((1 - y_true) * y_pred[1] - y_true * y_pred[0])\n",
    "    del_L_del_theta = np.ones((num_params, 1)) * (- y_true + y_pred[1])\n",
    "    for j in range(1, num_params):\n",
    "            del_L_del_theta[j] *=  x[j-1]\n",
    "    return del_L_del_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hessian: Second-order partial derivative of loss function with respect to model parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T07:40:04.916950Z",
     "start_time": "2021-06-26T07:40:04.903295Z"
    }
   },
   "outputs": [],
   "source": [
    "def hessian_one_point(num_params, x, y_pred):\n",
    "    H = np.ones((num_params, num_params)) * (y_pred[0] * y_pred[1])\n",
    "    for i in range(1, num_params):\n",
    "        for j in range(i + 1):\n",
    "            if j == 0:\n",
    "                H[i][j] *= x[i-1]\n",
    "            else:\n",
    "                H[i][j] *= x[i-1] * x[j-1] \n",
    "    i_lower = np.tril_indices(num_params, -1)\n",
    "    H.T[i_lower] = H[i_lower]     \n",
    "    return H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First-order derivative of $P(y \\mid \\textbf{x})$ with respect to model parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T07:40:04.927323Z",
     "start_time": "2021-06-26T07:40:04.919452Z"
    }
   },
   "outputs": [],
   "source": [
    "def del_f_del_theta_i(num_params, x, y_pred):\n",
    "    del_f_del_theta = np.ones((num_params, 1)) * (y_pred[0] * y_pred[1])\n",
    "    for j in range(1, num_params):\n",
    "            del_f_del_theta[j] *=  x[j-1]\n",
    "    return del_f_del_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Computing $v=\\nabla($Statistical parity difference$)$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T07:40:04.945197Z",
     "start_time": "2021-06-26T07:40:04.930439Z"
    }
   },
   "outputs": [],
   "source": [
    "# Return v = del(SPD)/del(theta)\n",
    "def del_spd_del_theta(num_params, X_test_orig, X_test, y_pred):\n",
    "    del_f_protected = np.zeros((num_params, 1))\n",
    "    del_f_privileged = np.zeros((num_params, 1))\n",
    "    numPrivileged = X_test_orig['age'].sum()\n",
    "    numProtected = len(X_test_orig) - numPrivileged\n",
    "    for i in range(len(X_test)):\n",
    "        del_f_i = del_f_del_theta_i(num_params, X_test[i], y_pred[i])\n",
    "        if X_test_orig.iloc[i]['age'] == 1: #privileged\n",
    "            del_f_privileged = np.add(del_f_privileged, del_f_i)\n",
    "        elif X_test_orig.iloc[i]['age'] == 0:\n",
    "            del_f_protected = np.add(del_f_protected, del_f_i)\n",
    "    del_f_privileged /= numPrivileged\n",
    "    del_f_protected /= numProtected\n",
    "    v = np.subtract(del_f_protected, del_f_privileged)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Computing $v=\\nabla($TPR parity difference$)$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T07:40:04.968801Z",
     "start_time": "2021-06-26T07:40:04.951055Z"
    }
   },
   "outputs": [],
   "source": [
    "# Return v = del(TPR_parity)/del(theta)\n",
    "def del_tpr_parity_del_theta(num_params, X_test_orig, X_test, y_pred, y_test):\n",
    "    del_f_protected = np.zeros((num_params, 1))\n",
    "    del_f_privileged = np.zeros((num_params, 1))\n",
    "    \n",
    "    protected_idx = X_test_orig[X_test_orig['age']==0].index\n",
    "    privileged_idx = X_test_orig[X_test_orig['age']==1].index\n",
    "\n",
    "    actual_positive_privileged = 0\n",
    "    for i in range(len(privileged_idx)):\n",
    "        if (y_test[privileged_idx[i]] == 1):\n",
    "            actual_positive_privileged += 1\n",
    "#             if (y_pred[privileged_idx[i]][1] > y_pred[privileged_idx[i]][0]):\n",
    "            del_f_i = del_f_del_theta_i(num_params, X_test[privileged_idx[i]], y_pred[privileged_idx[i]])\n",
    "            del_f_privileged = np.add(del_f_privileged, del_f_i)\n",
    "    del_f_privileged /= actual_positive_privileged\n",
    "    \n",
    "    actual_positive_protected = 0\n",
    "    for i in range(len(protected_idx)):\n",
    "        if (y_test[protected_idx[i]] == 1):\n",
    "            actual_positive_protected += 1\n",
    "#             if (y_pred[protected_idx[i]][1] > y_pred[protected_idx[i]][0]):\n",
    "            del_f_i = del_f_del_theta_i(num_params, X_test[protected_idx[i]], y_pred[protected_idx[i]])\n",
    "            del_f_protected = np.add(del_f_protected, del_f_i)\n",
    "    del_f_protected /= actual_positive_protected\n",
    "\n",
    "    v = np.subtract(del_f_protected, del_f_privileged)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Computing $v=\\nabla($Predictive parity difference$)$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T07:40:05.014735Z",
     "start_time": "2021-06-26T07:40:04.990397Z"
    }
   },
   "outputs": [],
   "source": [
    "# Return v = del(Predictive_parity)/del(theta)\n",
    "def del_predictive_parity_del_theta(num_params, X_test_orig, X_test, y_pred, y_test):\n",
    "    del_f_protected = np.zeros((num_params, 1))\n",
    "    del_f_privileged = np.zeros((num_params, 1))\n",
    "    \n",
    "    protected_idx = X_test_orig[X_test_orig['age']==0].index\n",
    "    privileged_idx = X_test_orig[X_test_orig['age']==1].index\n",
    "\n",
    "    u_dash_protected = np.zeros((num_params, 1))\n",
    "    v_protected = 0\n",
    "    v_dash_protected = np.zeros((num_params, 1))\n",
    "    u_protected = 0\n",
    "    for i in range(len(protected_idx)):\n",
    "        del_f_i = del_f_del_theta_i(num_params, X_test[protected_idx[i]], y_pred[protected_idx[i]])\n",
    "#         if (y_pred[protected_idx[i]][1] > y_pred[protected_idx[i]][0]):\n",
    "        v_protected += y_pred[protected_idx[i]][1]\n",
    "        v_dash_protected = np.add(v_dash_protected, del_f_i)\n",
    "        if (y_test[protected_idx[i]] == 1):\n",
    "            u_dash_protected = np.add(u_dash_protected, del_f_i)\n",
    "            u_protected += y_pred[protected_idx[i]][1]\n",
    "    del_f_protected = (u_dash_protected * v_protected - u_protected * v_dash_protected)/(v_protected * v_protected)\n",
    "    \n",
    "    u_dash_privileged = np.zeros((num_params, 1))\n",
    "    v_privileged = 0\n",
    "    v_dash_privileged = np.zeros((num_params, 1))\n",
    "    u_privileged = 0\n",
    "    for i in range(len(privileged_idx)):\n",
    "        del_f_i = del_f_del_theta_i(num_params, X_test[privileged_idx[i]], y_pred[privileged_idx[i]])\n",
    "#         if (y_pred[privileged_idx[i]][1] > y_pred[privileged_idx[i]][0]):\n",
    "        v_privileged += y_pred[privileged_idx[i]][1]\n",
    "        v_dash_privileged = np.add(v_dash_privileged, del_f_i)\n",
    "        if (y_test[privileged_idx[i]] == 1):\n",
    "            u_dash_privileged = np.add(u_dash_privileged, del_f_i)\n",
    "            u_privileged += y_pred[privileged_idx[i]][1]\n",
    "    del_f_privileged = (u_dash_privileged * v_privileged - u_privileged * v_dash_privileged)/(v_privileged * v_privileged)\n",
    "    \n",
    "    v = np.subtract(del_f_protected, del_f_privileged)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stochastic estimation of Hessian vector product (involving del fairness): $H_{\\theta}^{-1}v = H_{\\theta}^{-1}\\nabla_{\\theta}f(z, \\theta) = v + [I - \\nabla_{\\theta}^2L(z_{s_j}, \\theta^*)]H_{\\theta}^{-1}v$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T07:40:05.090932Z",
     "start_time": "2021-06-26T07:40:05.082709Z"
    }
   },
   "outputs": [],
   "source": [
    "# Uniformly sample t points from training data \n",
    "def hessian_vector_product(num_params, n, size, v, hessian_all_points):\n",
    "    if (size > n):\n",
    "        size = n\n",
    "    sample = random.sample(range(n), size)\n",
    "    hinv_v = copy.deepcopy(v)\n",
    "    for idx in range(size):\n",
    "        i = sample[idx]\n",
    "        hessian_i = hessian_all_points[i]\n",
    "        hinv_v = np.matmul(np.subtract(np.identity(num_params), hessian_i), hinv_v)\n",
    "        hinv_v = np.add(hinv_v, v)\n",
    "    return hinv_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First-order influence computation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T07:40:05.813097Z",
     "start_time": "2021-06-26T07:40:05.804689Z"
    }
   },
   "outputs": [],
   "source": [
    "def first_order_influence(del_L_del_theta, hinv_v, n):\n",
    "    infs = []\n",
    "    for i in range(n):\n",
    "        inf = -np.dot(del_L_del_theta[i].transpose(), hinv_v)\n",
    "        inf *= -1/n\n",
    "        infs.append(inf[0][0].tolist())\n",
    "    return infs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Second-order influence computation for a group of points in subset U**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T07:40:06.424844Z",
     "start_time": "2021-06-26T07:40:06.404358Z"
    }
   },
   "outputs": [],
   "source": [
    "def second_order_influence(X_train, U, size, del_L_del_theta, hessian_all_points):\n",
    "    u = len(U)\n",
    "    s = len(X_train)\n",
    "    p = u/s\n",
    "    c1 = (1 - 2*p)/(s * (1-p)**2)\n",
    "    c2 = 1/((s * (1-p))**2)\n",
    "    num_params = len(del_L_del_theta[0])\n",
    "    del_L_del_theta_hinv = np.zeros((num_params, 1))\n",
    "    del_L_del_theta_sum = np.zeros((num_params, 1))\n",
    "    hessian_U = np.zeros((num_params, num_params))\n",
    "    for i in range(u):\n",
    "        idx = U[i]\n",
    "        hessian_U = np.add(hessian_U, s * hessian_all_points[idx])\n",
    "        del_L_del_theta_sum = np.add(del_L_del_theta_sum, del_L_del_theta[idx])\n",
    "    \n",
    "    hinv_del_L_del_theta= np.matmul(hinv_exact, del_L_del_theta_sum)\n",
    "    hinv_hessian_U = np.matmul(hinv_exact, hessian_U)\n",
    "    term1 = c1 * hinv_del_L_del_theta\n",
    "    term2 = c2 * np.matmul(hinv_hessian_U, hinv_del_L_del_theta)\n",
    "    sum_term = np.add(term1, term2)\n",
    "    return sum_term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Metrics: Initial state**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T07:40:06.644526Z",
     "start_time": "2021-06-26T07:40:06.561979Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial statistical parity:  -0.11221257233724657\n",
      "Initial TPR parity:  -0.08652218596293215\n",
      "Initial predictive parity:  -0.09399734636476853\n",
      "Initial loss:  0.5060895126027029\n",
      "Initial accuracy:  0.755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "num_params = len(clf.coef_.transpose()) + 1 #weights and intercept; params: clf.coef_, clf.intercept_\n",
    "y_pred_test = clf.predict_proba(X_test)\n",
    "y_pred_train = clf.predict_proba(X_train)\n",
    "\n",
    "spd_0 = computeFairness(y_pred_test, X_test_orig, y_test, 0)\n",
    "print(\"Initial statistical parity: \", spd_0)\n",
    "\n",
    "tpr_parity_0 = computeFairness(y_pred_test, X_test_orig, y_test, 1)\n",
    "print(\"Initial TPR parity: \", tpr_parity_0)\n",
    "\n",
    "predictive_parity_0 = computeFairness(y_pred_test, X_test_orig, y_test, 2)\n",
    "print(\"Initial predictive parity: \", predictive_parity_0)\n",
    "\n",
    "loss_0 = logistic_loss(y_test, y_pred_test)\n",
    "print(\"Initial loss: \", loss_0)\n",
    "\n",
    "accuracy_0 = computeAccuracy(y_test, y_pred_test)\n",
    "print(\"Initial accuracy: \", accuracy_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-compute: (1) Hessian (2) del_L_del_theta for each training data point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T07:40:07.690529Z",
     "start_time": "2021-06-26T07:40:06.722634Z"
    }
   },
   "outputs": [],
   "source": [
    "del_L_del_theta = []\n",
    "for i in range(int(len(X_train))):\n",
    "    del_L_del_theta.insert(i, del_L_del_theta_i(num_params, y_train[i], X_train[i], y_pred_train[i]))\n",
    "\n",
    "hessian_all_points = []\n",
    "for i in range(len(X_train)):\n",
    "    hessian_all_points.insert(i, hessian_one_point(num_params, X_train[i], y_pred_train[i])\n",
    "                              /len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Select delta fairness function depending on selected metric*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T07:40:07.856382Z",
     "start_time": "2021-06-26T07:40:07.693890Z"
    }
   },
   "outputs": [],
   "source": [
    "metric = 0\n",
    "if metric == 0:\n",
    "    v1 = del_spd_del_theta(num_params, X_test_orig, X_test, y_pred_test)\n",
    "elif metric == 1:\n",
    "    v1 = del_tpr_parity_del_theta(num_params, X_test_orig, X_test, y_pred_test, y_test)\n",
    "elif metric == 2:\n",
    "    v1 = del_predictive_parity_del_theta(num_params, X_test_orig, X_test, y_pred_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*H^{-1} computation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T07:40:08.030448Z",
     "start_time": "2021-06-26T07:40:08.019026Z"
    }
   },
   "outputs": [],
   "source": [
    "hexact = 1\n",
    "if hexact == 1: \n",
    "    H_exact = np.zeros((num_params, num_params))\n",
    "    for i in range(len(X_train)):\n",
    "        H_exact = np.add(H_exact, hessian_all_points[i])\n",
    "    hinv_exact = np.linalg.pinv(H_exact) \n",
    "    hinv_v = np.matmul(hinv_exact, v1)\n",
    "else: #using Hessian vector product\n",
    "    size_hvp = int(len(X_train) * .01)\n",
    "    hinv_v = hessian_vector_product(num_params, len(X_train), size_hvp, v1, hessian_all_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First-order influence of each training data point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T07:40:08.620043Z",
     "start_time": "2021-06-26T07:40:08.604397Z"
    }
   },
   "outputs": [],
   "source": [
    "infs_1 = first_order_influence(del_L_del_theta, hinv_v, len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking ground truth, first-order and second-order influences for a set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T07:40:08.783428Z",
     "start_time": "2021-06-26T07:40:08.778057Z"
    }
   },
   "outputs": [],
   "source": [
    "# if metric == 0:\n",
    "#     print(\"Statistical parity \")\n",
    "# elif metric == 1:\n",
    "#     print(\"True positive rate parity \")\n",
    "# elif metric == 2:\n",
    "#     print(\"Predictive parity\")\n",
    "    \n",
    "# active = 1\n",
    "# if active:\n",
    "#     predicates = [ 'age']\n",
    "#     idx=X_train_orig.index \n",
    "#     for pred in predicates:\n",
    "#        idx0 = X_train_orig[(X_train_orig[pred] == 1)].index \n",
    "#        idx=idx.intersection(idx0)\n",
    "      \n",
    "#     print(\"#Rows removed: \", len(idx))\n",
    "#     print(\"#Rows left: \", len(X_train) - len(idx))\n",
    "#     X = np.delete(X_train, idx, 0)\n",
    "#     y = y_train.drop(index=idx, inplace=False)\n",
    "#     clf.fit(X, y)\n",
    "#     y_pred_test = clf.predict_proba(X_test)\n",
    "#     print(\"Ground truth influence of subset (on statistical parity): \", computeFairness(y_pred_test, X_test_orig, y_test, 0) - spd_0)\n",
    "#     print(\"Ground truth influence of subset (on tpr parity): \", computeFairness(y_pred_test, X_test_orig, y_test, 1) - tpr_parity_0)\n",
    "#     print(\"Ground truth influence of subset (on predictive parity): \", computeFairness(y_pred_test, X_test_orig, y_test, 2) - predictive_parity_0)\n",
    "\n",
    "#     del_f_1 = 0\n",
    "#     for i in range(len(idx)):\n",
    "#         del_f_1 += infs_1[idx[i]]\n",
    "#     print(\"First-order influence: \", del_f_1)\n",
    "\n",
    "#     size_hvp = 1\n",
    "#     params_f_2 = second_order_influence(X_train, idx, size_hvp, del_L_del_theta, hessian_all_points)\n",
    "#     del_f_2 = np.dot(v1.transpose(), params_f_2)[0][0]\n",
    "#     print(\"Second-order influence: \", del_f_2)\n",
    "    \n",
    "#     spd_1 = computeFairness(y_pred_test, X_test_orig, y_test, 0)\n",
    "#     print(\"Ground truth statistical parity after removing subset: \", spd_1)\n",
    "    \n",
    "#     tpr_parity_1 = computeFairness(y_pred_test, X_test_orig, y_test, 1)\n",
    "#     print(\"Ground truth tpr parity after removing subset: \", tpr_parity_1)\n",
    "\n",
    "#     predictive_parity_1 = computeFairness(y_pred_test, X_test_orig, y_test, 1)\n",
    "#     print(\"Ground truth predictive parity after removing subset: \", predictive_parity_1)\n",
    "\n",
    "#     loss_1 = logistic_loss(y_test, y_pred_test)\n",
    "#     print(\"Loss after removing subset: \", loss_1)\n",
    "\n",
    "#     accuracy_1 = computeAccuracy(y_test, y_pred_test)\n",
    "#     print(\"Accuracy after removing subset: \", accuracy_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T07:40:08.872454Z",
     "start_time": "2021-06-26T07:40:08.866891Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(spd_0, tpr_parity_0, preditive_parity_0, loss_0, accuracy_0)\n",
    "# print(spd_1, tpr_parity_1, predictive_parity_1, loss_1, accuracy_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fairness: Ground-truth subset influence vs. computed subset influences: Random subset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T07:40:09.656504Z",
     "start_time": "2021-06-26T07:40:09.651939Z"
    }
   },
   "outputs": [],
   "source": [
    "# print(\"Ground-truth subset, Add 1st-order inf individual, Second-order subset influence\")\n",
    "# sampleSize = int(.2 * len(X_train))\n",
    "# for i in range(100):\n",
    "#     idx = random.sample(range(1, len(X_train)), sampleSize) \n",
    "    \n",
    "#     # Ground truth subset influence\n",
    "#     X = np.delete(X_train, idx, 0)\n",
    "#     y = y_train.drop(index=idx, inplace=False)\n",
    "#     clf.fit(X, y)\n",
    "#     y_pred_test = clf.predict_proba(X_test)\n",
    "#     inf_gt = computeFairness(y_pred_test, X_test_orig, y_test, 0) - spd_0\n",
    "    \n",
    "#     # First-order subset influence\n",
    "#     del_f_1 = 0\n",
    "#     for i in range(len(idx)):\n",
    "#         del_f_1 += infs_1[idx[i]]\n",
    "    \n",
    "#     # Second-order subset influence\n",
    "#     size_hvp = 1\n",
    "#     params_f_2 = second_order_influence(X_train, idx, size_hvp, del_L_del_theta, hessian_all_points)\n",
    "#     del_f_2 = np.dot(v1.transpose(), params_f_2)[0][0]\n",
    "    \n",
    "# #     print(inf_gt, del_f_1, del_f_2, sep=\", \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fairness: Ground-truth subset influence vs. computed subset influences: Coherent subset** \n",
    "\n",
    "(by coherent, we mean group of data points that share some properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T07:40:12.962700Z",
     "start_time": "2021-06-26T07:40:11.859967Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute, Value, Ground-truth subset, Add 1st-order inf individual, Second-order subset influence, %rowsRemoved, Accuracy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "attributes = []\n",
    "attributeValues = []\n",
    "second_order_influences = []\n",
    "gt_influences = []\n",
    "fractionRows = []\n",
    "\n",
    "print(\"Attribute, Value, Ground-truth subset, Add 1st-order inf individual, \\\n",
    "Second-order subset influence, %rowsRemoved, Accuracy\")\n",
    "clf.fit(X_train, y_train)\n",
    "continuous_cols = ['duration', 'credit_amt', 'install_rate', 'num_credits', 'residence']\n",
    "for col in X_train_orig.columns:\n",
    "    if \"purpose\" in col or \"housing\" in col: #dummy variables purpose=0 doesn't make sense\n",
    "        vals = [1]\n",
    "    else:\n",
    "        vals = X_train_orig[col].unique()\n",
    "    for val in vals:\n",
    "#         print(col, val, sep=\": \")\n",
    "        idx = X_train_orig[X_train_orig[col] == val].index \n",
    "    \n",
    "        X = np.delete(X_train, idx, 0)\n",
    "        y = y_train.drop(index=idx, inplace=False)\n",
    "        inf_gt = 0\n",
    "        if len(y.unique()) == 1:\n",
    "            print(col, val)\n",
    "        if len(y.unique()) > 1:\n",
    "            # Ground truth subset influence\n",
    "            clf.fit(X, y)\n",
    "            y_pred = clf.predict_proba(X_test)\n",
    "            if metric == 0:\n",
    "                inf_gt = computeFairness(y_pred, X_test_orig, y_test, 0) - spd_0\n",
    "            elif metric == 1:\n",
    "                inf_gt = computeFairness(y_pred, X_test_orig, y_test, 1) - tpr_parity_0\n",
    "            elif metric == 2:\n",
    "                inf_gt = computeFairness(y_pred, X_test_orig, y_test, 2) - predictive_parity_0\n",
    "            accuracy = computeAccuracy(y_test, y_pred)\n",
    "\n",
    "        # First-order subset influence\n",
    "        del_f_1 = 0            \n",
    "        for i in range(len(idx)):\n",
    "            del_f_1 += infs_1[idx[i]]\n",
    "\n",
    "        # Second-order subset influence\n",
    "        size_hvp = 1\n",
    "        params_f_2 = second_order_influence(X_train, idx, size_hvp, del_L_del_theta, hessian_all_points)\n",
    "        del_f_2 = np.dot(v1.transpose(), params_f_2)[0][0]\n",
    "        \n",
    "        attributes.append(col)\n",
    "        attributeValues.append(val)\n",
    "        second_order_influences.append(del_f_2)\n",
    "        gt_influences.append(inf_gt)\n",
    "        fractionRows.append(len(idx)/len(X_train)*100)\n",
    "\n",
    "#         print(col, val, inf_gt, del_f_1, del_f_2, len(idx)/len(X_train), accuracy, sep=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T07:40:15.153125Z",
     "start_time": "2021-06-26T07:40:15.113316Z"
    }
   },
   "outputs": [],
   "source": [
    "expl = [attributes, attributeValues, second_order_influences, gt_influences, fractionRows]\n",
    "expl = (np.array(expl).T).tolist()\n",
    "\n",
    "explanations = pd.DataFrame(expl, columns=[\"attributes\", \"attributeValues\", \"second_order_influences\", \"gt_influences\", \"fractionRows\"])\n",
    "\n",
    "explanations['attributes'] = explanations['attributes'].astype(str)\n",
    "explanations['attributeValues'] = explanations['attributeValues'].astype(int)\n",
    "explanations['second_order_influences'] = explanations['second_order_influences'].astype(float)\n",
    "explanations['gt_influences'] = explanations['gt_influences'].astype(float)\n",
    "explanations['fractionRows'] = explanations['fractionRows'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T07:40:16.928500Z",
     "start_time": "2021-06-26T07:40:16.924425Z"
    }
   },
   "outputs": [],
   "source": [
    "# explanations.sort_values(by=\"second_order_influences\", ascending=False).head(30)\n",
    "# explanations.sort_values(by=\"fractionRows\", ascending=False).head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T07:40:17.352070Z",
     "start_time": "2021-06-26T07:40:17.344557Z"
    }
   },
   "outputs": [],
   "source": [
    "# import scipy.stats as ss\n",
    "# explanations[\"gt_rank\"] = len(explanations) - ss.rankdata(explanations[\"gt_influences\"])\n",
    "# explanations[\"so_rank\"] = len(explanations) - ss.rankdata(explanations[\"second_order_influences\"])\n",
    "# stats.kendalltau(explanations[\"gt_rank\"], explanations[\"so_rank\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T07:40:18.301092Z",
     "start_time": "2021-06-26T07:40:18.283319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha_f_lower: 0.0011221257233724657\n",
      "alpha_f_upper: 0.11221257233724657\n",
      "del_f_threshold: -0.0\n",
      "support_small: 0.3\n",
      "del_f_threshold_small: 0.011221257233724658\n"
     ]
    }
   ],
   "source": [
    "alpha_f_lower = (-0.01) * (spd_0)\n",
    "alpha_f_upper = -spd_0\n",
    "del_f_threshold = (0.0) * spd_0\n",
    "support = 0.05 # Do not consider extremely small patterns\n",
    "support_small = 0.3 # For small patterns, 2nd-order estimation is quite accurate\n",
    "del_f_threshold_small = (-0.1) * (spd_0)\n",
    "print(\"alpha_f_lower:\", alpha_f_lower)\n",
    "print(\"alpha_f_upper:\", alpha_f_upper)\n",
    "print(\"del_f_threshold:\", del_f_threshold)\n",
    "print(\"support_small:\", support_small)\n",
    "print(\"del_f_threshold_small:\", del_f_threshold_small)\n",
    "\n",
    "candidates = explanations[(explanations[\"second_order_influences\"] > alpha_f_lower) \n",
    "                           & (explanations[\"second_order_influences\"] < alpha_f_upper)]\n",
    "candidates = copy.deepcopy(explanations)\n",
    "candidates.loc[:, 'score'] = candidates.loc[:, 'second_order_influences']*100/candidates.loc[:, 'fractionRows']\n",
    "# display(candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lattice generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T07:40:20.673280Z",
     "start_time": "2021-06-26T07:40:20.640582Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated:  74  1-candidates\n"
     ]
    }
   ],
   "source": [
    "candidates_1 = []\n",
    "for i in range(len(candidates)):\n",
    "    candidate = []\n",
    "    candidate_i = candidates.iloc[i]\n",
    "#     if ((candidate_i[\"second_order_influences\"] > del_f_threshold) & \n",
    "#         (candidate_i[\"fractionRows\"] > support)):\n",
    "    if ((candidate_i[\"fractionRows\"] > support_small) \n",
    "#         or\n",
    "#        ((candidate_i[\"fractionRows\"] > support) & (candidate_i[\"second_order_influences\"] > del_f_threshold))\n",
    "       ):\n",
    "        attr_i = candidate_i[\"attributes\"]\n",
    "        val_i = str(candidate_i[\"attributeValues\"])\n",
    "        predicates = []\n",
    "        predicates.insert(0, attr_i + '=' + str(val_i))\n",
    "        candidate.insert(0, predicates)\n",
    "        candidate.insert(1, candidate_i[\"fractionRows\"])\n",
    "        candidate.insert(2, candidate_i[\"score\"])\n",
    "        candidate.insert(3, candidate_i[\"second_order_influences\"])\n",
    "        candidates_1.insert(i, candidate)\n",
    "print(\"Generated: \", len(candidates_1), \" 1-candidates\")\n",
    "candidates_1.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T07:42:29.043084Z",
     "start_time": "2021-06-26T07:40:21.371356Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated:  74  1-candidates\n",
      "Generated:  277  2-candidates\n",
      "Generated:  2\n",
      "Generated: 1195   3 -candidates\n",
      "Generated:  3\n",
      "Generated: 3032   4 -candidates\n",
      "CPU times: user 2min 4s, sys: 897 ms, total: 2min 5s\n",
      "Wall time: 2min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "candidates_all = []\n",
    "\n",
    "# Generating 1-candidates\n",
    "candidates_1 = []\n",
    "for i in range(len(candidates)):\n",
    "    candidate = []\n",
    "    candidate_i = candidates.iloc[i]\n",
    "#     if ((candidate_i[\"second_order_influences\"] > del_f_threshold) & \n",
    "#         (candidate_i[\"fractionRows\"] > support)):\n",
    "    if ((candidate_i[\"fractionRows\"] > support_small) or\n",
    "       ((candidate_i[\"fractionRows\"] > support) & (candidate_i[\"second_order_influences\"] > del_f_threshold))\n",
    "       ):\n",
    "        attr_i = candidate_i[\"attributes\"]\n",
    "        val_i = str(candidate_i[\"attributeValues\"])\n",
    "        predicates = []\n",
    "        predicates.insert(0, attr_i + '=' + str(val_i))\n",
    "        candidate.insert(0, predicates)\n",
    "        candidate.insert(1, candidate_i[\"fractionRows\"])\n",
    "        candidate.insert(2, candidate_i[\"score\"])\n",
    "        candidate.insert(3, candidate_i[\"second_order_influences\"])\n",
    "        candidates_1.insert(i, candidate)\n",
    "print(\"Generated: \", len(candidates_1), \" 1-candidates\")\n",
    "candidates_1.sort()\n",
    "# display(candidates_1)\n",
    "\n",
    "for i in range(len(candidates_1)):\n",
    "    if (float(candidates_1[i][2]) > support): # if score > top-k, keep in candidates, not otherwise\n",
    "        candidates_all.insert(len(candidates_all), candidates_1[i])\n",
    "    \n",
    "# Generating 2-candidates\n",
    "candidates_2 = []\n",
    "for i in range(len(candidates_1)):\n",
    "    attr_i = candidates_1[i][0][0].split(\"=\")[0]\n",
    "    val_i = int(candidates_1[i][0][0].split(\"=\")[1])\n",
    "    for j in range(i):\n",
    "        # merge two candidates\n",
    "        attr_j = candidates_1[j][0][0].split(\"=\")[0]\n",
    "        val_j = int(candidates_1[j][0][0].split(\"=\")[1])\n",
    "        \n",
    "        if (attr_i != attr_j):\n",
    "            idx = X_train_orig[(X_train_orig[attr_i] == val_i) &\n",
    "                              (X_train_orig[attr_j] == val_j)].index \n",
    "            \n",
    "            idx_i = X_train_orig[(X_train_orig[attr_i] == val_i)].index \n",
    "            idx_j = X_train_orig[(X_train_orig[attr_j] == val_j)].index \n",
    "            fractionRows = len(idx)/len(X_train) * 100\n",
    "            isCompact = True\n",
    "            if (len(idx) == min(len(idx_i), len(idx_j))): # pattern is not compact if intersection equals one of its parents\n",
    "                isCompact = False\n",
    "            if (fractionRows/100 > support):\n",
    "                X = np.delete(X_train, idx, 0)\n",
    "                y = y_train.drop(index=idx, inplace=False)\n",
    "\n",
    "                size_hvp = 1\n",
    "                params_f_2 = second_order_influence(X_train, idx, size_hvp, del_L_del_theta, hessian_all_points)\n",
    "                del_f_2 = np.dot(v1.transpose(), params_f_2)[0][0]\n",
    "                \n",
    "                score = del_f_2 * 100/fractionRows\n",
    "                if ((score > candidates_1[i][2]) & (score > candidates_1[j][2])):\n",
    "\n",
    "#                 if (\n",
    "#         #             (del_f_2 > alpha_f_lower) & \n",
    "#                     (del_f_2 < alpha_f_upper) & \n",
    "#                     (del_f_2 > del_f_threshold)\n",
    "#                    ):\n",
    "#                     if (del_f_2 > 0.01):\n",
    "                        candidate = []\n",
    "                        predicates = []\n",
    "                        predicates.insert(0, attr_i + '=' + str(val_i))\n",
    "                        predicates.insert(1, attr_j + '=' + str(val_j))\n",
    "                        candidate.insert(0, sorted(predicates, key=itemgetter(0)))                        \n",
    "                        candidate.insert(1, len(idx)*100/len(X_train))\n",
    "                        candidate.insert(2, score)\n",
    "                        candidate.insert(3, del_f_2)\n",
    "            #             print(candidate)\n",
    "                        candidates_2.insert(len(candidates_2), candidate)  \n",
    "                        if (isCompact):\n",
    "                            candidates_all.insert(len(candidates_all), candidate)\n",
    "print(\"Generated: \", len(candidates_2), \" 2-candidates\")\n",
    "candidates_2.sort()\n",
    "# display(candidates_2)\n",
    "\n",
    "# Recursively generating the rest\n",
    "candidates_L_1 = copy.deepcopy(candidates_2)\n",
    "# display(candidates_L_1)\n",
    "iter=2\n",
    "while((len(candidates_L_1) > 0) & (iter < 4)):\n",
    "    print(\"Generated: \", iter)\n",
    "#     for i in range(len(candidates_L_1)):\n",
    "#         candidates_all.insert(len(candidates_all), candidates_L_1[i])\n",
    "    \n",
    "    candidates_L = []\n",
    "    for i in range(len(candidates_L_1)):\n",
    "        candidate_i = candidates_L_1[i][0]\n",
    "        for j in range(i):\n",
    "            candidate_j = candidates_L_1[j][0]\n",
    "#             print(candidate_i, candidate_j)\n",
    "            # if L-1 lists intersect\n",
    "            intersect_candidates = set(candidate_i).intersection(candidate_j)\n",
    "            if (len(intersect_candidates) == iter - 1):\n",
    "                setminus_i = list(set(candidate_i) - intersect_candidates)[0].split(\"=\")\n",
    "                setminus_j = list(set(candidate_j) - intersect_candidates)[0].split(\"=\")\n",
    "                attr_i = setminus_i[0]\n",
    "                val_i = int(setminus_i[1])\n",
    "                attr_j = setminus_j[0]\n",
    "                val_j = int(setminus_j[1])\n",
    "                if (attr_i != attr_j):\n",
    "                    # merge to get L list\n",
    "                    merged_candidate = list(set(candidate_i + candidate_j))\n",
    "\n",
    "                    idx_i_j = pd.Index(list(range(len(X_train_orig))))\n",
    "                    for k in range(len(intersect_candidates)):\n",
    "                        attr = list(intersect_candidates)[k].split(\"=\")[0]\n",
    "                        val = int(list(intersect_candidates)[k].split(\"=\")[1])\n",
    "                        idx_i_j = idx_i_j.intersection(X_train_orig[(X_train_orig[attr] == val)].index)\n",
    "                    \n",
    "                    idx_i = idx_i_j.intersection(X_train_orig[(X_train_orig[attr_i] == val_i)].index)\n",
    "                    idx_j = idx_i_j.intersection(X_train_orig[(X_train_orig[attr_j] == val_j)].index)                    \n",
    "                    idx = idx_i.intersection(X_train_orig[(X_train_orig[attr_j] == val_j)].index) # merged\n",
    "\n",
    "                    fractionRows = len(idx)/len(X_train) * 100\n",
    "                    isCompact = True\n",
    "                    if (len(idx) == min(len(idx_i), len(idx_j))): # pattern is not compact if intersection equals one of its parents\n",
    "                        isCompact = False\n",
    "                    if (fractionRows/100 > support):\n",
    "                        X = np.delete(X_train, idx, 0)\n",
    "                        y = y_train.drop(index=idx, inplace=False)\n",
    "\n",
    "                        size_hvp = 1\n",
    "                        params_f_2 = second_order_influence(X_train, idx, size_hvp, del_L_del_theta, hessian_all_points)\n",
    "                        del_f_2 = np.dot(v1.transpose(), params_f_2)[0][0]\n",
    "    \n",
    "#                         print(fractionRows)\n",
    "                        score = del_f_2 * 100/fractionRows\n",
    "#                         print(score)\n",
    "#                         print(candidates_L_1[i][2], candidates_L_1[j][2])\n",
    "                        if (((score > candidates_L_1[i][2]) & (score > candidates_L_1[j][2])) or \n",
    "                           (fractionRows > support_small)):\n",
    "                        \n",
    "#                         if ((len(idx)/len(X_train) < support_small) &\n",
    "#                             (del_f_2 < del_f_threshold_small) \n",
    "#                             ):\n",
    "#                             continue\n",
    "#                             if (\n",
    "    #                             (del_f_2 > alpha_f_lower) & \n",
    "#                                 (del_f_2 > del_f_threshold) \n",
    "#                                 &\n",
    "#                                 (del_f_2 < alpha_f_upper)\n",
    "#                             ):\n",
    "                            candidate = []\n",
    "                            candidate.insert(0, sorted(merged_candidate, key=itemgetter(0)))                        \n",
    "                            candidate.insert(1, fractionRows)\n",
    "                            candidate.insert(2, del_f_2*len(X_train)/len(idx))\n",
    "                            candidate.insert(3, del_f_2)\n",
    "                            if (candidate not in candidates_L):\n",
    "#                                     print(candidate_i, candidate_j, \"Generated\", candidate)\n",
    "                                candidates_L.insert(len(candidates_L), candidate)\n",
    "                                if (isCompact):\n",
    "                                    candidates_all.insert(len(candidates_all), candidate)\n",
    "    #     print(candidates_L)\n",
    "    print(\"Generated:\", len(candidates_L), \" \", str(iter+1), \"-candidates\")\n",
    "    candidates_L_1 = copy.deepcopy(candidates_L)\n",
    "    candidates_L_1.sort()\n",
    "    iter += 1\n",
    "\n",
    "# for i in range(len(candidates_L_1)):\n",
    "#     candidates_all.insert(len(candidates_all), candidates_L_1[i])\n",
    "    \n",
    "#     # display(candidates_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T07:42:47.421775Z",
     "start_time": "2021-06-26T07:42:47.260866Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4426\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicates</th>\n",
       "      <th>support</th>\n",
       "      <th>score</th>\n",
       "      <th>2nd-inf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2550</th>\n",
       "      <td>[credit_hist=2, foreign_worker=1, gender=0, nu...</td>\n",
       "      <td>19.000</td>\n",
       "      <td>0.275472</td>\n",
       "      <td>0.052340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>[credit_hist=2, gender=0, num_liable=1]</td>\n",
       "      <td>19.125</td>\n",
       "      <td>0.272469</td>\n",
       "      <td>0.052110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>[age=1, foreign_worker=1, num_liable=1]</td>\n",
       "      <td>16.750</td>\n",
       "      <td>0.293920</td>\n",
       "      <td>0.049232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3327</th>\n",
       "      <td>[foreign_worker=1, gender=0, num_liable=1, sav...</td>\n",
       "      <td>18.875</td>\n",
       "      <td>0.257428</td>\n",
       "      <td>0.048590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>[gender=0, num_liable=1, savings=0]</td>\n",
       "      <td>19.375</td>\n",
       "      <td>0.247746</td>\n",
       "      <td>0.048001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2523</th>\n",
       "      <td>[credit_hist=2, employment=2, foreign_worker=1...</td>\n",
       "      <td>12.500</td>\n",
       "      <td>-0.101689</td>\n",
       "      <td>-0.012711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1507</th>\n",
       "      <td>[age=0, duration=1, num_credits=1, residence=4]</td>\n",
       "      <td>9.125</td>\n",
       "      <td>-0.157525</td>\n",
       "      <td>-0.014374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1504</th>\n",
       "      <td>[age=0, credit_amt=1, duration=1, residence=4]</td>\n",
       "      <td>6.500</td>\n",
       "      <td>-0.228992</td>\n",
       "      <td>-0.014885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>[age=0, duration=1, residence=4]</td>\n",
       "      <td>13.125</td>\n",
       "      <td>-0.117006</td>\n",
       "      <td>-0.015357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>[gender=1, num_liable=2]</td>\n",
       "      <td>13.375</td>\n",
       "      <td>-0.154206</td>\n",
       "      <td>-0.020625</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4149 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             predicates  support     score  \\\n",
       "2550  [credit_hist=2, foreign_worker=1, gender=0, nu...   19.000  0.275472   \n",
       "933             [credit_hist=2, gender=0, num_liable=1]   19.125  0.272469   \n",
       "328             [age=1, foreign_worker=1, num_liable=1]   16.750  0.293920   \n",
       "3327  [foreign_worker=1, gender=0, num_liable=1, sav...   18.875  0.257428   \n",
       "969                 [gender=0, num_liable=1, savings=0]   19.375  0.247746   \n",
       "...                                                 ...      ...       ...   \n",
       "2523  [credit_hist=2, employment=2, foreign_worker=1...   12.500 -0.101689   \n",
       "1507    [age=0, duration=1, num_credits=1, residence=4]    9.125 -0.157525   \n",
       "1504     [age=0, credit_amt=1, duration=1, residence=4]    6.500 -0.228992   \n",
       "685                    [age=0, duration=1, residence=4]   13.125 -0.117006   \n",
       "141                            [gender=1, num_liable=2]   13.375 -0.154206   \n",
       "\n",
       "       2nd-inf  \n",
       "2550  0.052340  \n",
       "933   0.052110  \n",
       "328   0.049232  \n",
       "3327  0.048590  \n",
       "969   0.048001  \n",
       "...        ...  \n",
       "2523 -0.012711  \n",
       "1507 -0.014374  \n",
       "1504 -0.014885  \n",
       "685  -0.015357  \n",
       "141  -0.020625  \n",
       "\n",
       "[4149 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "candidates_support_3_compact = copy.deepcopy(candidates_all)\n",
    "print(len(candidates_support_3_compact))\n",
    "candidates_df_3_compact = pd.DataFrame(candidates_support_3_compact, columns=[\"predicates\",\"support\",\"score\",\"2nd-inf\"])\n",
    "candidates_df_3_compact = candidates_df_3_compact[candidates_df_3_compact[\"support\"] < 20].sort_values(by=['2nd-inf'], ascending=False)\n",
    "display(candidates_df_3_compact)\n",
    "# display(candidates_df_3_compact[candidates_df_3_compact[\"support\"] < 20].sort_values(by=['2nd-inf'], ascending=False).head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2479    0.463260\n",
       "904     0.461219\n",
       "3176    0.432564\n",
       "934     0.427344\n",
       "330     0.417178\n",
       "          ...   \n",
       "2442   -0.113054\n",
       "1486   -0.126542\n",
       "1483   -0.131397\n",
       "656    -0.134362\n",
       "140    -0.184637\n",
       "Name: 2nd-inf, Length: 4000, dtype: float64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates_df_3_compact[\"2nd-inf\"]/0.112182"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "5.0\n",
      "inf-1 0.03508225559891035\n",
      "0.05898558051707459\n"
     ]
    }
   ],
   "source": [
    "idx = X_train_orig[\n",
    "                   (X_train_orig['age']==1)\n",
    "                   & (X_train_orig['gender']==0)                \n",
    "#                    & (X_train_orig['num_liable']==1)\n",
    "                   & (X_train_orig['foreign_worker']==1)\n",
    "                  ].index \n",
    "\n",
    "print(len(idx))\n",
    "print(len(idx)*100/len(X_train))\n",
    "\n",
    "del_f_1 = 0            \n",
    "for i in range(len(idx)):\n",
    "    del_f_1 += infs_1[idx[i]]\n",
    "print(\"inf-1\", del_f_1)\n",
    "            \n",
    "size_hvp = 1\n",
    "params_f_2 = second_order_influence(X_train, idx, size_hvp, del_L_del_theta, hessian_all_points)\n",
    "del_f_2 = np.dot(v1.transpose(), params_f_2)[0][0]\n",
    "\n",
    "df_updated = df_orig.drop(index=idx, inplace=False)\n",
    "# display(df_orig[['credit','age']].groupby(by=[\"age\"]).mean())\n",
    "# display(df_updated[['credit','age']].groupby(by=[\"age\"]).mean())\n",
    "\n",
    "X = np.delete(X_train, idx, 0)\n",
    "y = y_train.drop(index=idx, inplace=False)\n",
    "clf.fit(X, y)\n",
    "y_pred = clf.predict_proba(X_test)\n",
    "print(computeFairness(y_pred, X_test_orig, y_test, 0) - spd_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T14:20:04.825198Z",
     "start_time": "2021-06-26T14:20:04.811049Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_subset(X_train_orig, explanation):\n",
    "    subset = X_train_orig.copy()\n",
    "    for predicate in explanation:\n",
    "#         print(predicate)\n",
    "        attr = predicate.split(\"=\")[0].strip(' ')\n",
    "        val = int(predicate.split(\"=\")[1].strip(' '))\n",
    "        subset = subset[subset[attr]==val]\n",
    "    return subset.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T09:04:34.909916Z",
     "start_time": "2021-06-26T09:04:34.885415Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "from datasketch import MinHashLSHEnsemble, MinHash, MinHashLSH\n",
    "import json\n",
    "\n",
    "\n",
    "class Topk:\n",
    "    '''\n",
    "        top explanations: explanation -> (minhash, set_index, score)\n",
    "    '''\n",
    "    def __init__(self, method='lsh', threshold=0.75, k=5):\n",
    "        self.method = method\n",
    "        if method == 'lshensemble':\n",
    "            self.index = MinHashLSHEnsemble(threshold=threshold)\n",
    "        elif method == 'lsh':\n",
    "            self.index = MinHashLSH(threshold=threshold)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        self.top_explanations = dict()\n",
    "        self.k = k\n",
    "        self.threshold = threshold\n",
    "        self.min_score = -100\n",
    "        self.min_score_explanation =None\n",
    "\n",
    "    def _pre_filtering(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    # if top explanation changes, recreate the index\n",
    "    def _recreate_index(self):\n",
    "        if self.method == 'lshensemble':\n",
    "            self.index = MinHashLSHEnsemble(threshold=self.threshold)\n",
    "            self.index.index([(k, v[0], len(v[1])) for k, v in self.top_explanations.items()])\n",
    "        else:\n",
    "            self.index = MinHashLSH(threshold=self.threshold)\n",
    "            for k, v in self.top_explanations.items():\n",
    "                self.index.insert(k, v[0])\n",
    "    \n",
    "    def _update_min(self, new_explanation, new_score):\n",
    "        if len(self.top_explanations) > 0:\n",
    "            for explanation, t in self.top_explanations.items():\n",
    "                if t[2] < new_score:\n",
    "                    new_score = t[2]\n",
    "                    new_explanation = explanation\n",
    "        self.min_score = new_score\n",
    "        self.min_score_explanation = new_explanation\n",
    "            \n",
    "    def update(self, df, explanation, score):\n",
    "        if (len(self.top_explanations) < self.k) or (score > self.min_score):\n",
    "            s = get_subset(df, explanation)\n",
    "            m = MinHash()\n",
    "            explanation = json.dumps(explanation)\n",
    "            for d in s:\n",
    "                m.update(str(d).encode('utf8'))\n",
    "\n",
    "            if self.method == 'lshensemble':\n",
    "                q_result = list(self.index.query(m, len(s)))\n",
    "            else:\n",
    "                q_result = list(self.index.query(m))\n",
    "\n",
    "            if len(q_result)==0:\n",
    "                if len(self.top_explanations) <= self.k-1:\n",
    "                    self._update_min(explanation, score)\n",
    "                    self.top_explanations[explanation] = (m, s, score)\n",
    "                    self._recreate_index()\n",
    "                    return 0\n",
    "                else:\n",
    "                    del self.top_explanations[self.min_score_explanation]\n",
    "                    self._update_min(explanation, score)\n",
    "                    self.top_explanations[explanation] = (m, s, score)\n",
    "                    self._recreate_index()\n",
    "                    return 0\n",
    "            else:\n",
    "                q_scores = [self.top_explanations[explanation][2] for explanation in q_result]\n",
    "                if max(q_scores) < score:\n",
    "                    for explanation in q_result:\n",
    "                        del self.top_explanations[explanation]\n",
    "                    self._update_min(explanation, score)\n",
    "                    self.top_explanations[explanation] = (m, s, score)\n",
    "                    self._recreate_index()\n",
    "                    return 0\n",
    "        return -1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T14:22:53.675433Z",
     "start_time": "2021-06-26T14:22:53.656825Z"
    }
   },
   "outputs": [],
   "source": [
    "lsh_df = candidates_df_3_compact.sort_values(by=['score'], ascending=False).copy()\n",
    "lsh_df = lsh_df[lsh_df['score']>.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T14:37:58.949836Z",
     "start_time": "2021-06-26T14:37:50.760435Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tqdm\n",
    "topk = Topk(method='lshensemble', threshold=0.2, k=10)\n",
    "# tbar = tqdm.tqdm(total=len(candidates_support_3_compact))\n",
    "for row_idx in range(len(lsh_df)):\n",
    "#     print(topk.top_explanations.keys())\n",
    "    row = lsh_df.iloc[row_idx]\n",
    "    explanation, score = row[0], row[2]\n",
    "    topk.update(X_train_orig, explanation, score)\n",
    "#     tbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T14:40:14.018014Z",
     "start_time": "2021-06-26T14:40:13.584938Z"
    }
   },
   "outputs": [],
   "source": [
    "explanations = list(topk.top_explanations.keys())\n",
    "idxs = [v[1] for v in topk.top_explanations.values()]\n",
    "supports = list()\n",
    "scores = list()\n",
    "infs = list()\n",
    "for e in explanations:\n",
    "    condition = candidates_df_3_compact.predicates.apply(lambda x: x==json.loads(e))\n",
    "    supports.append(float(candidates_df_3_compact[condition]['support']))\n",
    "    scores.append(float(candidates_df_3_compact[condition]['score']))\n",
    "    infs.append(float(candidates_df_3_compact[condition]['2nd-inf']))\n",
    "\n",
    "expl = [explanations, supports, scores, infs]\n",
    "expl = (np.array(expl).T).tolist()\n",
    "\n",
    "explanations = pd.DataFrame(expl, columns=[\"explanations\", \"support\", \"score\", \"2nd-inf\"])\n",
    "explanations['score'] = explanations['score'].astype(float)\n",
    "explanations['support'] = explanations['support'].astype(float)\n",
    "explanations['2nd-inf'] = explanations['2nd-inf'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T14:40:24.501081Z",
     "start_time": "2021-06-26T14:40:24.455401Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>explanations</th>\n",
       "      <th>support</th>\n",
       "      <th>score</th>\n",
       "      <th>2nd-inf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[\"credit_amt=0\", \"credit_hist=2\", \"gender=0\", \"housing_A152=1\"]</td>\n",
       "      <td>6.875</td>\n",
       "      <td>0.516978</td>\n",
       "      <td>0.035542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[\"age=1\", \"credit_amt=1\", \"num_liable=1\"]</td>\n",
       "      <td>5.375</td>\n",
       "      <td>0.496170</td>\n",
       "      <td>0.026669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[\"credit_amt=0\", \"install_plans=0\", \"install_rate=4\", \"status=0\"]</td>\n",
       "      <td>6.500</td>\n",
       "      <td>0.489595</td>\n",
       "      <td>0.031824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[\"credit_hist=2\", \"gender=0\", \"status=0\"]</td>\n",
       "      <td>6.500</td>\n",
       "      <td>0.422720</td>\n",
       "      <td>0.027477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[\"debtors=0\", \"foreign_worker=1\", \"job=3\", \"residence=2\"]</td>\n",
       "      <td>5.375</td>\n",
       "      <td>0.422057</td>\n",
       "      <td>0.022686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[\"purpose_A46=1\"]</td>\n",
       "      <td>4.250</td>\n",
       "      <td>0.407117</td>\n",
       "      <td>0.017302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[\"install_rate=4\", \"job=2\", \"savings=0\", \"telephone=1\"]</td>\n",
       "      <td>5.375</td>\n",
       "      <td>0.385150</td>\n",
       "      <td>0.020702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[\"foreign_worker=1\", \"status=1\", \"savings=0\", \"telephone=1\"]</td>\n",
       "      <td>6.750</td>\n",
       "      <td>0.381900</td>\n",
       "      <td>0.025778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[\"foreign_worker=1\", \"gender=0\", \"residence=2\", \"savings=0\"]</td>\n",
       "      <td>5.500</td>\n",
       "      <td>0.381890</td>\n",
       "      <td>0.021004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[\"credit_amt=0\", \"credit_hist=0\", \"employment=4\", \"foreign_worker=1\"]</td>\n",
       "      <td>5.250</td>\n",
       "      <td>0.367426</td>\n",
       "      <td>0.019290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            explanations  \\\n",
       "0        [\"credit_amt=0\", \"credit_hist=2\", \"gender=0\", \"housing_A152=1\"]   \n",
       "1                              [\"age=1\", \"credit_amt=1\", \"num_liable=1\"]   \n",
       "2      [\"credit_amt=0\", \"install_plans=0\", \"install_rate=4\", \"status=0\"]   \n",
       "3                              [\"credit_hist=2\", \"gender=0\", \"status=0\"]   \n",
       "4              [\"debtors=0\", \"foreign_worker=1\", \"job=3\", \"residence=2\"]   \n",
       "5                                                      [\"purpose_A46=1\"]   \n",
       "6                [\"install_rate=4\", \"job=2\", \"savings=0\", \"telephone=1\"]   \n",
       "7           [\"foreign_worker=1\", \"status=1\", \"savings=0\", \"telephone=1\"]   \n",
       "8           [\"foreign_worker=1\", \"gender=0\", \"residence=2\", \"savings=0\"]   \n",
       "9  [\"credit_amt=0\", \"credit_hist=0\", \"employment=4\", \"foreign_worker=1\"]   \n",
       "\n",
       "   support     score   2nd-inf  \n",
       "0    6.875  0.516978  0.035542  \n",
       "1    5.375  0.496170  0.026669  \n",
       "2    6.500  0.489595  0.031824  \n",
       "3    6.500  0.422720  0.027477  \n",
       "4    5.375  0.422057  0.022686  \n",
       "5    4.250  0.407117  0.017302  \n",
       "6    5.375  0.385150  0.020702  \n",
       "7    6.750  0.381900  0.025778  \n",
       "8    5.500  0.381890  0.021004  \n",
       "9    5.250  0.367426  0.019290  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('max_colwidth', 100)\n",
    "explanations.sort_values(by=['score'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T14:40:14.949459Z",
     "start_time": "2021-06-26T14:40:14.884816Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicates</th>\n",
       "      <th>support</th>\n",
       "      <th>score</th>\n",
       "      <th>2nd-inf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1670</th>\n",
       "      <td>[credit_amt=0, credit_hist=2, gender=0, housing_A152=1]</td>\n",
       "      <td>6.875</td>\n",
       "      <td>0.516978</td>\n",
       "      <td>0.035542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2661</th>\n",
       "      <td>[credit_hist=2, gender=0, num_liable=1, telephone=1]</td>\n",
       "      <td>6.000</td>\n",
       "      <td>0.502193</td>\n",
       "      <td>0.030132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2782</th>\n",
       "      <td>[credit_hist=2, job=2, savings=0, telephone=1]</td>\n",
       "      <td>5.875</td>\n",
       "      <td>0.498851</td>\n",
       "      <td>0.029307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>[age=1, credit_amt=1, num_liable=1]</td>\n",
       "      <td>5.375</td>\n",
       "      <td>0.496170</td>\n",
       "      <td>0.026669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>[credit_amt=0, install_plans=0, install_rate=4, status=0]</td>\n",
       "      <td>6.500</td>\n",
       "      <td>0.489595</td>\n",
       "      <td>0.031824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>[age=1, housing_A152=1, install_plans=0, job=2]</td>\n",
       "      <td>6.125</td>\n",
       "      <td>0.477509</td>\n",
       "      <td>0.029247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>[age=1, duration=0, housing_A152=1, install_plans=0]</td>\n",
       "      <td>5.125</td>\n",
       "      <td>0.468263</td>\n",
       "      <td>0.023998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2621</th>\n",
       "      <td>[credit_hist=2, duration=1, gender=0, housing_A152=1]</td>\n",
       "      <td>5.125</td>\n",
       "      <td>0.463693</td>\n",
       "      <td>0.023764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2659</th>\n",
       "      <td>[credit_hist=2, gender=0, install_plans=0, telephone=1]</td>\n",
       "      <td>5.750</td>\n",
       "      <td>0.460186</td>\n",
       "      <td>0.026461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>[age=1, credit_hist=2, foreign_worker=1, housing_A152=1]</td>\n",
       "      <td>5.250</td>\n",
       "      <td>0.456259</td>\n",
       "      <td>0.023954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     predicates  support  \\\n",
       "1670    [credit_amt=0, credit_hist=2, gender=0, housing_A152=1]    6.875   \n",
       "2661       [credit_hist=2, gender=0, num_liable=1, telephone=1]    6.000   \n",
       "2782             [credit_hist=2, job=2, savings=0, telephone=1]    5.875   \n",
       "325                         [age=1, credit_amt=1, num_liable=1]    5.375   \n",
       "1922  [credit_amt=0, install_plans=0, install_rate=4, status=0]    6.500   \n",
       "1624            [age=1, housing_A152=1, install_plans=0, job=2]    6.125   \n",
       "1620       [age=1, duration=0, housing_A152=1, install_plans=0]    5.125   \n",
       "2621      [credit_hist=2, duration=1, gender=0, housing_A152=1]    5.125   \n",
       "2659    [credit_hist=2, gender=0, install_plans=0, telephone=1]    5.750   \n",
       "1596   [age=1, credit_hist=2, foreign_worker=1, housing_A152=1]    5.250   \n",
       "\n",
       "         score   2nd-inf  \n",
       "1670  0.516978  0.035542  \n",
       "2661  0.502193  0.030132  \n",
       "2782  0.498851  0.029307  \n",
       "325   0.496170  0.026669  \n",
       "1922  0.489595  0.031824  \n",
       "1624  0.477509  0.029247  \n",
       "1620  0.468263  0.023998  \n",
       "2621  0.463693  0.023764  \n",
       "2659  0.460186  0.026461  \n",
       "1596  0.456259  0.023954  "
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates_df_3_compact.sort_values(by=['score'], ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T09:04:46.096145Z",
     "start_time": "2021-06-26T09:04:40.881452Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/4426 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 2/4426 [00:00<05:29, 13.44it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 4/4426 [00:00<05:48, 12.70it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 6/4426 [00:00<05:31, 13.33it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 8/4426 [00:00<05:42, 12.91it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 10/4426 [00:00<05:34, 13.19it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 13/4426 [00:00<04:48, 15.32it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 15/4426 [00:01<06:03, 12.13it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 19/4426 [00:01<04:57, 14.79it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 21/4426 [00:01<05:15, 13.96it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 26/4426 [00:01<04:18, 17.03it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 29/4426 [00:01<04:01, 18.24it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 34/4426 [00:01<03:21, 21.82it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|          | 53/4426 [00:01<02:30, 29.01it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  1%|▏         | 59/4426 [00:02<02:14, 32.57it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  2%|▏         | 78/4426 [00:02<01:43, 41.87it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  3%|▎         | 113/4426 [00:02<01:17, 55.82it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  5%|▍         | 205/4426 [00:02<00:55, 76.49it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  6%|▌         | 245/4426 [00:02<00:42, 97.37it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  6%|▋         | 283/4426 [00:02<00:34, 118.78it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  7%|▋         | 309/4426 [00:03<00:32, 125.26it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  8%|▊         | 332/4426 [00:03<00:45, 89.08it/s] \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "  8%|▊         | 350/4426 [00:03<00:38, 104.63it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 10%|█         | 464/4426 [00:03<00:27, 141.53it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 12%|█▏        | 553/4426 [00:03<00:20, 185.85it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 19%|█▉        | 851/4426 [00:03<00:13, 256.83it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 22%|██▏       | 981/4426 [00:04<00:10, 319.40it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 24%|██▍       | 1076/4426 [00:04<00:08, 396.52it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 36%|███▌      | 1597/4426 [00:04<00:05, 542.39it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 40%|████      | 1778/4426 [00:04<00:05, 528.64it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 59%|█████▉    | 2622/4426 [00:04<00:02, 726.65it/s]\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      " 65%|██████▌   | 2894/4426 [00:05<00:01, 826.87it/s]\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "topk = Topk(method='lsh', threshold=0.7, k=10)\n",
    "tbar = tqdm.tqdm(total=len(candidates_support_3_compact))\n",
    "for row in candidates_support_3_compact:\n",
    "    explanation, score = row[0], row[2]\n",
    "    topk.update(X_train_orig, explanation, score)\n",
    "    tbar.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T09:04:56.395727Z",
     "start_time": "2021-06-26T09:04:56.125096Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "100%|██████████| 4426/4426 [00:17<00:00, 826.87it/s]\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "explanations = list(topk.top_explanations.keys())\n",
    "idxs = [v[1] for v in topk.top_explanations.values()]\n",
    "supports = list()\n",
    "scores = list()\n",
    "for e in explanations:\n",
    "    condition = candidates_df_3_compact.predicates.apply(lambda x: x==json.loads(e))\n",
    "    supports.append(float(candidates_df_3_compact[condition]['support']))\n",
    "    scores.append(float(candidates_df_3_compact[condition]['score']))\n",
    "\n",
    "expl = [explanations, scores, supports]\n",
    "expl = (np.array(expl).T).tolist()\n",
    "\n",
    "explanations = pd.DataFrame(expl, columns=[\"explanations\", \"scores\", \"supports\"])\n",
    "explanations['scores'] = explanations['scores'].astype(float)\n",
    "explanations['supports'] = explanations['supports'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-26T09:05:05.390863Z",
     "start_time": "2021-06-26T09:05:05.374268Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>explanations</th>\n",
       "      <th>scores</th>\n",
       "      <th>supports</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[\"credit_amt=0\", \"credit_hist=2\", \"gender=0\", \"housing_A152=1\"]</td>\n",
       "      <td>0.516978</td>\n",
       "      <td>6.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[\"credit_hist=2\", \"job=2\", \"savings=0\", \"telephone=1\"]</td>\n",
       "      <td>0.498851</td>\n",
       "      <td>5.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[\"credit_amt=0\", \"install_plans=0\", \"install_rate=4\", \"status=0\"]</td>\n",
       "      <td>0.489595</td>\n",
       "      <td>6.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[\"age=1\", \"duration=0\", \"housing_A152=1\", \"install_plans=0\"]</td>\n",
       "      <td>0.468263</td>\n",
       "      <td>5.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[\"credit_hist=2\", \"duration=1\", \"gender=0\", \"housing_A152=1\"]</td>\n",
       "      <td>0.463693</td>\n",
       "      <td>5.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[\"age=1\", \"credit_hist=2\", \"foreign_worker=1\", \"housing_A152=1\"]</td>\n",
       "      <td>0.456259</td>\n",
       "      <td>5.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[\"age=1\", \"credit_amt=1\"]</td>\n",
       "      <td>0.452362</td>\n",
       "      <td>6.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[\"credit_hist=2\", \"gender=0\", \"telephone=1\"]</td>\n",
       "      <td>0.452080</td>\n",
       "      <td>6.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[\"credit_hist=2\", \"gender=0\", \"install_plans=0\", \"status=0\"]</td>\n",
       "      <td>0.445829</td>\n",
       "      <td>5.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[\"age=1\", \"housing_A152=1\", \"job=2\"]</td>\n",
       "      <td>0.421357</td>\n",
       "      <td>7.375</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        explanations  \\\n",
       "4    [\"credit_amt=0\", \"credit_hist=2\", \"gender=0\", \"housing_A152=1\"]   \n",
       "9             [\"credit_hist=2\", \"job=2\", \"savings=0\", \"telephone=1\"]   \n",
       "5  [\"credit_amt=0\", \"install_plans=0\", \"install_rate=4\", \"status=0\"]   \n",
       "2       [\"age=1\", \"duration=0\", \"housing_A152=1\", \"install_plans=0\"]   \n",
       "6      [\"credit_hist=2\", \"duration=1\", \"gender=0\", \"housing_A152=1\"]   \n",
       "1   [\"age=1\", \"credit_hist=2\", \"foreign_worker=1\", \"housing_A152=1\"]   \n",
       "0                                          [\"age=1\", \"credit_amt=1\"]   \n",
       "8                       [\"credit_hist=2\", \"gender=0\", \"telephone=1\"]   \n",
       "7       [\"credit_hist=2\", \"gender=0\", \"install_plans=0\", \"status=0\"]   \n",
       "3                               [\"age=1\", \"housing_A152=1\", \"job=2\"]   \n",
       "\n",
       "     scores  supports  \n",
       "4  0.516978     6.875  \n",
       "9  0.498851     5.875  \n",
       "5  0.489595     6.500  \n",
       "2  0.468263     5.125  \n",
       "6  0.463693     5.125  \n",
       "1  0.456259     5.250  \n",
       "0  0.452362     6.375  \n",
       "8  0.452080     6.250  \n",
       "7  0.445829     5.500  \n",
       "3  0.421357     7.375  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanations.sort_values(by=['scores'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
