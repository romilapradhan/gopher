{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "from aif360.algorithms.preprocessing.optim_preproc import OptimPreproc\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.data_preproc_functions import load_preproc_data_adult\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.distortion_functions import get_distortion_adult\n",
    "from aif360.algorithms.preprocessing.optim_preproc_helpers.opt_tools import OptTools\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Markdown, display\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the clean the adult dataset\n",
    "\n",
    "df = pd.read_csv('adult.csv')\n",
    "\n",
    "# df = df.sample(n = 5000)\n",
    "# print(df.shape)\n",
    "\n",
    "# check columns that have missing values\\n\n",
    "df.isin(['?']).sum(axis=0)\n",
    "\n",
    "# replace missing values (?) to nan and then drop the columns\n",
    "df['native.country'] = df['native.country'].replace('?',np.nan)\n",
    "df['workclass'] = df['workclass'].replace('?',np.nan)\n",
    "df['occupation'] = df['occupation'].replace('?',np.nan)\n",
    "\n",
    "# dropping the NaN rows now\n",
    "df.dropna(how='any',inplace=True)\n",
    "\n",
    "df['income'] = df['income'].map({'<=50K': 0, '>50K': 1}).astype(int)\n",
    "df['sex'] = df['sex'].map({'Male': 1, 'Female': 0}).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data pre-processing (using one-hot encoding)\n",
    "\n",
    "# For each category we made a separate column\n",
    "df = pd.concat([df, pd.get_dummies(df['race'], prefix='race')],axis=1)\n",
    "df = pd.concat([df, pd.get_dummies(df['marital.status'], prefix='marital')],axis=1)\n",
    "df = pd.concat([df, pd.get_dummies(df['workclass'], prefix='workclass')],axis=1)\n",
    "df = pd.concat([df, pd.get_dummies(df['relationship'], prefix='relationship')],axis=1)\n",
    "df = pd.concat([df, pd.get_dummies(df['education'], prefix='education')],axis=1)\n",
    "df = pd.concat([df, pd.get_dummies(df['occupation'], prefix='occupation')],axis=1)\n",
    "\n",
    "# age binning\n",
    "df['ageUnder18'] = np.where(df['age'] < 18, 1, 0)\n",
    "df['age18to24'] = np.where((df['age'] >= 18) & (df['age'] <= 24), 1, 0)\n",
    "df['age25to44'] = np.where((df['age'] >= 25) & (df['age'] <= 44), 1, 0)\n",
    "df['age45to64'] = np.where((df['age'] >= 45) & (df['age'] <= 64), 1, 0)\n",
    "df['ageAbove65'] = np.where(df['age'] >= 65, 1, 0)\n",
    "\n",
    "# privileged, unprivileged groups\n",
    "privileged_groups = [{'sex': 1}] # Male\n",
    "unprivileged_groups = [{'sex': 0}] # Female\n",
    "\n",
    "df = df.drop(columns=['workclass', 'fnlwgt', 'education', 'education.num', 'occupation', \\\n",
    "                      'relationship', 'marital.status', 'race', 'native.country', 'capital.gain', \\\n",
    "                      'capital.loss', 'hours.per.week', 'age'])\n",
    "#\n",
    "#df.columns[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes fairness of data and returns the fairness metrics in a form of array\n",
    "\n",
    "def get_metrics(test_df, y_pred, unprivileged_groups, privileged_groups):\n",
    "    # BLD constructor is taking arguments of Structured dataset\n",
    "    test_bld = BinaryLabelDataset(df=test_df, label_names=['income'], protected_attribute_names=['sex'])\n",
    "    \n",
    "    # Made a copy of the the bld dataset\n",
    "    pred_data = test_bld.copy()\n",
    "    pred_data.labels = y_pred\n",
    "\n",
    "    # Using classification metric because we have 2 binary label datasets\n",
    "    metric_selection = ClassificationMetric(\n",
    "                    test_bld, pred_data,\n",
    "                    unprivileged_groups=unprivileged_groups,\n",
    "                    privileged_groups=privileged_groups)\n",
    "    \n",
    "    tnr_diff = metric_selection.true_negative_rate(1) - metric_selection.true_negative_rate(0)\n",
    "    \n",
    "    return [metric_selection.true_positive_rate_difference(), \\\n",
    "        metric_selection.statistical_parity_difference(),\\\n",
    "        tnr_diff,\\\n",
    "        metric_selection.accuracy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: Original\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TruePositiveRateDiff    -0.135077\n",
       "StatisticalParityDiff   -0.181838\n",
       "TrueNegativeRateDiff    -0.088531\n",
       "Accuracy                 0.825942\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute fairness over all the data\n",
    "\n",
    "X = df.drop(columns='income')\n",
    "y = df['income']\n",
    "\n",
    "num_k = 5 # number of folds for cross-validation\n",
    "\n",
    "# Metrics for each set of (train and test) sample\n",
    "metrics = [None] * num_k\n",
    "\n",
    "# Regression on original data\n",
    "k_fold = KFold(n_splits=num_k, random_state=None, shuffle=False)\n",
    "for k, (train, test) in enumerate(k_fold.split(X, y)):\n",
    "    # Here train and test are the list of indices on which split is done\n",
    "   \n",
    "    # take out test set from X\n",
    "    test_df = X.iloc[test].copy()\n",
    "    test_df['income'] = y.iloc[test]\n",
    "    \n",
    "    reg = LogisticRegression(max_iter=300, solver = 'lbfgs')\n",
    "    reg.fit(X.iloc[train], y.iloc[train])\n",
    "    y_pred = reg.predict(X.iloc[test])\n",
    "    metrics[k] = get_metrics(test_df, y_pred, unprivileged_groups, privileged_groups)\n",
    "\n",
    "print(\"Results: Original\")\n",
    "mf_orig = pd.DataFrame(metrics, columns = ['TruePositiveRateDiff', 'StatisticalParityDiff', \\\n",
    "                                      'TrueNegativeRateDiff', 'Accuracy'])\n",
    "mf_orig.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apurvgoel/opt/anaconda3/lib/python3.7/site-packages/aif360/metrics/classification_metric.py:264: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  TPR=TP / P, TNR=TN / N, FPR=FP / N, FNR=FN / P,\n",
      "/Users/apurvgoel/opt/anaconda3/lib/python3.7/site-packages/aif360/metrics/classification_metric.py:265: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  GTPR=GTP / P, GTNR=GTN / N, GFPR=GFP / N, GFNR=GFN / P,\n",
      "/Users/apurvgoel/opt/anaconda3/lib/python3.7/site-packages/aif360/metrics/classification_metric.py:632: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  / self.num_instances(privileged=privileged))\n",
      "/Users/apurvgoel/opt/anaconda3/lib/python3.7/site-packages/aif360/metrics/classification_metric.py:264: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  TPR=TP / P, TNR=TN / N, FPR=FP / N, FNR=FN / P,\n",
      "/Users/apurvgoel/opt/anaconda3/lib/python3.7/site-packages/aif360/metrics/classification_metric.py:265: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  GTPR=GTP / P, GTNR=GTN / N, GFPR=GFP / N, GFNR=GFN / P,\n",
      "/Users/apurvgoel/opt/anaconda3/lib/python3.7/site-packages/aif360/metrics/classification_metric.py:632: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  / self.num_instances(privileged=privileged))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-cce7b5206d97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mvalidation_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol_test_rem_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_temp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0my_temp_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1561\u001b[0m             raise ValueError(\"This solver needs samples of at least 2 classes\"\n\u001b[1;32m   1562\u001b[0m                              \u001b[0;34m\" in the data, but the data contains only one\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1563\u001b[0;31m                              \" class: %r\" % classes_[0])\n\u001b[0m\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: 0"
     ]
    }
   ],
   "source": [
    "# Try to find predicates for which the fairness of the model increases\n",
    "train, test = train_test_split(df, test_size = 0.3)\n",
    "\n",
    "\n",
    "X_train = train.drop(columns='income')\n",
    "y_train = train['income']\n",
    "\n",
    "'''\n",
    "col_rem = X_train.columns[1]\n",
    "col_rem_indices = X_train[X_train[col_rem] == 1].index\n",
    "X_train_temp = X_train.drop(col_rem_indices, inplace = False)\n",
    "'''\n",
    "\n",
    "X_test = test.drop(columns='income')\n",
    "y_test = test['income']\n",
    "\n",
    "# Taking three separate lists for candidate attribute, value, and fairness\n",
    "# considering only statistical parity\n",
    "\n",
    "attributes = []\n",
    "values = []\n",
    "infs = []\n",
    "\n",
    "reg = LogisticRegression(max_iter=200, solver = 'lbfgs')\n",
    "\n",
    "for i in range(0, len(X_train.columns)):\n",
    "    col_rem = X_train.columns[i]\n",
    "    for j in range(0,2):\n",
    "        \n",
    "        # Remove the preduicates in training and test set\n",
    "        col_train_rem_indices = X_train[X_train[col_rem] == j].index\n",
    "        \n",
    "        X_train_temp = X_train.drop(col_train_rem_indices, inplace = False)\n",
    "        y_train_temp = y_train.drop(col_train_rem_indices, inplace = False)\n",
    "        \n",
    "        \n",
    "        col_test_rem_indices = X_test[X_test[col_rem] == j].index\n",
    "        \n",
    "        X_test_temp = X_test.drop(col_test_rem_indices, inplace = False)\n",
    "        y_test_temp = y_test.drop(col_test_rem_indices, inplace = False)\n",
    "        \n",
    "        # Make a validation set\n",
    "        validation_set = test.drop(col_test_rem_indices, inplace = False)\n",
    "        \n",
    "        reg.fit(X_train_temp, y_train_temp)\n",
    "        \n",
    "        y_temp_predict = reg.predict(X_test_temp)\n",
    "        \n",
    "        # Get the metrics\n",
    "        metrics = get_metrics(validation_set, y_temp_predict, privileged_groups, unprivileged_groups)\n",
    "        \n",
    "        # Take the Statistical parity diff\n",
    "        inf = mf_orig.mean()[1] - metrics[1]\n",
    "        \n",
    "        if (inf < 0) :\n",
    "            attributes.append(col_rem)\n",
    "            values.append(j)\n",
    "            infs.append(inf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([ 5798, 32434, 17838, 13370, 20170, 12187,  3494, 14011, 20876,\n",
      "             5272,\n",
      "            ...\n",
      "            19077, 31792,    53, 20012,  6882, 17903, 18896, 12456, 23257,\n",
      "             3735],\n",
      "           dtype='int64', length=20908)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
