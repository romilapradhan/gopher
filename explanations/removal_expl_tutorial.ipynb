{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-18T23:55:53.242540Z",
     "start_time": "2022-10-18T23:55:52.159762Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x17302ffb0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import copy\n",
    "import random\n",
    "from load_dataset import load\n",
    "from classifier import NeuralNetwork, LogisticRegression, SVM\n",
    "from utils import *\n",
    "from metrics import *  # include fairness and corresponding derivatives\n",
    "from expl import explanation_candidate_generation, get_top_k_expl\n",
    "from influence import *\n",
    "\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-18T23:55:53.247400Z",
     "start_time": "2022-10-18T23:55:53.245176Z"
    }
   },
   "outputs": [],
   "source": [
    "# ignore all the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameters can be changed:**\n",
    "\n",
    "**dataset**: german / sqf / adult\n",
    "\n",
    "**clf_name**: LogisticRegression / SVM / NeuralNetwork\n",
    "\n",
    "**metric**: The metric for debugging. 0 -> spd, 1 -> tpr parity (equal opportunity), 2 -> predictive parity\n",
    "\n",
    "**support**: lower bound of pattern size\n",
    "\n",
    "**support_small**: upper bound of pattern size\n",
    "\n",
    "**duplicates**: make duplicates of datasets to test runtime vs dataset size with the same feature number and relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-18T23:55:53.251860Z",
     "start_time": "2022-10-18T23:55:53.249503Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "dataset = 'german'\n",
    "clf_name = 'LogisticRegression'\n",
    "metric = 0\n",
    "support = 0.05\n",
    "support_small = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-18T23:55:53.277372Z",
     "start_time": "2022-10-18T23:55:53.254219Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-18T23:55:53.282776Z",
     "start_time": "2022-10-18T23:55:53.278807Z"
    }
   },
   "outputs": [],
   "source": [
    "duplicates = 1\n",
    "make_duplicates = lambda x, d: pd.concat([x]*d, axis=0).reset_index(drop=True)\n",
    "X_train = make_duplicates(X_train, duplicates)\n",
    "X_test = make_duplicates(X_test, duplicates)\n",
    "y_train = make_duplicates(y_train, duplicates)\n",
    "y_test = make_duplicates(y_test, duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-18T23:55:53.292076Z",
     "start_time": "2022-10-18T23:55:53.284207Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "X_train_orig = copy.deepcopy(X_train)\n",
    "X_test_orig = copy.deepcopy(X_test)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model & Loss function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-18T23:55:53.297851Z",
     "start_time": "2022-10-18T23:55:53.293433Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "clf = eval(clf_name)(input_size=X_train.shape[-1])\n",
    "\n",
    "num_params = len(convert_grad_to_ndarray(list(clf.parameters())))\n",
    "if isinstance(clf, LogisticRegression):\n",
    "    loss_func = logistic_loss_torch\n",
    "elif isinstance(clf, SVM):\n",
    "    loss_func = svm_loss_torch\n",
    "elif isinstance(clf, NeuralNetwork):\n",
    "    loss_func = nn_loss_torch\n",
    "else:\n",
    "    raise NotImplementedError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Metrics: Initial state**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-18T23:55:53.356076Z",
     "start_time": "2022-10-18T23:55:53.301268Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial statistical parity:  -0.09527580118738121\n",
      "Initial TPR parity:  -0.07785149359511678\n",
      "Initial predictive parity:  -0.10136869102808022\n",
      "Initial accuracy:  0.755\n"
     ]
    }
   ],
   "source": [
    "clf = eval(clf_name)(input_size=X_train.shape[-1])\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_test = clf.predict_proba(X_test)\n",
    "y_pred_train = clf.predict_proba(X_train)\n",
    "\n",
    "spd_0 = computeFairness(y_pred_test, X_test_orig, y_test, 0, dataset)\n",
    "print(\"Initial statistical parity: \", spd_0)\n",
    "\n",
    "tpr_parity_0 = computeFairness(y_pred_test, X_test_orig, y_test, 1, dataset)\n",
    "print(\"Initial TPR parity: \", tpr_parity_0)\n",
    "\n",
    "predictive_parity_0 = computeFairness(y_pred_test, X_test_orig, y_test, 2, dataset)\n",
    "print(\"Initial predictive parity: \", predictive_parity_0)\n",
    "\n",
    "accuracy_0 = computeAccuracy(y_test, y_pred_test)\n",
    "print(\"Initial accuracy: \", accuracy_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select delta fairness function depending on selected metric**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-18T23:55:53.417981Z",
     "start_time": "2022-10-18T23:55:53.358764Z"
    }
   },
   "outputs": [],
   "source": [
    "metric_val = [spd_0, tpr_parity_0, predictive_parity_0][metric]\n",
    "del_F_del_theta = get_del_F_del_theta(clf, X_test_orig, X_test, y_test, dataset, metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-compute: (1) Hessian $H_{\\theta}$ (2) del_L_del_theta for each training data point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-18T23:56:03.133655Z",
     "start_time": "2022-10-18T23:55:53.420307Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 800/800 [00:09<00:00, 82.54it/s]\n"
     ]
    }
   ],
   "source": [
    "hessian_all_points = get_hessian_all_points(clf, X_train, y_train, loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-18T23:56:03.342607Z",
     "start_time": "2022-10-18T23:56:03.135493Z"
    }
   },
   "outputs": [],
   "source": [
    "del_L_del_theta = get_del_L_del_theta(clf, X_train, y_train, loss_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hessian vector product: $H_{\\theta}^{-1}v$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-18T23:56:03.347671Z",
     "start_time": "2022-10-18T23:56:03.343717Z"
    }
   },
   "outputs": [],
   "source": [
    "hinv_v, hinv = get_hinv_v(hessian_all_points, del_F_del_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Removal-based explanation generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-18T23:56:03.351489Z",
     "start_time": "2022-10-18T23:56:03.349007Z"
    }
   },
   "outputs": [],
   "source": [
    "# influence lower bound for the first-level patterns.\n",
    "# The first-level patterns with influencelower than this value would be filtered out\n",
    "del_f_threshold = 0.1 * metric_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-18T23:56:18.145863Z",
     "start_time": "2022-10-18T23:56:03.353186Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated:  62  1-candidates\n",
      "Generated:  341  2-candidates\n",
      "Generated:  2\n",
      "Generated: 2429   3 -candidates\n",
      "Generated:  3\n",
      "Generated: 10798   4 -candidates\n",
      "# candidates left:  12861\n",
      "CPU times: user 14.7 s, sys: 77.1 ms, total: 14.8 s\n",
      "Wall time: 14.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "containment_df = explanation_candidate_generation(X_train_orig, X_train, y_train, dataset, del_L_del_theta,\n",
    "                                                  hessian_all_points, hinv, del_F_del_theta,\n",
    "                                                  del_f_threshold=del_f_threshold, support=support,\n",
    "                                                  support_small=support_small)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Containment-based filtering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-18T23:56:18.302113Z",
     "start_time": "2022-10-18T23:56:18.147057Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'[\"age=1\", \"gender=0\"]': (Int64Index([ 13,  37,  76, 196, 212, 233, 241, 266, 285, 294, 333, 342, 354,\n",
      "            357, 370, 376, 398, 430, 435, 444, 494, 526, 537, 542, 545, 553,\n",
      "            562, 567, 588, 592, 598, 608, 613, 656, 671, 701, 727, 737, 749,\n",
      "            797],\n",
      "           dtype='int64'), 0.9832245805874269), '[\"age=1\", \"credit_hist=0\", \"gender=1\"]': (Int64Index([ 14,  17,  62,  63,  64,  80,  86,  89,  97, 124, 133, 139, 162,\n",
      "            164, 168, 182, 208, 214, 254, 275, 301, 303, 306, 329, 337, 344,\n",
      "            369, 399, 409, 411, 462, 468, 484, 500, 523, 556, 578, 585, 614,\n",
      "            623, 644, 668, 673, 679, 707, 713, 719, 742, 793, 796],\n",
      "           dtype='int64'), 0.6207703170367591), '[\"credit_amt=0\", \"install_rate=4\", \"install_plans=0\", \"status=0\"]': (Int64Index([ 14,  17,  43,  72,  82, 102, 112, 120, 124, 166, 170, 223, 224,\n",
      "            241, 245, 254, 281, 301, 317, 328, 351, 355, 357, 365, 371, 406,\n",
      "            425, 430, 434, 482, 483, 492, 501, 511, 535, 550, 560, 569, 585,\n",
      "            598, 624, 662, 668, 685, 703, 710, 718, 724, 725, 732, 736, 737],\n",
      "           dtype='int64'), 0.41899259980787995), '[\"duration=1\", \"employment=4\", \"num_liable=1\", \"residence=4\"]': (Int64Index([ 32,  52,  55,  63,  64,  74,  75,  76,  86,  97, 115, 123, 146,\n",
      "            152, 200, 214, 228, 241, 243, 252, 266, 273, 283, 301, 308, 335,\n",
      "            341, 404, 430, 448, 451, 528, 547, 551, 578, 592, 631, 669, 673,\n",
      "            688, 694, 737, 758],\n",
      "           dtype='int64'), 0.4048996966030878), '[\"credit_hist=2\", \"gender=0\", \"housing_A152=1\", \"savings=0\"]': (Int64Index([  4,  27,  37,  39,  59, 102, 127, 141, 160, 183, 191, 196, 205,\n",
      "            231, 239, 241, 245, 256, 297, 311, 327, 345, 353, 354, 376, 402,\n",
      "            417, 419, 430, 432, 433, 442, 444, 445, 446, 448, 449, 453, 455,\n",
      "            460, 472, 494, 501, 510, 537, 560, 567, 577, 588, 605, 621, 622,\n",
      "            633, 637, 660, 696, 701, 703, 712, 718, 723, 729, 761, 774],\n",
      "           dtype='int64'), 0.39308678614982157)}\n"
     ]
    }
   ],
   "source": [
    "topk = get_top_k_expl(containment_df, X_train_orig, containment_threshold=0.2, k=5)\n",
    "print(topk.top_explanations)  # in the format of [(pattern, indices)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Integrate the patterns and other info into more comprehensive results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-10-18T23:56:18.643230Z",
     "start_time": "2022-10-18T23:56:18.303419Z"
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>explanations</th>\n",
       "      <th>support</th>\n",
       "      <th>score</th>\n",
       "      <th>gt-score</th>\n",
       "      <th>2nd-inf(%)</th>\n",
       "      <th>gt-inf(%)</th>\n",
       "      <th>new-acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[\"age=1\", \"gender=0\"]</td>\n",
       "      <td>5.000</td>\n",
       "      <td>0.983225</td>\n",
       "      <td>1.079512</td>\n",
       "      <td>0.515989</td>\n",
       "      <td>0.566519</td>\n",
       "      <td>0.745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[\"age=1\", \"credit_hist=0\", \"gender=1\"]</td>\n",
       "      <td>6.250</td>\n",
       "      <td>0.620770</td>\n",
       "      <td>0.660626</td>\n",
       "      <td>0.407219</td>\n",
       "      <td>0.433364</td>\n",
       "      <td>0.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[\"credit_amt=0\", \"install_rate=4\", \"install_plans=0\", \"status=0\"]</td>\n",
       "      <td>6.500</td>\n",
       "      <td>0.418993</td>\n",
       "      <td>0.413260</td>\n",
       "      <td>0.285849</td>\n",
       "      <td>0.281938</td>\n",
       "      <td>0.755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[\"duration=1\", \"employment=4\", \"num_liable=1\", \"residence=4\"]</td>\n",
       "      <td>5.375</td>\n",
       "      <td>0.404900</td>\n",
       "      <td>0.403639</td>\n",
       "      <td>0.228425</td>\n",
       "      <td>0.227714</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[\"credit_hist=2\", \"gender=0\", \"housing_A152=1\", \"savings=0\"]</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0.393087</td>\n",
       "      <td>0.385020</td>\n",
       "      <td>0.330062</td>\n",
       "      <td>0.323289</td>\n",
       "      <td>0.760</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        explanations  support  \\\n",
       "0                                              [\"age=1\", \"gender=0\"]    5.000   \n",
       "1                             [\"age=1\", \"credit_hist=0\", \"gender=1\"]    6.250   \n",
       "2  [\"credit_amt=0\", \"install_rate=4\", \"install_plans=0\", \"status=0\"]    6.500   \n",
       "3      [\"duration=1\", \"employment=4\", \"num_liable=1\", \"residence=4\"]    5.375   \n",
       "4       [\"credit_hist=2\", \"gender=0\", \"housing_A152=1\", \"savings=0\"]    8.000   \n",
       "\n",
       "      score  gt-score  2nd-inf(%)  gt-inf(%)  new-acc  \n",
       "0  0.983225  1.079512    0.515989   0.566519    0.745  \n",
       "1  0.620770  0.660626    0.407219   0.433364    0.755  \n",
       "2  0.418993  0.413260    0.285849   0.281938    0.755  \n",
       "3  0.404900  0.403639    0.228425   0.227714    0.740  \n",
       "4  0.393087  0.385020    0.330062   0.323289    0.760  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explanations = list(topk.top_explanations.keys())\n",
    "idxs = [v[1] for v in topk.top_explanations.values()]\n",
    "supports = list()\n",
    "scores = list()\n",
    "gt_scores = list()\n",
    "infs = list()\n",
    "gts = list()\n",
    "new_accs = list()\n",
    "for e in explanations:\n",
    "    idx = get_subset(json.loads(e), X_train_orig)\n",
    "    X = np.delete(X_train, idx, 0)\n",
    "    y = y_train.drop(index=idx, inplace=False)\n",
    "    clf.fit(np.array(X), np.array(y))\n",
    "    y_pred = clf.predict_proba(np.array(X_test))\n",
    "    new_acc = computeAccuracy(y_test, y_pred)\n",
    "    inf_gt = computeFairness(y_pred, X_test_orig, y_test, 0, dataset) - metric_val\n",
    "    \n",
    "    condition = containment_df.predicates.apply(lambda x: x==json.loads(e))\n",
    "    supports.append(float(containment_df[condition]['support']))\n",
    "    scores.append(float(containment_df[condition]['score']))\n",
    "    infs.append(float(containment_df[condition]['2nd-inf']))\n",
    "    gts.append(inf_gt/(-metric_val))\n",
    "    gt_scores.append(inf_gt*100/float(containment_df[condition]['support']))\n",
    "    new_accs.append(new_acc)\n",
    "\n",
    "\n",
    "expl = [explanations, supports, scores, gt_scores, infs, gts, new_accs]\n",
    "expl = np.array(expl).T.tolist()\n",
    "\n",
    "explanations = pd.DataFrame(expl, columns=[\"explanations\", \"support\", \"score\", \"gt-score\", \"2nd-inf(%)\", \"gt-inf(%)\", \"new-acc\"])\n",
    "explanations['score'] = explanations['score'].astype(float)\n",
    "explanations['gt-score'] = explanations['gt-score'].astype(float)\n",
    "explanations['support'] = explanations['support'].astype(float)\n",
    "explanations['2nd-inf(%)'] = explanations['2nd-inf(%)'].astype(float)/(-metric_val)\n",
    "explanations['gt-inf(%)'] = explanations['gt-inf(%)'].astype(float)\n",
    "explanations['new-acc'] = explanations['new-acc'].astype(float)\n",
    "\n",
    "pd.set_option('max_colwidth', 100)\n",
    "explanations.sort_values(by=['score'], ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
