{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import copy\n",
    "import random\n",
    "import math\n",
    "from scipy import stats\n",
    "from scipy.stats import rankdata\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Markdown, display\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['age', 'workclass', 'fnlwgt', 'education', 'education.num', 'marital', 'occupation', 'relationship', 'race', 'gender', 'capgain', 'caploss', 'hours', 'country', 'income']\n",
    "df_train = pd.read_csv('adult.data', names=cols, sep=\",\")\n",
    "df_test = pd.read_csv('adult.test', names=cols, sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One-hot encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    " def one_hot_encode(df):\n",
    "    df.isin(['?']).sum(axis=0)\n",
    "\n",
    "    # replace missing values (?) to nan and then drop the columns\n",
    "    df['country'] = df['country'].replace('?',np.nan)\n",
    "    df['workclass'] = df['workclass'].replace('?',np.nan)\n",
    "    df['occupation'] = df['occupation'].replace('?',np.nan)\n",
    "\n",
    "    # dropping the NaN rows now\n",
    "    df.dropna(how='any',inplace=True)\n",
    "    df['income'] = df['income'].map({'<=50K': 0, '>50K': 1}).astype(int)\n",
    "    df = pd.concat([df, pd.get_dummies(df['gender'], prefix='gender')],axis=1)\n",
    "    df = pd.concat([df, pd.get_dummies(df['race'], prefix='race')],axis=1)\n",
    "    df = pd.concat([df, pd.get_dummies(df['marital'], prefix='marital')],axis=1)\n",
    "    df = pd.concat([df, pd.get_dummies(df['workclass'], prefix='workclass')],axis=1)\n",
    "    df = pd.concat([df, pd.get_dummies(df['relationship'], prefix='relationship')],axis=1)\n",
    "    df = pd.concat([df, pd.get_dummies(df['occupation'], prefix='occupation')],axis=1)\n",
    "    \n",
    "    # process age\n",
    "    df.loc[(df['age'] >= 15) & (df['age'] <= 24) , 'age'] = 0\n",
    "    df.loc[(df['age'] >= 25) & (df['age'] <= 34) , 'age'] = 1\n",
    "    df.loc[(df['age'] >= 35) & (df['age'] <= 44) , 'age'] = 2\n",
    "    df.loc[(df['age'] >= 45) & (df['age'] <= 54) , 'age'] = 3\n",
    "    df.loc[(df['age'] >= 55) & (df['age'] <= 64) , 'age'] = 4\n",
    "    df.loc[(df['age'] >= 65) , 'age'] = 5\n",
    "\n",
    "    # process hours\n",
    "    df.loc[(df['hours'] < 40), 'hours'] = 0\n",
    "    df.loc[(df['hours'] == 40), 'hours'] = 1\n",
    "    df.loc[(df['hours'] > 40), 'hours'] = 2\n",
    "\n",
    "    df = df.drop(columns=['workclass', 'gender', 'fnlwgt', 'education', 'occupation', \\\n",
    "                      'relationship', 'marital', 'race', 'country', 'capgain', \\\n",
    "                      'caploss'])\n",
    "    return df\n",
    "\n",
    "# one-hot encoding (for regression mdoels)\n",
    "df_train = one_hot_encode(df_train)\n",
    "df_test = one_hot_encode(df_test)\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Protected, privileged**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# protected: 'gender_Female'=1\n",
    "# privileged: 'gender_Male'=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parametric Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns='income')\n",
    "y_train = df_train['income']\n",
    "\n",
    "X_test = df_test.drop(columns='income')\n",
    "y_test = df_test['income']\n",
    "\n",
    "# size=500\n",
    "# X_train = X_train[0:size]\n",
    "# y_train = y_train[0:size]\n",
    "\n",
    "X_train_orig = copy.deepcopy(X_train)\n",
    "X_test_orig = copy.deepcopy(X_test)\n",
    "\n",
    "# Scale data: regularization penalty default: ‘l2’, ‘lbfgs’ solvers support only l2 penalties. \n",
    "# Regularization makes the predictor dependent on the scale of the features.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "clf = LogisticRegression(random_state=0, max_iter=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute statistical parity difference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeFairness(y_pred, X_test): \n",
    "    protected_idx = X_test[X_test['gender_Female']==1].index\n",
    "    numProtected = len(protected_idx)\n",
    "    privileged_idx = X_test[X_test['gender_Male']==1].index\n",
    "    numPrivileged = len(privileged_idx)\n",
    "    \n",
    "    p_protected = 0\n",
    "    for i in range(len(protected_idx)):\n",
    "        p_protected += y_pred[protected_idx[i]][1]\n",
    "    p_protected /= len(protected_idx)\n",
    "    \n",
    "    p_privileged = 0\n",
    "    for i in range(len(privileged_idx)):\n",
    "        p_privileged += y_pred[privileged_idx[i]][1]\n",
    "    p_privileged /= len(privileged_idx)\n",
    "    \n",
    "    spd = p_protected - p_privileged\n",
    "    return spd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Influence of points computed using ground truth**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ground_truth_influence(X_train, y_train, X_test, X_test_orig):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict_proba(X_test)\n",
    "    spd_0 = computeFairness(y_pred, X_test_orig)\n",
    "\n",
    "    delta_spd = []\n",
    "    for i in range(len(X_train)):\n",
    "        X_removed = np.delete(X_train, i, 0)\n",
    "        y_removed = y_train.drop(index=i, inplace=False)\n",
    "        clf.fit(X_removed, y_removed)\n",
    "        y_pred = clf.predict_proba(X_test)\n",
    "        delta_spd_i = computeFairness(y_pred, X_test_orig) - spd_0\n",
    "        delta_spd.append(delta_spd_i)\n",
    "    \n",
    "    return delta_spd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loss function** (Log loss for logistic regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_loss(y_true, y_pred):\n",
    "    loss = 0\n",
    "    for i in range(len(y_true)):\n",
    "        if (y_pred[i][1] != 0 and y_pred[i][0] != 0):\n",
    "            loss += - y_true[i] * math.log(y_pred[i][1]) - (1 - y_true[i]) * math.log(y_pred[i][0])\n",
    "    loss /= len(y_true)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute Accuracy** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeAccuracy(y_true, y_pred):\n",
    "    accuracy = 0\n",
    "    for i in range(len(y_true)):\n",
    "        idx = y_true[i]\n",
    "        accuracy += y_pred[i][idx]\n",
    "    accuracy /= len(y_true)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First-order derivative of loss function at z with respect to model parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_L_del_theta_i(num_params, y_true, x, y_pred):\n",
    "#     del_L_del_theta = np.ones((num_params, 1)) * ((1 - y_true) * y_pred[1] - y_true * y_pred[0])\n",
    "    del_L_del_theta = np.ones((num_params, 1)) * (- y_true + y_pred[1])\n",
    "    for j in range(1, num_params):\n",
    "            del_L_del_theta[j] *=  x[j-1]\n",
    "    return del_L_del_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hessian: Second-order partial derivative of loss function with respect to model parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hessian_one_point(num_params, x, y_pred):\n",
    "    H = np.ones((num_params, num_params)) * (y_pred[0] * y_pred[1])\n",
    "    for i in range(1, num_params):\n",
    "        for j in range(i + 1):\n",
    "            if j == 0:\n",
    "                H[i][j] *= x[i-1]\n",
    "            else:\n",
    "                H[i][j] *= x[i-1] * x[j-1] \n",
    "    i_lower = np.tril_indices(num_params, -1)\n",
    "    H.T[i_lower] = H[i_lower]     \n",
    "    return H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First-order derivative of $P(y \\mid \\textbf{x})$ with respect to model parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_f_del_theta_i(num_params, x, y_pred):\n",
    "    del_f_del_theta = np.ones((num_params, 1)) * (y_pred[0] * y_pred[1])\n",
    "    for j in range(1, num_params):\n",
    "            del_f_del_theta[j] *=  x[j-1]\n",
    "    return del_f_del_theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Computing $v=\\nabla($Statistical parity difference$)$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return v = del(SPD)/del(theta)\n",
    "def del_spd_del_theta(num_params, X_test_orig, X_test, y_pred):\n",
    "    del_f_protected = np.zeros((num_params, 1))\n",
    "    del_f_privileged = np.zeros((num_params, 1))\n",
    "    numProtected = X_test_orig['gender_Female'].sum()\n",
    "    numPrivileged = X_test_orig['gender_Male'].sum()\n",
    "    for i in range(len(X_test)):\n",
    "        del_f_i = del_f_del_theta_i(num_params, X_test[i], y_pred[i])\n",
    "        if X_test_orig.iloc[i]['gender_Male'] == 1: #privileged\n",
    "            del_f_privileged = np.add(del_f_privileged, del_f_i)\n",
    "        elif X_test_orig.iloc[i]['gender_Female'] == 1:\n",
    "            del_f_protected = np.add(del_f_protected, del_f_i)\n",
    "    del_f_privileged /= numPrivileged\n",
    "    del_f_protected /= numProtected\n",
    "    v = np.subtract(del_f_protected, del_f_privileged)\n",
    "    return v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stochastic estimation of Hessian vector product (involving del fairness): $H_{\\theta}^{-1}v = H_{\\theta}^{-1}\\nabla_{\\theta}f(z, \\theta) = v + [I - \\nabla_{\\theta}^2L(z_{s_j}, \\theta^*)]H_{\\theta}^{-1}v$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uniformly sample t points from training data \n",
    "def hessian_vector_product(num_params, n, size, v, hessian_all_points):\n",
    "    if (size > n):\n",
    "        size = n\n",
    "    sample = random.sample(range(n), size)\n",
    "    hinv_v = copy.deepcopy(v)\n",
    "    for idx in range(size):\n",
    "        i = sample[idx]\n",
    "        hessian_i = hessian_all_points[i]\n",
    "        hinv_v = np.matmul(np.subtract(np.identity(num_params), hessian_i), hinv_v)\n",
    "        hinv_v = np.add(hinv_v, v)\n",
    "    return hinv_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First-order influence computation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_order_influence(del_L_del_theta, hinv_v, n):\n",
    "    infs = []\n",
    "    for i in range(n):\n",
    "        inf = -np.dot(del_L_del_theta[i].transpose(), hinv_v)\n",
    "        inf *= -1/n\n",
    "        infs.append(inf[0][0].tolist())\n",
    "    return infs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Second-order influence computation for a group of points in subset U**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def second_order_influence(X_train, U, size, del_L_del_theta, hessian_all_points):\n",
    "    u = len(U)\n",
    "    s = len(X_train)\n",
    "    p = u/s\n",
    "    c1 = (1 - 2*p)/(s * (1-p)**2)\n",
    "    c2 = 1/((s * (1-p))**2)\n",
    "    num_params = len(del_L_del_theta[0])\n",
    "    del_L_del_theta_hinv = np.zeros((num_params, 1))\n",
    "    del_L_del_theta_sum = np.zeros((num_params, 1))\n",
    "    hessian_U = np.zeros((num_params, num_params))\n",
    "    for i in range(u):\n",
    "        idx = U[i]\n",
    "        hessian_U = np.add(hessian_U, s * hessian_all_points[idx])\n",
    "        del_L_del_theta_sum = np.add(del_L_del_theta_sum, del_L_del_theta[idx])\n",
    "    \n",
    "    hinv_del_L_del_theta= np.matmul(hinv_exact, del_L_del_theta_sum)\n",
    "    hinv_hessian_U = np.matmul(hinv_exact, hessian_U)\n",
    "    term1 = c1 * hinv_del_L_del_theta\n",
    "    term2 = c2 * np.matmul(hinv_hessian_U, hinv_del_L_del_theta)\n",
    "    sum_term = np.add(term1, term2)\n",
    "    return sum_term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Metrics: Initial state**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial fairness:  -0.20044233691822827\n",
      "Initial loss:  0.3597551530603338\n",
      "Initial accuracy:  0.7697879897394231\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "num_params = len(clf.coef_.transpose()) + 1 #weights and intercept; params: clf.coef_, clf.intercept_\n",
    "y_pred_test = clf.predict_proba(X_test)\n",
    "y_pred_train = clf.predict_proba(X_train)\n",
    "    \n",
    "spd_0 = computeFairness(y_pred_test, X_test_orig)\n",
    "print(\"Initial fairness: \", spd_0)\n",
    "\n",
    "loss_0 = logistic_loss(y_test, y_pred_test)\n",
    "print(\"Initial loss: \", loss_0)\n",
    "\n",
    "accuracy_0 = computeAccuracy(y_test, y_pred_test)\n",
    "print(\"Initial accuracy: \", accuracy_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pre-compute: (1) Hessian (2) del_L_del_theta for each training data point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "del_L_del_theta = []\n",
    "for i in range(int(len(X_train))):\n",
    "    del_L_del_theta.insert(i, del_L_del_theta_i(num_params, y_train[i], X_train[i], y_pred_train[i]))\n",
    "\n",
    "hessian_all_points = []\n",
    "for i in range(len(X_train)):\n",
    "    hessian_all_points.insert(i, hessian_one_point(num_params, X_train[i], y_pred_train[i])\n",
    "                              /len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*H^{-1} computation*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hexact = 1\n",
    "v1 = del_spd_del_theta(num_params, X_test_orig, X_test, y_pred_test)\n",
    "if hexact == 1: \n",
    "    H_exact = np.zeros((num_params, num_params))\n",
    "    for i in range(len(X_train)):\n",
    "        H_exact = np.add(H_exact, hessian_all_points[i])\n",
    "    hinv_exact = np.linalg.pinv(H_exact) \n",
    "    hinv_v = np.matmul(hinv_exact, v1)\n",
    "else: #using Hessian vector product\n",
    "    size_hvp = int(len(X_train) * .01)\n",
    "    hinv_v = hessian_vector_product(num_params, len(X_train), size_hvp, v1, hessian_all_points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ground truth influence of each training data point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth influence\n",
    "# spdgt = ground_truth_influence(X_train, y_train, X_test, X_test_orig)\n",
    "# with open('delta_spd_ground_truth_v0.txt', 'w') as filehandle:\n",
    "#     for listitem in delta_spd:\n",
    "#         filehandle.write('%s\\n' % listitem)\n",
    "gt_spd = pd.read_csv('delta_spd_ground_truth_v0.txt', names=[\"Values\"], sep=\",\")\n",
    "gt_spd = gt_spd.values.tolist()\n",
    "spdgt=[]\n",
    "for i in range(len(gt_spd)):\n",
    "    spdgt.append(gt_spd[i][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First-order influence of each training data point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "infs_1 = first_order_influence(del_L_del_theta, hinv_v, len(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correlation between first-order and ground truth influences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman rank correlation between 1st order inf and ground truth inf:  0.9758985293908202\n",
      "Pearson correlation coefficient between 1st order inf and ground truth inf:  0.9905517682165959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*c* argument looks like a single numeric RGB or RGBA sequence, which should be avoided as value-mapping will have precedence in case its length matches with *x* & *y*.  Please use the *color* keyword-argument or provide a 2-D array with a single row if you intend to specify the same RGB or RGBA value for all points.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Spearman rank correlation between 1st order inf and ground truth inf: \", \n",
    "      stats.spearmanr(spdgt, infs_1)[0])\n",
    "print(\"Pearson correlation coefficient between 1st order inf and ground truth inf: \", \n",
    "      stats.pearsonr(spdgt, infs_1)[0])\n",
    "\n",
    "colors = (0.5,0.2,0.5)\n",
    "fig = plt.figure()\n",
    "plt.scatter(infs_1, spdgt, c=colors, alpha=0.5)\n",
    "plt.xlabel('First-order influence')\n",
    "plt.ylabel('Ground truth influence')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Verification of first-order influence (implementation) on log-loss of a single point**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ground_truth_influence_loss(X_train, y_train, X_test, y_test, idx):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict_proba([X_test[idx]])[0]\n",
    "    loss_0 = - y_test[idx] * math.log(y_pred[1]) - (1 - y_test[idx]) * math.log(y_pred[0])\n",
    "\n",
    "    delta_loss = []\n",
    "    for i in range(len(X_train)):\n",
    "        X_removed = np.delete(X_train, i, 0)\n",
    "        y_removed = y_train.drop(index=i, inplace=False)\n",
    "        clf.fit(X_removed, y_removed)\n",
    "        y_pred = clf.predict_proba([X_test[idx]])[0]\n",
    "        loss_i = - y_test[idx] * math.log(y_pred[1]) - (1 - y_test[idx]) * math.log(y_pred[0])\n",
    "        delta_loss_i = loss_i - loss_0\n",
    "        delta_loss.append(delta_loss_i)\n",
    "    \n",
    "    return delta_loss\n",
    "\n",
    "verify = 0\n",
    "if verify:\n",
    "    # Identify data points misclassified by the model\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict_proba(X_test)\n",
    "    for i in range(len(X_test)):\n",
    "        if (y_pred[i][y_test[i]] < y_pred[i][1 - y_test[i]]):\n",
    "            print(i)\n",
    "\n",
    "    # compute loss approximated by first-order influence for a misclassified test data point\n",
    "    ix = 203 \n",
    "    v1 = del_L_del_theta_i(num_params, y_test[ix], X_test[ix], y_pred_test[ix])\n",
    "    H_exact = np.zeros((num_params, num_params))\n",
    "    for i in range(len(X_train)):\n",
    "        H_exact = np.add(H_exact, hessian_all_points[i])\n",
    "    hinv_exact = np.linalg.pinv(H_exact) \n",
    "    hinv_v = np.matmul(hinv_exact, v1)\n",
    "\n",
    "    infs_1 = first_order_influence(del_L_del_theta, hinv_v, len(X_train))\n",
    "    delta_loss_gt = ground_truth_influence_loss(X_train, y_train, X_test, y_test, ix)\n",
    "\n",
    "    colors = (0.5,0.2,0.5)\n",
    "    # fig = plt.figure()\n",
    "    fig, ax = plt.subplots(figsize=(4,4))\n",
    "    plt.scatter(infs_1, delta_loss_gt, c=colors, alpha=0.5)\n",
    "    plt.xlabel('First-order influence')\n",
    "    plt.ylabel('Ground truth influence')\n",
    "    ax.plot((0,1), 'r--')\n",
    "    # ax.plot([0,1],[0,1], transform=ax.transAxes)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking ground truth, first-order and second-order influences for a set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "active = 0\n",
    "if active:\n",
    "    predicates = ['marital_Never-married', 'gender_Female']\n",
    "    idx = X_train_orig[(X_train_orig[predicates[0]] == 1)\n",
    "                       & (X_train_orig[predicates[1]] == 1) \n",
    "                      ].index \n",
    "    print(\"#Rows removed: \", len(idx))\n",
    "    print(\"#Rows left: \", len(X_train) - len(idx))\n",
    "    X = np.delete(X_train, idx, 0)\n",
    "    y = y_train.drop(index=idx, inplace=False)\n",
    "    clf.fit(X, y)\n",
    "    y_pred_test = clf.predict_proba(X_test)\n",
    "    print(\"Ground truth fairness of subset: \", computeFairness(y_pred_test, X_test_orig))\n",
    "    print(\"Ground truth influence of subset: \", computeFairness(y_pred_test, X_test_orig) - spd_0)\n",
    "\n",
    "    del_f_1 = 0\n",
    "    for i in range(len(idx)):\n",
    "        del_f_1 += infs_1[idx[i]]\n",
    "    print(\"First-order influence: \", del_f_1)\n",
    "\n",
    "    size_hvp = 1\n",
    "    params_f_2 = second_order_influence(X_train, idx, size_hvp, del_L_del_theta, hessian_all_points)\n",
    "    del_f_2 = np.dot(v1.transpose(), params_f_2)[0][0]\n",
    "    print(\"Second-order influence: \", del_f_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fairness: Ground-truth subset influence vs. computed subset influences: Random subset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ground-truth subset, Add 1st-order inf individual, Add ground-truth inf individual, Second-order subset influence\n"
     ]
    }
   ],
   "source": [
    "print(\"Ground-truth subset, Add 1st-order inf individual, Add ground-truth inf individual, Second-order subset influence\")\n",
    "sampleSize = int(.2 * len(X_train))\n",
    "for i in range(100):\n",
    "    idx = random.sample(range(1, len(X_train)), sampleSize) \n",
    "    \n",
    "    # Ground truth subset influence\n",
    "    X = np.delete(X_train, idx, 0)\n",
    "    y = y_train.drop(index=idx, inplace=False)\n",
    "    clf.fit(X, y)\n",
    "    y_pred_test = clf.predict_proba(X_test)\n",
    "    inf_gt = computeFairness(y_pred_test, X_test_orig) - spd_0\n",
    "    \n",
    "    # First-order subset influence\n",
    "    del_f_1 = 0\n",
    "    for i in range(len(idx)):\n",
    "        del_f_1 += infs_1[idx[i]]\n",
    "    \n",
    "    # Second-order subset influence\n",
    "    size_hvp = 1\n",
    "    params_f_2 = second_order_influence(X_train, idx, size_hvp, del_L_del_theta, hessian_all_points)\n",
    "    del_f_2 = np.dot(v1.transpose(), params_f_2)[0][0]\n",
    "    \n",
    "#     print(inf_gt, del_f_1, del_f_2, sep=\", \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fairness: Ground-truth subset influence vs. computed subset influences: Coherent subset** \n",
    "\n",
    "(by coherent, we mean group of data points that share some properties)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribute, Value, Ground-truth subset, Add 1st-order inf individual, Second-order subset influence, #rowsRemoved, Accuracy\n",
      "age, 2, 0.001738985483057287, 0.0010442475473438184, 0.0015884611667642003, 7807, 0.7713831930870712\n",
      "age, 3, 0.01186742386215106, 0.008092110416821558, 0.011438620031781773, 5621, 0.7710644297644512\n",
      "age, 1, -0.008576235854335423, -0.004684600707812446, -0.0077114763640210885, 8041, 0.7670985322140986\n",
      "age, 0, -0.0004915442516325585, -0.00037015894215078473, -0.0004909708024371194, 4869, 0.7674116251466035\n",
      "age, 4, -0.0030169922030444107, -0.0014460030664138926, -0.002560053319390826, 2849, 0.7700913419582628\n",
      "age, 5, -0.003515454473200952, -0.002627454573157027, -0.0034070006304255615, 975, 0.7691750256673835\n",
      "education.num, 13, -0.0016957302517503492, -0.0014506750358219426, -0.001713755370338796, 5044, 0.7696689677640415\n",
      "education.num, 9, 0.0028731538912217247, 0.0018398584816321666, 0.002659171609421306, 9840, 0.7693027595125387\n",
      "education.num, 7, -0.0004669722681995836, -0.00045328144262146887, -0.0004678002391749279, 1048, 0.7699707159944769\n",
      "education.num, 14, -0.001225175363101516, -0.001231489286522565, -0.00131761840236789, 1627, 0.7696267332720858\n",
      "education.num, 5, -0.0001735136227433154, -0.000175906911832747, -0.00017490401948007766, 455, 0.7698728814783267\n",
      "education.num, 10, 0.003486971087859697, 0.0027915242837682672, 0.003505687542468478, 6678, 0.7694866779201165\n",
      "education.num, 12, -0.0011756755180462597, -0.0011264388144809083, -0.0011815331762059097, 1008, 0.7696107650749499\n",
      "education.num, 4, 0.0004644994546137149, 0.0004437095326587821, 0.0004604593163611254, 557, 0.7699929767171755\n",
      "education.num, 16, -0.001657742530164763, -0.001593729403134636, -0.0016592277510768232, 375, 0.7701256030354796\n",
      "education.num, 11, -0.0009989410003757304, -0.0009340490881430435, -0.0010064285997427507, 1307, 0.7696278867187375\n",
      "education.num, 15, 0.0010187493419213656, 0.0007847965903957075, 0.0009818512877707473, 542, 0.7697048704396104\n",
      "education.num, 3, 1.0851029199399065e-05, 1.2865863881160743e-06, 5.968363609878728e-06, 288, 0.7699299776375236\n",
      "education.num, 6, 0.0007152297452928946, 0.0006962074081511596, 0.0007159964756320239, 820, 0.7699009328815124\n",
      "education.num, 1, -1.3271829582828243e-05, -1.1522674208614865e-05, -1.1553625217217068e-05, 45, 0.7697638232173708\n",
      "education.num, 8, 0.0002566344398018394, 0.0002562552668215821, 0.000255886071454777, 377, 0.7697879338602905\n",
      "education.num, 2, 0.00017442250903548784, 0.00017159518158136995, 0.0001748022164412788, 151, 0.7698555423532614\n",
      "hours, 1, 0.01961041848624895, 0.008648306807554964, 0.01842402747263415, 14251, 0.7677586492330907\n",
      "hours, 0, -0.0082371164035272, -0.006316040638928851, -0.008296862039951832, 6714, 0.7685541586503993\n",
      "hours, 2, -0.012027085603773802, -0.0023241254939949806, -0.005472971425772165, 9197, 0.7722231714428909\n",
      "gender_Female, 1, 0.07930358692840347, -0.00039216461506846455, -0.0006407848050725415, 9782, 0.7565363882848725\n",
      "gender_Male, 1, 0.07785878639440647, 0.00040030528969968503, 0.0006311180795703596, 20380, 0.7767971413703665\n",
      "race_Amer-Indian-Eskimo, 1, -0.0003773486473568344, -0.00027089290920205035, -0.0002735616945099042, 286, 0.7698208202809661\n",
      "race_Asian-Pac-Islander, 1, -0.000516828764107774, -0.0005247593965967967, -0.0005376894627316389, 895, 0.7704032964991947\n",
      "race_Black, 1, 0.002182691996259839, 0.0019301917036626765, 0.0020974180677988145, 2817, 0.7694933993537811\n",
      "race_Other, 1, -0.001019118683369069, -0.00017805036875717412, -0.0001799151851978297, 231, 0.7690138413161783\n",
      "race_White, 1, 0.0019215042326633514, -0.0009483483544754142, -0.0072741530563829645, 25933, 0.7689950429218244\n",
      "marital_Divorced, 1, 0.010057342532674651, 0.0015612479153494555, 0.0024069588543990518, 4214, 0.7629425843331962\n",
      "marital_Married-AF-spouse, 1, -9.632205337162247e-05, -0.00011851263882643117, -0.00011973847403766024, 21, 0.7697872887143089\n",
      "marital_Married-civ-spouse, 1, 0.17076104741051418, -0.0005825815849803259, 0.0006976612646411917, 14065, 0.7566812411204711\n",
      "marital_Married-spouse-absent, 1, -5.3291001375521674e-05, -0.00012896371226540465, -0.00013109041297459755, 370, 0.7694747166490379\n",
      "marital_Never-married, 1, -0.007559798485271552, -0.003391576496853468, -0.006109267590534102, 9726, 0.7456509404790447\n",
      "marital_Separated, 1, 0.0016340439717257293, 0.0008963260396029095, 0.0009629115177309113, 939, 0.7685537551946033\n",
      "marital_Widowed, 1, 0.003642613121319388, 0.0017722011526045043, 0.0019022472866041314, 827, 0.7691108775881673\n",
      "workclass_Federal-gov, 1, 0.002566635866445177, 0.0006015909960056337, 0.0006908734256578312, 943, 0.7694109535676792\n",
      "workclass_Local-gov, 1, 0.00151256905557684, 0.00019731003448198987, 0.0009721766693847598, 2067, 0.7701416497601498\n",
      "workclass_Private, 1, 0.004674572490506873, 0.0016811685947856017, 0.014318593256502019, 22286, 0.7575237126684156\n",
      "workclass_Self-emp-inc, 1, 0.0030199274178358826, 0.00018672190663769018, 0.00017927577691459706, 1074, 0.769620668011426\n",
      "workclass_Self-emp-not-inc, 1, -0.006313702575846847, -0.0017894955426749997, -0.0018998975400064317, 2499, 0.77035434763395\n",
      "workclass_State-gov, 1, -0.0013290660053357217, -0.0008689225742788078, -0.0009615980296913918, 1279, 0.769529701611953\n",
      "workclass_Without-pay, 1, -0.0002051461031148949, -2.3274032585395307e-07, -4.652865799743584e-07, 14, 0.769725746668011\n",
      "relationship_Husband, 1, -0.009500589181360819, 0.00019105034081637106, 0.00045845233850712937, 12463, 0.7702157437090552\n",
      "relationship_Not-in-family, 1, -0.006084336906650806, -0.002055087653476582, -0.004355949032193104, 7726, 0.7739168154455023\n",
      "relationship_Other-relative, 1, 0.00011849756434867409, -0.00027473795168698773, -0.0002697076259012442, 889, 0.7693832840260217\n",
      "relationship_Own-child, 1, -0.001890829380133352, -0.0009925521845638562, -0.001081801792378752, 4466, 0.7657538154090104\n",
      "relationship_Unmarried, 1, 0.0028535586893386755, 0.0031300401924006, 0.0039372253089341325, 3212, 0.7700282358784823\n",
      "relationship_Wife, 1, -0.03507643518842948, 9.427931141684045e-06, -3.1894732064658733e-06, 1406, 0.7695917034208113\n",
      "occupation_Adm-clerical, 1, 0.0005812164271142006, 0.0005312947939400147, 0.0005674507310268954, 3721, 0.7687182736502147\n",
      "occupation_Armed-Forces, 1, -0.00016123875181345282, 1.8014750059165251e-06, 2.011681084309911e-06, 9, 0.7698311406662897\n",
      "occupation_Craft-repair, 1, -7.035870010763112e-05, -0.00015627486530200076, -0.00018385565043428954, 4030, 0.7700884831744197\n",
      "occupation_Exec-managerial, 1, 0.010029860978970517, -0.0006778402784394598, -0.001207930665976886, 3992, 0.7670851658895089\n",
      "occupation_Farming-fishing, 1, -0.004337991170597633, 0.00018554163008969557, 0.0001886177260613183, 989, 0.7680269502397232\n",
      "occupation_Handlers-cleaners, 1, -0.002721049684859256, 5.028007234185201e-05, 5.132087508654319e-05, 1350, 0.7683163592202347\n",
      "occupation_Machine-op-inspct, 1, -0.0007756435743928314, 0.0010948466327819156, 0.0011462925352782106, 1966, 0.7684679253818261\n",
      "occupation_Other-service, 1, -0.0007250916736707413, -0.0009745125205303596, -0.001049252561148962, 3212, 0.7663080793919548\n",
      "occupation_Priv-house-serv, 1, 0.00332151015071816, -2.6370404303554648e-05, -2.5244848181342975e-05, 143, 0.768725583878494\n",
      "occupation_Prof-specialty, 1, 0.0020082111840913908, -0.0022306928751138974, -0.002427900743409021, 4038, 0.7695871057348654\n",
      "occupation_Protective-serv, 1, 0.00181560727309793, -0.00046085805149307307, -0.00044323160119620305, 644, 0.7702238785892602\n",
      "occupation_Sales, 1, 0.005303582849617461, 0.0024593517635402022, 0.002824619979452824, 3584, 0.7700788512945167\n",
      "occupation_Tech-support, 1, 0.0012818195396941956, 0.0003621883333873038, 0.00037398521461998467, 912, 0.7699858677407267\n",
      "occupation_Transport-moving, 1, -0.0022697672372697653, -0.00015061503127331694, -0.00014331252976761038, 1572, 0.7694223492134\n"
     ]
    }
   ],
   "source": [
    "print(\"Attribute, Value, Ground-truth subset, Add 1st-order inf individual, \\\n",
    "Second-order subset influence, #rowsRemoved, Accuracy\")\n",
    "clf.fit(X_train, y_train)\n",
    "continuous_cols = ['age', 'education.num', 'hours',]\n",
    "for col in X_train_orig.columns:\n",
    "    if col in continuous_cols:\n",
    "        vals = X_train_orig[col].unique()\n",
    "    else:\n",
    "        vals = [1]\n",
    "    for val in vals:\n",
    "#         print(col, val, sep=\": \")\n",
    "        idx = X_train_orig[X_train_orig[col] == val].index \n",
    "    \n",
    "        X = np.delete(X_train, idx, 0)\n",
    "        y = y_train.drop(index=idx, inplace=False)\n",
    "        inf_gt = 0\n",
    "        if len(y.unique()) > 1:\n",
    "            # Ground truth subset influence\n",
    "            clf.fit(X, y)\n",
    "            y_pred = clf.predict_proba(X_test)\n",
    "            inf_gt = computeFairness(y_pred, X_test_orig) - spd_0\n",
    "            accuracy = computeAccuracy(y_test, y_pred)\n",
    "\n",
    "        # First-order subset influence\n",
    "        del_f_1 = 0            \n",
    "        for i in range(len(idx)):\n",
    "            del_f_1 += infs_1[idx[i]]\n",
    "\n",
    "        # Second-order subset influence\n",
    "        size_hvp = 1\n",
    "        params_f_2 = second_order_influence(X_train, idx, size_hvp, del_L_del_theta, hessian_all_points)\n",
    "        del_f_2 = np.dot(v1.transpose(), params_f_2)[0][0]\n",
    "\n",
    "        print(col, val, inf_gt, del_f_1, del_f_2, len(idx), accuracy, sep=\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['age', 'workclass', 'fnlwgt', 'education', 'education.num', 'marital', 'occupation', 'relationship', 'race', 'gender', 'capgain', 'caploss', 'hours', 'country', 'income']\n",
    "df_train = pd.read_csv('adult.data', names=cols, sep=\",\")\n",
    "df_test = pd.read_csv('adult.test', names=cols, sep=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Space Partitioner for reducing bias**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['age', 'workclass', 'fnlwgt', 'education', 'education.num', 'marital', 'occupation', 'relationship', 'race', 'gender', 'capgain', 'caploss', 'hours', 'country', 'income']\n",
    "df_train = pd.read_csv('adult.data', names=cols, sep=\",\")\n",
    "df_test = pd.read_csv('adult.test', names=cols, sep=\",\")\n",
    "\n",
    "def preprocess(df):\n",
    "    df.isin(['?']).sum(axis=0)\n",
    "\n",
    "    # replace missing values (?) to nan and then drop the columns\n",
    "    df['country'] = df['country'].replace('?',np.nan)\n",
    "    df['workclass'] = df['workclass'].replace('?',np.nan)\n",
    "    df['occupation'] = df['occupation'].replace('?',np.nan)\n",
    "\n",
    "    df.loc[(df['age'] >= 15) & (df['age'] <= 24) , 'age'] = 0\n",
    "    df.loc[(df['age'] >= 25) & (df['age'] <= 34) , 'age'] = 1\n",
    "    df.loc[(df['age'] >= 35) & (df['age'] <= 44) , 'age'] = 2\n",
    "    df.loc[(df['age'] >= 45) & (df['age'] <= 54) , 'age'] = 3\n",
    "    df.loc[(df['age'] >= 55) & (df['age'] <= 64) , 'age'] = 4\n",
    "    df.loc[(df['age'] >= 65) , 'age'] = 5\n",
    "\n",
    "    df.loc[(df['hours'] < 40), 'hours'] = 0\n",
    "    df.loc[(df['hours'] == 40), 'hours'] = 1\n",
    "    df.loc[(df['hours'] > 40), 'hours'] = 2\n",
    "    \n",
    "    # dropping the NaN rows now\n",
    "    df.dropna(how='any',inplace=True)\n",
    "    df['income'] = df['income'].map({'<=50K': 0, '>50K': 1}).astype(int)\n",
    "    df = df.drop(columns=['fnlwgt', 'education.num', 'country', 'capgain', 'caploss'])\n",
    "    return df\n",
    "\n",
    "df_train = preprocess(df_train)\n",
    "df_test = preprocess(df_test)\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "X_train_ = df_train.drop(columns='income')\n",
    "y_train_ = df_train['income']\n",
    "\n",
    "X_test_ = df_test.drop(columns='income')\n",
    "y_test_ = df_test['income']\n",
    "\n",
    "# size=2000\n",
    "# X_train = X_train[0:size]\n",
    "# y_train = y_train[0:size]\n",
    "\n",
    "# X_train_ = X_train_[0:size]\n",
    "# y_train_ = y_train_[0:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root:  {'splitCol': 'workclass', 'predCols': [], 'predVals': [], 'numRows': 30162}\n",
      "Depth:  1\n",
      "Depth:  2\n",
      "Depth:  2\n",
      "Depth:  2\n",
      "Depth:  2\n",
      "Depth:  2\n",
      "Depth:  2\n",
      "Depth:  2\n"
     ]
    }
   ],
   "source": [
    "def computeFairness(y_pred, X_test): \n",
    "    protected_idx = X_test[X_test['gender']=='Female'].index\n",
    "    numProtected = len(protected_idx)\n",
    "    privileged_idx = X_test[X_test['gender']=='Male'].index\n",
    "    numPrivileged = len(privileged_idx)\n",
    "    \n",
    "    p_protected = 0\n",
    "    for i in range(len(protected_idx)):\n",
    "        p_protected += y_pred[protected_idx[i]][1]\n",
    "    p_protected /= len(protected_idx)\n",
    "    \n",
    "    p_privileged = 0\n",
    "    for i in range(len(privileged_idx)):\n",
    "        p_privileged += y_pred[privileged_idx[i]][1]\n",
    "    p_privileged /= len(privileged_idx)\n",
    "    \n",
    "    spd = p_protected - p_privileged\n",
    "    return spd\n",
    "\n",
    "def getInfluenceOfSet(indices, f, X_train, y_train, X_test, X_test_, method): \n",
    "    del_f = 0\n",
    "    if (method == 1):\n",
    "        X = X_train.drop(index=indices, inplace=False)\n",
    "        y = y_train.drop(index=indices, inplace=False)\n",
    "        if len(y.unique()) < 2:\n",
    "            return 0\n",
    "        clf.fit(X, y)\n",
    "        y_pred = clf.predict_proba(X_test)\n",
    "        del_f = computeFairness(y_pred, X_test_)\n",
    "    elif (method == 2):\n",
    "        for i in range(len(indices)):\n",
    "            del_f += infs_1[indices[i]]\n",
    "    elif (method == 3):\n",
    "        size_hvp = 1\n",
    "        params_f_2 = second_order_influence(X_train, indices, size_hvp, del_L_del_theta, hessian_all_points)\n",
    "        del_f = np.dot(v1.transpose(), params_f_2)[0][0]\n",
    "    return  del_f\n",
    "\n",
    "def getSplitVal(infs):\n",
    "    score = np.Inf\n",
    "    splitColIdx = -1\n",
    "    for i in range(len(infs)):\n",
    "        for j in range(len(infs[i])):\n",
    "            if (abs(infs[i][j]) < score):\n",
    "                splitColIdx = i\n",
    "                score = abs(infs[i][j])\n",
    "    return splitColIdx\n",
    "\n",
    "def getSplitAttribute(cols, predCols, predVals, \n",
    "                      X_train, y_train, X_test, X_train_, X_test_, method):\n",
    "    splitCol, numRows, score, idx = None, len(X_train_), abs(spd_0), []\n",
    "    X_ = copy.deepcopy(X_train_)\n",
    "    \n",
    "    if len(predCols) > 0:\n",
    "        for i in range(len(predCols)):\n",
    "            pred = predCols[i]\n",
    "            val = predVals[i]\n",
    "            idx = X_[X_[pred] == val].index \n",
    "            X_ = X_[X_[pred] == val]\n",
    "    \n",
    "    numRows = len(X_train_) - len(idx)\n",
    "    infs = []\n",
    "    for i in range(len(cols)):\n",
    "        col = cols[i]\n",
    "        infs_i = []\n",
    "        vals_i = []\n",
    "        colVals = X_train_[col].unique()\n",
    "        for val in colVals:\n",
    "            idx_i = X_[X_[col] == val].index\n",
    "            infs_i.append(getInfluenceOfSet(idx_i, spd_0, X_train, y_train, X_test, X_test_, method))\n",
    "        infs.append(infs_i)\n",
    "           \n",
    "    colIdx = getSplitVal(infs)\n",
    "    splitCol = cols[colIdx]\n",
    "    return {'splitCol': splitCol, 'predCols': predCols, 'predVals': predVals, 'numRows': numRows}\n",
    "\n",
    "def partition(node, maxDepth, minSize, depth, cols, \n",
    "              X_train_, y_train_, X_train, X_test_, X_test, method):\n",
    "    print(\"Depth: \", depth)\n",
    "    if depth >= maxDepth or node['numRows'] < minSize:\n",
    "        node['children'] = None\n",
    "        return\n",
    "    \n",
    "    X_ = copy.deepcopy(X_train_)\n",
    "    if len(node['predCols']) > 0:\n",
    "        for i in range(len(node['predCols'])):\n",
    "            pred = node['predCols'][i]\n",
    "            val = node['predVals'][i]\n",
    "            idx = X_[X_[pred] == val].index \n",
    "            X_ = X_[X_[pred] == val]\n",
    "    \n",
    "    col = node['splitCol']\n",
    "    vals = X_train_[col].unique()\n",
    "    child = [None] * len(vals)\n",
    "    for i in range(len(vals)):\n",
    "        idx = X_[X_[col] == vals[i]].index \n",
    "        X = X_train.drop(index=idx, inplace=False)\n",
    "        y = y_train.drop(index=idx, inplace=False)\n",
    "        X_ = X_train_.drop(index=idx, inplace=False)\n",
    "        if len(X) < minSize:\n",
    "            node['children'] = None\n",
    "        else:\n",
    "            cols_ = copy.deepcopy(cols)\n",
    "            cols_.remove(col)\n",
    "            predCols_temp = copy.deepcopy(node['predCols'])\n",
    "            predCols_temp.append(col)\n",
    "            predVals_temp = copy.deepcopy(node['predVals'])\n",
    "            predVals_temp.append(vals[i])\n",
    "            child[i] = getSplitAttribute(cols_, predCols_temp, predVals_temp, \n",
    "                                         X_train, y_train, X_test,  X_train_, X_test_, method)\n",
    "            child[i]['predCols'] = predCols_temp\n",
    "            child[i]['predVals'] = predVals_temp\n",
    "            partition(child[i], maxDepth, minSize, depth + 1, cols_,  \n",
    "                      X_train_, y_train_, X_train, X_test_, X_test, method)\n",
    "    node['children'] = child\n",
    "\n",
    "def buildTree(X_train_, X_train, maxDepth, minSize, method):\n",
    "    cols = copy.deepcopy(X_train_.columns).tolist()\n",
    "    X_train = pd.DataFrame(data=X_train, columns=X_train_orig.columns)\n",
    "    root = getSplitAttribute(cols, [], [], X_train, y_train, X_test, X_train_, X_test_, method)\n",
    "    print(\"Root: \", root)\n",
    "    partition(root, maxDepth, minSize, 1, cols,\n",
    "              X_train_, y_train_, X_train, X_test_, X_test, method)\n",
    "    return root\n",
    "\n",
    "method = 3\n",
    "dtree = buildTree(X_train_, X_train, 2, 100, method)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'splitCol': 'workclass',\n",
       " 'predCols': [],\n",
       " 'predVals': [],\n",
       " 'numRows': 30162,\n",
       " 'children': [{'splitCol': 'occupation',\n",
       "   'predCols': ['workclass'],\n",
       "   'predVals': ['State-gov'],\n",
       "   'numRows': 28883,\n",
       "   'children': None},\n",
       "  {'splitCol': 'education',\n",
       "   'predCols': ['workclass'],\n",
       "   'predVals': ['Self-emp-not-inc'],\n",
       "   'numRows': 27663,\n",
       "   'children': None},\n",
       "  {'splitCol': 'occupation',\n",
       "   'predCols': ['workclass'],\n",
       "   'predVals': ['Private'],\n",
       "   'numRows': 7876,\n",
       "   'children': None},\n",
       "  {'splitCol': 'education',\n",
       "   'predCols': ['workclass'],\n",
       "   'predVals': ['Federal-gov'],\n",
       "   'numRows': 29219,\n",
       "   'children': None},\n",
       "  {'splitCol': 'marital',\n",
       "   'predCols': ['workclass'],\n",
       "   'predVals': ['Local-gov'],\n",
       "   'numRows': 28095,\n",
       "   'children': None},\n",
       "  {'splitCol': 'education',\n",
       "   'predCols': ['workclass'],\n",
       "   'predVals': ['Self-emp-inc'],\n",
       "   'numRows': 29088,\n",
       "   'children': None},\n",
       "  {'splitCol': 'age',\n",
       "   'predCols': ['workclass'],\n",
       "   'predVals': ['Without-pay'],\n",
       "   'numRows': 30148,\n",
       "   'children': None}]}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
